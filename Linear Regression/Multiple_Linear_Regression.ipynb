{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regression \n",
        "\n",
        "Now that we did univariate linear regression, It is now time to understand more about Multiple linear regression. Here, we will have output depending on more than one input variables. \n",
        "\n",
        "$$ Y(x_1,x_2,x_3,....) = W_1x_1+W_2x_2+W_3x_3+.....$$"
      ],
      "metadata": {
        "id": "TqocejS_GZNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a dataset about house prices as a function of different features like number of bathrooms, zipcode, floors and area of house along with condition."
      ],
      "metadata": {
        "id": "0ysquqqUaLtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "metadata": {
        "id": "8A6UlxQfavJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"kc_house_data.csv\")\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66HfaX5ZbcHy",
        "outputId": "ac4ca5ef-d284-412b-ae03-bd7067cee41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21613, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will find the correlation matrix which will tell us about the dependence of all the input variables on each other as well as on the output variables."
      ],
      "metadata": {
        "id": "UtjGY06ESDAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = dataset.corr()\n",
        "corr_features = corr_matrix.index\n",
        "plt.figure(figsize=(20,20))\n",
        "g=sns.heatmap(dataset[corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "metadata": {
        "id": "TzBQ5UezbmN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "outputId": "c5e4fff4-230e-43e4-a8d5-63ed16c5264e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the above heatmap the price does not depend on the id of the house which is quite \n",
        "intuitive. We can also sense some correlation in the sqft_living, sqft_above and bathrooms."
      ],
      "metadata": {
        "id": "qJ2ST4SuUyJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will calculate the VIF of the variables now to identify which variables to drop."
      ],
      "metadata": {
        "id": "vFjzB1y0yRCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are dropping zipcode, latitude and longitude columns as we do not expect them to have a linear relationship with the price.\n",
        "# id, date won't have  any significance related to the price therefore we drop them from the dataset.\n",
        "# yr_renovated, sqft_above and yr_built have been dropped because we wanted to have independent variables for the model.\n",
        "\n",
        "X=dataset.drop([\"price\",\"date\",\"id\",'zipcode','lat','long','yr_renovated','sqft_above','yr_built',], axis=1)\n",
        "vif = pd.DataFrame()\n",
        "vif[\"features\"] = X.columns\n",
        "vif[\"vif_Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "print(vif)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw8aJgiER6y6",
        "outputId": "61133d79-81df-4869-e35c-e81a2bf8322f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         features  vif_Factor\n",
            "0        bedrooms   20.662594\n",
            "1       bathrooms   24.917224\n",
            "2     sqft_living   29.309951\n",
            "3        sqft_lot    2.364605\n",
            "4          floors   15.917238\n",
            "5      waterfront    1.207270\n",
            "6            view    1.492498\n",
            "7       condition   21.107708\n",
            "8           grade   68.180283\n",
            "9   sqft_basement    2.615966\n",
            "10  sqft_living15   26.317104\n",
            "11     sqft_lot15    2.569635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.full(len(X.columns),100)\n",
        "bias = 0\n",
        "no_of_epochs = 10000\n",
        "lr = 0.009\n",
        "loss,loss1=[],[]\n",
        "X.head(10)\n",
        "X['sqft_living'] /= np.std(X['sqft_living'], axis = 0)\n",
        "X['sqft_lot'] /= np.std(X['sqft_lot'], axis = 0)\n",
        "X['sqft_living15']/= np.std(X['sqft_living15'], axis = 0)\n",
        "X['sqft_lot15']/= np.std(X['sqft_lot15'], axis = 0)\n",
        "X['sqft_basement']/= np.std(X['sqft_basement'], axis = 0)"
      ],
      "metadata": {
        "id": "xY0B09d9B8LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = X.iloc[:15000,:]\n",
        "val_data = X.iloc[15000:,:]"
      ],
      "metadata": {
        "id": "R0o-mZmnoF41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(no_of_epochs):\n",
        "   y_pred = np.matmul(train_data.values, weights) + bias\n",
        "   train_loss = ((y_pred - (dataset.iloc[:15000,:])[\"price\"])**2).mean()\n",
        "   dloss = 2*(y_pred - (dataset.iloc[:15000,:])['price'])\n",
        "   for i in range(len(X.columns)):\n",
        "     grad = (dloss*train_data.iloc[0:,i]).mean()\n",
        "     weights[i] = weights[i] - (grad*lr)\n",
        "   bias = bias - (dloss.mean())*lr\n",
        "   loss.append(train_loss)\n",
        "   print(\"For {}th iteration, the training loss is {}\".format(epoch+1,train_loss))\n",
        "   predict_data = np.matmul(val_data.values,weights)+ bias\n",
        "   val_loss = ((predict_data - (dataset.iloc[15000:,:])[\"price\"])**2).mean()\n",
        "   loss1.append(val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJcEKVIOCQ--",
        "outputId": "73845576-f703-40eb-f848-3b8b1d7a9be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "For 5001th iteration, the training loss is 54817804546.13337\n",
            "For 5002th iteration, the training loss is 54817423176.83473\n",
            "For 5003th iteration, the training loss is 54817042901.52984\n",
            "For 5004th iteration, the training loss is 54816662828.33295\n",
            "For 5005th iteration, the training loss is 54816282321.86521\n",
            "For 5006th iteration, the training loss is 54815901240.6026\n",
            "For 5007th iteration, the training loss is 54815520819.29355\n",
            "For 5008th iteration, the training loss is 54815140826.44321\n",
            "For 5009th iteration, the training loss is 54814759872.80445\n",
            "For 5010th iteration, the training loss is 54814379579.28661\n",
            "For 5011th iteration, the training loss is 54813999585.90883\n",
            "For 5012th iteration, the training loss is 54813619214.00779\n",
            "For 5013th iteration, the training loss is 54813239685.577484\n",
            "For 5014th iteration, the training loss is 54812860243.15141\n",
            "For 5015th iteration, the training loss is 54812480509.508835\n",
            "For 5016th iteration, the training loss is 54812100162.54826\n",
            "For 5017th iteration, the training loss is 54811720469.48025\n",
            "For 5018th iteration, the training loss is 54811341099.439865\n",
            "For 5019th iteration, the training loss is 54810961385.275764\n",
            "For 5020th iteration, the training loss is 54810581798.00687\n",
            "For 5021th iteration, the training loss is 54810202738.924355\n",
            "For 5022th iteration, the training loss is 54809823068.65873\n",
            "For 5023th iteration, the training loss is 54809444335.87728\n",
            "For 5024th iteration, the training loss is 54809064905.751335\n",
            "For 5025th iteration, the training loss is 54808685221.89228\n",
            "For 5026th iteration, the training loss is 54808306545.96188\n",
            "For 5027th iteration, the training loss is 54807927168.466064\n",
            "For 5028th iteration, the training loss is 54807548197.058266\n",
            "For 5029th iteration, the training loss is 54807169523.4979\n",
            "For 5030th iteration, the training loss is 54806790455.518585\n",
            "For 5031th iteration, the training loss is 54806411789.9308\n",
            "For 5032th iteration, the training loss is 54806033540.92533\n",
            "For 5033th iteration, the training loss is 54805654365.61141\n",
            "For 5034th iteration, the training loss is 54805275835.31639\n",
            "For 5035th iteration, the training loss is 54804897597.96195\n",
            "For 5036th iteration, the training loss is 54804518965.202576\n",
            "For 5037th iteration, the training loss is 54804141163.8744\n",
            "For 5038th iteration, the training loss is 54803763546.727776\n",
            "For 5039th iteration, the training loss is 54803385592.87687\n",
            "For 5040th iteration, the training loss is 54803007016.38287\n",
            "For 5041th iteration, the training loss is 54802629511.334015\n",
            "For 5042th iteration, the training loss is 54802252188.278015\n",
            "For 5043th iteration, the training loss is 54801874429.19006\n",
            "For 5044th iteration, the training loss is 54801496624.59539\n",
            "For 5045th iteration, the training loss is 54801118902.036385\n",
            "For 5046th iteration, the training loss is 54800741726.9092\n",
            "For 5047th iteration, the training loss is 54800363906.48188\n",
            "For 5048th iteration, the training loss is 54799987015.34354\n",
            "For 5049th iteration, the training loss is 54799609424.32972\n",
            "For 5050th iteration, the training loss is 54799231552.03144\n",
            "For 5051th iteration, the training loss is 54798854691.36221\n",
            "For 5052th iteration, the training loss is 54798477445.007935\n",
            "For 5053th iteration, the training loss is 54798100384.11611\n",
            "For 5054th iteration, the training loss is 54797723190.40425\n",
            "For 5055th iteration, the training loss is 54797346280.31122\n",
            "For 5056th iteration, the training loss is 54796969908.935\n",
            "For 5057th iteration, the training loss is 54796593032.22563\n",
            "For 5058th iteration, the training loss is 54796216828.47215\n",
            "For 5059th iteration, the training loss is 54795839972.91025\n",
            "For 5060th iteration, the training loss is 54795463227.22203\n",
            "For 5061th iteration, the training loss is 54795086767.992\n",
            "For 5062th iteration, the training loss is 54794710833.97265\n",
            "For 5063th iteration, the training loss is 54794334413.21848\n",
            "For 5064th iteration, the training loss is 54793958634.207\n",
            "For 5065th iteration, the training loss is 54793582501.05897\n",
            "For 5066th iteration, the training loss is 54793205855.15806\n",
            "For 5067th iteration, the training loss is 54792830054.06105\n",
            "For 5068th iteration, the training loss is 54792453853.14703\n",
            "For 5069th iteration, the training loss is 54792078029.44871\n",
            "For 5070th iteration, the training loss is 54791702459.335686\n",
            "For 5071th iteration, the training loss is 54791326493.4015\n",
            "For 5072th iteration, the training loss is 54790950902.57377\n",
            "For 5073th iteration, the training loss is 54790575702.02042\n",
            "For 5074th iteration, the training loss is 54790199780.9001\n",
            "For 5075th iteration, the training loss is 54789824236.75359\n",
            "For 5076th iteration, the training loss is 54789449488.46336\n",
            "For 5077th iteration, the training loss is 54789074375.41103\n",
            "For 5078th iteration, the training loss is 54788698850.88278\n",
            "For 5079th iteration, the training loss is 54788323698.751495\n",
            "For 5080th iteration, the training loss is 54787948806.76979\n",
            "For 5081th iteration, the training loss is 54787573504.79953\n",
            "For 5082th iteration, the training loss is 54787198573.37907\n",
            "For 5083th iteration, the training loss is 54786823801.55195\n",
            "For 5084th iteration, the training loss is 54786448637.56271\n",
            "For 5085th iteration, the training loss is 54786073844.01313\n",
            "For 5086th iteration, the training loss is 54785699324.103935\n",
            "For 5087th iteration, the training loss is 54785324377.62866\n",
            "For 5088th iteration, the training loss is 54784949799.8521\n",
            "For 5089th iteration, the training loss is 54784575499.768265\n",
            "For 5090th iteration, the training loss is 54784201060.69512\n",
            "For 5091th iteration, the training loss is 54783826687.38298\n",
            "For 5092th iteration, the training loss is 54783452806.2641\n",
            "For 5093th iteration, the training loss is 54783078502.76736\n",
            "For 5094th iteration, the training loss is 54782704924.83215\n",
            "For 5095th iteration, the training loss is 54782330667.47743\n",
            "For 5096th iteration, the training loss is 54781957175.61173\n",
            "For 5097th iteration, the training loss is 54781583197.5733\n",
            "For 5098th iteration, the training loss is 54781210003.55572\n",
            "For 5099th iteration, the training loss is 54780836070.32325\n",
            "For 5100th iteration, the training loss is 54780461826.21529\n",
            "For 5101th iteration, the training loss is 54780088432.03894\n",
            "For 5102th iteration, the training loss is 54779714612.48928\n",
            "For 5103th iteration, the training loss is 54779341151.76677\n",
            "For 5104th iteration, the training loss is 54778967950.830956\n",
            "For 5105th iteration, the training loss is 54778594318.88768\n",
            "For 5106th iteration, the training loss is 54778221044.658035\n",
            "For 5107th iteration, the training loss is 54777848542.72765\n",
            "For 5108th iteration, the training loss is 54777475807.87181\n",
            "For 5109th iteration, the training loss is 54777102861.623085\n",
            "For 5110th iteration, the training loss is 54776730023.92581\n",
            "For 5111th iteration, the training loss is 54776356850.35029\n",
            "For 5112th iteration, the training loss is 54775984450.18645\n",
            "For 5113th iteration, the training loss is 54775611867.501335\n",
            "For 5114th iteration, the training loss is 54775239338.264275\n",
            "For 5115th iteration, the training loss is 54774866166.56049\n",
            "For 5116th iteration, the training loss is 54774494219.02921\n",
            "For 5117th iteration, the training loss is 54774122412.21547\n",
            "For 5118th iteration, the training loss is 54773750229.568726\n",
            "For 5119th iteration, the training loss is 54773377613.912285\n",
            "For 5120th iteration, the training loss is 54773005347.7031\n",
            "For 5121th iteration, the training loss is 54772633844.85074\n",
            "For 5122th iteration, the training loss is 54772261927.69275\n",
            "For 5123th iteration, the training loss is 54771889350.5467\n",
            "For 5124th iteration, the training loss is 54771517796.99096\n",
            "For 5125th iteration, the training loss is 54771146383.59268\n",
            "For 5126th iteration, the training loss is 54770775108.55022\n",
            "For 5127th iteration, the training loss is 54770403859.966965\n",
            "For 5128th iteration, the training loss is 54770032782.3621\n",
            "For 5129th iteration, the training loss is 54769661839.306\n",
            "For 5130th iteration, the training loss is 54769290526.24068\n",
            "For 5131th iteration, the training loss is 54768919052.155174\n",
            "For 5132th iteration, the training loss is 54768547646.40745\n",
            "For 5133th iteration, the training loss is 54768177017.74728\n",
            "For 5134th iteration, the training loss is 54767805779.063484\n",
            "For 5135th iteration, the training loss is 54767434128.71704\n",
            "For 5136th iteration, the training loss is 54767063426.6043\n",
            "For 5137th iteration, the training loss is 54766692289.24657\n",
            "For 5138th iteration, the training loss is 54766321449.52081\n",
            "For 5139th iteration, the training loss is 54765950189.723816\n",
            "For 5140th iteration, the training loss is 54765579828.22723\n",
            "For 5141th iteration, the training loss is 54765209280.31011\n",
            "For 5142th iteration, the training loss is 54764838673.70737\n",
            "For 5143th iteration, the training loss is 54764467660.371\n",
            "For 5144th iteration, the training loss is 54764097560.99825\n",
            "For 5145th iteration, the training loss is 54763727258.002235\n",
            "For 5146th iteration, the training loss is 54763357016.45933\n",
            "For 5147th iteration, the training loss is 54762986286.2499\n",
            "For 5148th iteration, the training loss is 54762616469.06582\n",
            "For 5149th iteration, the training loss is 54762246443.88975\n",
            "For 5150th iteration, the training loss is 54761876387.690285\n",
            "For 5151th iteration, the training loss is 54761506329.79239\n",
            "For 5152th iteration, the training loss is 54761136460.14514\n",
            "For 5153th iteration, the training loss is 54760767077.104774\n",
            "For 5154th iteration, the training loss is 54760397193.06897\n",
            "For 5155th iteration, the training loss is 54760028012.02626\n",
            "For 5156th iteration, the training loss is 54759658332.54594\n",
            "For 5157th iteration, the training loss is 54759289240.559265\n",
            "For 5158th iteration, the training loss is 54758919655.7318\n",
            "For 5159th iteration, the training loss is 54758550758.17296\n",
            "For 5160th iteration, the training loss is 54758181463.22498\n",
            "For 5161th iteration, the training loss is 54757812034.7545\n",
            "For 5162th iteration, the training loss is 54757442957.347176\n",
            "For 5163th iteration, the training loss is 54757073487.12634\n",
            "For 5164th iteration, the training loss is 54756704968.86702\n",
            "For 5165th iteration, the training loss is 54756336567.48143\n",
            "For 5166th iteration, the training loss is 54755968281.623985\n",
            "For 5167th iteration, the training loss is 54755599605.427666\n",
            "For 5168th iteration, the training loss is 54755230465.623344\n",
            "For 5169th iteration, the training loss is 54754861647.66593\n",
            "For 5170th iteration, the training loss is 54754493572.90252\n",
            "For 5171th iteration, the training loss is 54754125611.79871\n",
            "For 5172th iteration, the training loss is 54753757763.07114\n",
            "For 5173th iteration, the training loss is 54753389520.53892\n",
            "For 5174th iteration, the training loss is 54753020813.64795\n",
            "For 5175th iteration, the training loss is 54752652425.14104\n",
            "For 5176th iteration, the training loss is 54752284775.88062\n",
            "For 5177th iteration, the training loss is 54751917237.40683\n",
            "For 5178th iteration, the training loss is 54751549808.49173\n",
            "For 5179th iteration, the training loss is 54751182487.93115\n",
            "For 5180th iteration, the training loss is 54750814670.90595\n",
            "For 5181th iteration, the training loss is 54750446731.08358\n",
            "For 5182th iteration, the training loss is 54750079003.00978\n",
            "For 5183th iteration, the training loss is 54749715344.21027\n",
            "For 5184th iteration, the training loss is 54749352322.5219\n",
            "For 5185th iteration, the training loss is 54748988833.71633\n",
            "For 5186th iteration, the training loss is 54748625657.01656\n",
            "For 5187th iteration, the training loss is 54748263212.4325\n",
            "For 5188th iteration, the training loss is 54747900873.25576\n",
            "For 5189th iteration, the training loss is 54747538638.34315\n",
            "For 5190th iteration, the training loss is 54747176506.57345\n",
            "For 5191th iteration, the training loss is 54746813981.79761\n",
            "For 5192th iteration, the training loss is 54746451256.87201\n",
            "For 5193th iteration, the training loss is 54746089052.07858\n",
            "For 5194th iteration, the training loss is 54745726206.51606\n",
            "For 5195th iteration, the training loss is 54745364123.86195\n",
            "For 5196th iteration, the training loss is 54745001769.9207\n",
            "For 5197th iteration, the training loss is 54744639891.860634\n",
            "For 5198th iteration, the training loss is 54744277780.4352\n",
            "For 5199th iteration, the training loss is 54743916008.5834\n",
            "For 5200th iteration, the training loss is 54743553826.21777\n",
            "For 5201th iteration, the training loss is 54743192316.00965\n",
            "For 5202th iteration, the training loss is 54742830556.80323\n",
            "For 5203th iteration, the training loss is 54742468805.80255\n",
            "For 5204th iteration, the training loss is 54742106606.393585\n",
            "For 5205th iteration, the training loss is 54741745279.80538\n",
            "For 5206th iteration, the training loss is 54741383712.660576\n",
            "For 5207th iteration, the training loss is 54741022487.341255\n",
            "For 5208th iteration, the training loss is 54740661056.59179\n",
            "For 5209th iteration, the training loss is 54740300062.77834\n",
            "For 5210th iteration, the training loss is 54739938857.308914\n",
            "For 5211th iteration, the training loss is 54739577919.69518\n",
            "For 5212th iteration, the training loss is 54739216331.094\n",
            "For 5213th iteration, the training loss is 54738855352.3893\n",
            "For 5214th iteration, the training loss is 54738493898.69212\n",
            "For 5215th iteration, the training loss is 54738132740.78786\n",
            "For 5216th iteration, the training loss is 54737772299.24597\n",
            "For 5217th iteration, the training loss is 54737411949.59757\n",
            "For 5218th iteration, the training loss is 54737051690.95742\n",
            "For 5219th iteration, the training loss is 54736691522.45707\n",
            "For 5220th iteration, the training loss is 54736331332.59315\n",
            "For 5221th iteration, the training loss is 54735971310.098206\n",
            "For 5222th iteration, the training loss is 54735611375.8152\n",
            "For 5223th iteration, the training loss is 54735251529.429955\n",
            "For 5224th iteration, the training loss is 54734891728.72385\n",
            "For 5225th iteration, the training loss is 54734532014.569534\n",
            "For 5226th iteration, the training loss is 54734172386.18281\n",
            "For 5227th iteration, the training loss is 54733812733.499466\n",
            "For 5228th iteration, the training loss is 54733453202.31982\n",
            "For 5229th iteration, the training loss is 54733093755.959274\n",
            "For 5230th iteration, the training loss is 54732734393.66631\n",
            "For 5231th iteration, the training loss is 54732375114.70354\n",
            "For 5232th iteration, the training loss is 54732015918.3474\n",
            "For 5233th iteration, the training loss is 54731656694.98721\n",
            "For 5234th iteration, the training loss is 54731297367.81095\n",
            "For 5235th iteration, the training loss is 54730938363.51223\n",
            "For 5236th iteration, the training loss is 54730579439.98982\n",
            "For 5237th iteration, the training loss is 54730220596.56815\n",
            "For 5238th iteration, the training loss is 54729861832.5843\n",
            "For 5239th iteration, the training loss is 54729503038.63781\n",
            "For 5240th iteration, the training loss is 54729144137.44842\n",
            "For 5241th iteration, the training loss is 54728785556.45493\n",
            "For 5242th iteration, the training loss is 54728427053.29675\n",
            "For 5243th iteration, the training loss is 54728068627.353355\n",
            "For 5244th iteration, the training loss is 54727710056.23109\n",
            "For 5245th iteration, the training loss is 54727351693.00945\n",
            "For 5246th iteration, the training loss is 54726993442.0666\n",
            "For 5247th iteration, the training loss is 54726635266.92528\n",
            "For 5248th iteration, the training loss is 54726276945.1108\n",
            "For 5249th iteration, the training loss is 54725918938.79708\n",
            "For 5250th iteration, the training loss is 54725561006.2155\n",
            "For 5251th iteration, the training loss is 54725203147.19611\n",
            "For 5252th iteration, the training loss is 54724845320.36273\n",
            "For 5253th iteration, the training loss is 54724487344.43192\n",
            "For 5254th iteration, the training loss is 54724129681.72519\n",
            "For 5255th iteration, the training loss is 54723771981.63126\n",
            "For 5256th iteration, the training loss is 54723414167.91994\n",
            "For 5257th iteration, the training loss is 54723056666.83775\n",
            "For 5258th iteration, the training loss is 54722699236.65881\n",
            "For 5259th iteration, the training loss is 54722341876.89173\n",
            "For 5260th iteration, the training loss is 54721984587.05428\n",
            "For 5261th iteration, the training loss is 54721627366.67316\n",
            "For 5262th iteration, the training loss is 54721269884.08581\n",
            "For 5263th iteration, the training loss is 54720912748.75275\n",
            "For 5264th iteration, the training loss is 54720555682.449265\n",
            "For 5265th iteration, the training loss is 54720198462.708565\n",
            "For 5266th iteration, the training loss is 54719841551.99044\n",
            "For 5267th iteration, the training loss is 54719484708.60565\n",
            "For 5268th iteration, the training loss is 54719127932.128944\n",
            "For 5269th iteration, the training loss is 54718771113.57027\n",
            "For 5270th iteration, the training loss is 54718413735.67022\n",
            "For 5271th iteration, the training loss is 54718057284.69852\n",
            "For 5272th iteration, the training loss is 54717700897.00935\n",
            "For 5273th iteration, the training loss is 54717344531.67473\n",
            "For 5274th iteration, the training loss is 54716988229.29935\n",
            "For 5275th iteration, the training loss is 54716631989.53868\n",
            "For 5276th iteration, the training loss is 54716275812.05452\n",
            "For 5277th iteration, the training loss is 54715919365.520355\n",
            "For 5278th iteration, the training loss is 54715563259.32997\n",
            "For 5279th iteration, the training loss is 54715206776.16075\n",
            "For 5280th iteration, the training loss is 54714850635.62319\n",
            "For 5281th iteration, the training loss is 54714493871.87743\n",
            "For 5282th iteration, the training loss is 54714138191.38633\n",
            "For 5283th iteration, the training loss is 54713782458.07504\n",
            "For 5284th iteration, the training loss is 54713426861.469315\n",
            "For 5285th iteration, the training loss is 54713071322.585236\n",
            "For 5286th iteration, the training loss is 54712715841.17433\n",
            "For 5287th iteration, the training loss is 54712360416.99274\n",
            "For 5288th iteration, the training loss is 54712004828.39432\n",
            "For 5289th iteration, the training loss is 54711649497.00215\n",
            "For 5290th iteration, the training loss is 54711294222.50252\n",
            "For 5291th iteration, the training loss is 54710938344.86655\n",
            "For 5292th iteration, the training loss is 54710582934.6611\n",
            "For 5293th iteration, the training loss is 54710226969.98579\n",
            "For 5294th iteration, the training loss is 54709872086.43467\n",
            "For 5295th iteration, the training loss is 54709517255.59317\n",
            "For 5296th iteration, the training loss is 54709162369.22823\n",
            "For 5297th iteration, the training loss is 54708807572.62864\n",
            "For 5298th iteration, the training loss is 54708452829.54537\n",
            "For 5299th iteration, the training loss is 54708097699.56734\n",
            "For 5300th iteration, the training loss is 54707743239.94052\n",
            "For 5301th iteration, the training loss is 54707388722.48853\n",
            "For 5302th iteration, the training loss is 54707034291.72932\n",
            "For 5303th iteration, the training loss is 54706679911.81189\n",
            "For 5304th iteration, the training loss is 54706325360.549774\n",
            "For 5305th iteration, the training loss is 54705971100.63578\n",
            "For 5306th iteration, the training loss is 54705616450.63068\n",
            "For 5307th iteration, the training loss is 54705262479.7155\n",
            "For 5308th iteration, the training loss is 54704907642.69614\n",
            "For 5309th iteration, the training loss is 54704553718.84076\n",
            "For 5310th iteration, the training loss is 54704199842.18228\n",
            "For 5311th iteration, the training loss is 54703846012.663605\n",
            "For 5312th iteration, the training loss is 54703492230.2287\n",
            "For 5313th iteration, the training loss is 54703138494.82249\n",
            "For 5314th iteration, the training loss is 54702784365.27703\n",
            "For 5315th iteration, the training loss is 54702430789.46837\n",
            "For 5316th iteration, the training loss is 54702077297.54538\n",
            "For 5317th iteration, the training loss is 54701723628.48508\n",
            "For 5318th iteration, the training loss is 54701370245.02325\n",
            "For 5319th iteration, the training loss is 54701016465.9144\n",
            "For 5320th iteration, the training loss is 54700663358.18048\n",
            "For 5321th iteration, the training loss is 54700309380.66405\n",
            "For 5322th iteration, the training loss is 54699956311.08812\n",
            "For 5323th iteration, the training loss is 54699603283.53702\n",
            "For 5324th iteration, the training loss is 54699250298.04684\n",
            "For 5325th iteration, the training loss is 54698897354.65296\n",
            "For 5326th iteration, the training loss is 54698544011.74319\n",
            "For 5327th iteration, the training loss is 54698191217.61215\n",
            "For 5328th iteration, the training loss is 54697838503.13069\n",
            "For 5329th iteration, the training loss is 54697485606.9318\n",
            "For 5330th iteration, the training loss is 54697132991.78965\n",
            "For 5331th iteration, the training loss is 54696779974.79372\n",
            "For 5332th iteration, the training loss is 54696427505.93426\n",
            "For 5333th iteration, the training loss is 54696075113.7231\n",
            "For 5334th iteration, the training loss is 54695722319.43796\n",
            "For 5335th iteration, the training loss is 54695370299.584145\n",
            "For 5336th iteration, the training loss is 54695017327.302635\n",
            "For 5337th iteration, the training loss is 54694665255.02719\n",
            "For 5338th iteration, the training loss is 54694313218.60316\n",
            "For 5339th iteration, the training loss is 54693961218.17702\n",
            "For 5340th iteration, the training loss is 54693609253.89267\n",
            "For 5341th iteration, the training loss is 54693256663.01395\n",
            "For 5342th iteration, the training loss is 54692904975.08286\n",
            "For 5343th iteration, the training loss is 54692552409.9678\n",
            "For 5344th iteration, the training loss is 54692200744.516235\n",
            "For 5345th iteration, the training loss is 54691849113.09403\n",
            "For 5346th iteration, the training loss is 54691497074.817116\n",
            "For 5347th iteration, the training loss is 54691145576.2362\n",
            "For 5348th iteration, the training loss is 54690794149.884964\n",
            "For 5349th iteration, the training loss is 54690442756.39823\n",
            "For 5350th iteration, the training loss is 54690090953.20178\n",
            "For 5351th iteration, the training loss is 54689739693.09869\n",
            "For 5352th iteration, the training loss is 54689388501.23907\n",
            "For 5353th iteration, the training loss is 54689036898.6989\n",
            "For 5354th iteration, the training loss is 54688685945.24386\n",
            "For 5355th iteration, the training loss is 54688335020.859985\n",
            "For 5356th iteration, the training loss is 54687984125.814026\n",
            "For 5357th iteration, the training loss is 54687633038.120514\n",
            "For 5358th iteration, the training loss is 54687281779.84485\n",
            "For 5359th iteration, the training loss is 54686931055.99572\n",
            "For 5360th iteration, the training loss is 54686580400.28077\n",
            "For 5361th iteration, the training loss is 54686229331.59825\n",
            "For 5362th iteration, the training loss is 54685878907.8923\n",
            "For 5363th iteration, the training loss is 54685528470.43584\n",
            "For 5364th iteration, the training loss is 54685177837.61205\n",
            "For 5365th iteration, the training loss is 54684827472.59213\n",
            "For 5366th iteration, the training loss is 54684476691.306366\n",
            "For 5367th iteration, the training loss is 54684126445.94456\n",
            "For 5368th iteration, the training loss is 54683775823.2346\n",
            "For 5369th iteration, the training loss is 54683425842.124855\n",
            "For 5370th iteration, the training loss is 54683075884.383194\n",
            "For 5371th iteration, the training loss is 54682725950.37672\n",
            "For 5372th iteration, the training loss is 54682375817.9994\n",
            "For 5373th iteration, the training loss is 54682025509.216835\n",
            "For 5374th iteration, the training loss is 54681675729.37894\n",
            "For 5375th iteration, the training loss is 54681326012.8593\n",
            "For 5376th iteration, the training loss is 54680975656.022545\n",
            "For 5377th iteration, the training loss is 54680626070.79534\n",
            "For 5378th iteration, the training loss is 54680276544.568436\n",
            "For 5379th iteration, the training loss is 54679926597.9135\n",
            "For 5380th iteration, the training loss is 54679577290.121994\n",
            "For 5381th iteration, the training loss is 54679228002.22648\n",
            "For 5382th iteration, the training loss is 54678878734.6548\n",
            "For 5383th iteration, the training loss is 54678528824.624016\n",
            "For 5384th iteration, the training loss is 54678179681.46505\n",
            "For 5385th iteration, the training loss is 54677830596.4126\n",
            "For 5386th iteration, the training loss is 54677481088.43102\n",
            "For 5387th iteration, the training loss is 54677132216.72427\n",
            "For 5388th iteration, the training loss is 54676783362.57547\n",
            "For 5389th iteration, the training loss is 54676434526.45322\n",
            "For 5390th iteration, the training loss is 54676085044.993965\n",
            "For 5391th iteration, the training loss is 54675736327.43061\n",
            "For 5392th iteration, the training loss is 54675387667.00297\n",
            "For 5393th iteration, the training loss is 54675038580.5435\n",
            "For 5394th iteration, the training loss is 54674690130.347534\n",
            "For 5395th iteration, the training loss is 54674341655.581924\n",
            "For 5396th iteration, the training loss is 54673992532.98708\n",
            "For 5397th iteration, the training loss is 54673644284.58823\n",
            "For 5398th iteration, the training loss is 54673296010.445335\n",
            "For 5399th iteration, the training loss is 54672947308.97258\n",
            "For 5400th iteration, the training loss is 54672599128.928215\n",
            "For 5401th iteration, the training loss is 54672251042.01511\n",
            "For 5402th iteration, the training loss is 54671902526.69455\n",
            "For 5403th iteration, the training loss is 54671554643.16902\n",
            "For 5404th iteration, the training loss is 54671206732.09793\n",
            "For 5405th iteration, the training loss is 54670858170.300255\n",
            "For 5406th iteration, the training loss is 54670510370.84017\n",
            "For 5407th iteration, the training loss is 54670162620.762085\n",
            "For 5408th iteration, the training loss is 54669814438.78682\n",
            "For 5409th iteration, the training loss is 54669466887.95402\n",
            "For 5410th iteration, the training loss is 54669119348.2031\n",
            "For 5411th iteration, the training loss is 54668771376.7067\n",
            "For 5412th iteration, the training loss is 54668423923.21523\n",
            "For 5413th iteration, the training loss is 54668076559.22698\n",
            "For 5414th iteration, the training loss is 54667728540.926025\n",
            "For 5415th iteration, the training loss is 54667381282.77047\n",
            "For 5416th iteration, the training loss is 54667033628.9192\n",
            "For 5417th iteration, the training loss is 54666686600.208984\n",
            "For 5418th iteration, the training loss is 54666339579.48415\n",
            "For 5419th iteration, the training loss is 54665992567.378624\n",
            "For 5420th iteration, the training loss is 54665645426.32344\n",
            "For 5421th iteration, the training loss is 54665298666.0058\n",
            "For 5422th iteration, the training loss is 54664956235.076866\n",
            "For 5423th iteration, the training loss is 54664614111.91913\n",
            "For 5424th iteration, the training loss is 54664271394.67543\n",
            "For 5425th iteration, the training loss is 54663929256.3303\n",
            "For 5426th iteration, the training loss is 54663586935.30473\n",
            "For 5427th iteration, the training loss is 54663245020.15275\n",
            "For 5428th iteration, the training loss is 54662903413.53825\n",
            "For 5429th iteration, the training loss is 54662561359.332855\n",
            "For 5430th iteration, the training loss is 54662219883.146164\n",
            "For 5431th iteration, the training loss is 54661877776.216545\n",
            "For 5432th iteration, the training loss is 54661536110.844215\n",
            "For 5433th iteration, the training loss is 54661194207.27635\n",
            "For 5434th iteration, the training loss is 54660852626.2541\n",
            "For 5435th iteration, the training loss is 54660510843.87677\n",
            "For 5436th iteration, the training loss is 54660169346.093765\n",
            "For 5437th iteration, the training loss is 54659827684.72224\n",
            "For 5438th iteration, the training loss is 54659486269.10751\n",
            "For 5439th iteration, the training loss is 54659144728.56384\n",
            "For 5440th iteration, the training loss is 54658803394.08492\n",
            "For 5441th iteration, the training loss is 54658461943.86203\n",
            "For 5442th iteration, the training loss is 54658120963.50651\n",
            "For 5443th iteration, the training loss is 54657779668.73676\n",
            "For 5444th iteration, the training loss is 54657438731.2473\n",
            "For 5445th iteration, the training loss is 54657097522.98431\n",
            "For 5446th iteration, the training loss is 54656756489.88845\n",
            "For 5447th iteration, the training loss is 54656415354.02902\n",
            "For 5448th iteration, the training loss is 54656074548.393364\n",
            "For 5449th iteration, the training loss is 54655733952.11624\n",
            "For 5450th iteration, the training loss is 54655393638.91196\n",
            "For 5451th iteration, the training loss is 54655053445.82469\n",
            "For 5452th iteration, the training loss is 54654712867.12263\n",
            "For 5453th iteration, the training loss is 54654372567.39981\n",
            "For 5454th iteration, the training loss is 54654032388.75531\n",
            "For 5455th iteration, the training loss is 54653692408.641235\n",
            "For 5456th iteration, the training loss is 54653352169.954414\n",
            "For 5457th iteration, the training loss is 54653012252.66503\n",
            "For 5458th iteration, the training loss is 54652672585.48067\n",
            "For 5459th iteration, the training loss is 54652332894.1369\n",
            "For 5460th iteration, the training loss is 54651992846.52725\n",
            "For 5461th iteration, the training loss is 54651653085.84424\n",
            "For 5462th iteration, the training loss is 54651313431.793465\n",
            "For 5463th iteration, the training loss is 54650973985.32262\n",
            "For 5464th iteration, the training loss is 54650634076.4643\n",
            "For 5465th iteration, the training loss is 54650294982.89162\n",
            "For 5466th iteration, the training loss is 54649955728.91438\n",
            "For 5467th iteration, the training loss is 54649616673.24225\n",
            "For 5468th iteration, the training loss is 54649277800.31377\n",
            "For 5469th iteration, the training loss is 54648938765.63268\n",
            "For 5470th iteration, the training loss is 54648599440.1503\n",
            "For 5471th iteration, the training loss is 54648260167.96353\n",
            "For 5472th iteration, the training loss is 54647921077.81005\n",
            "For 5473th iteration, the training loss is 54647581875.08978\n",
            "For 5474th iteration, the training loss is 54647243058.88951\n",
            "For 5475th iteration, the training loss is 54646904506.52761\n",
            "For 5476th iteration, the training loss is 54646565615.46817\n",
            "For 5477th iteration, the training loss is 54646227073.55047\n",
            "For 5478th iteration, the training loss is 54645888676.33698\n",
            "For 5479th iteration, the training loss is 54645549841.04085\n",
            "For 5480th iteration, the training loss is 54645211797.24402\n",
            "For 5481th iteration, the training loss is 54644873587.004974\n",
            "For 5482th iteration, the training loss is 54644535081.24108\n",
            "For 5483th iteration, the training loss is 54644196624.9298\n",
            "For 5484th iteration, the training loss is 54643858427.9798\n",
            "For 5485th iteration, the training loss is 54643520132.12093\n",
            "For 5486th iteration, the training loss is 54643182158.630264\n",
            "For 5487th iteration, the training loss is 54642844053.95382\n",
            "For 5488th iteration, the training loss is 54642506238.059875\n",
            "For 5489th iteration, the training loss is 54642168672.41635\n",
            "For 5490th iteration, the training loss is 54641830638.539406\n",
            "For 5491th iteration, the training loss is 54641493116.03923\n",
            "For 5492th iteration, the training loss is 54641155019.368034\n",
            "For 5493th iteration, the training loss is 54640817212.21722\n",
            "For 5494th iteration, the training loss is 54640479273.84675\n",
            "For 5495th iteration, the training loss is 54640141533.81627\n",
            "For 5496th iteration, the training loss is 54639803740.77751\n",
            "For 5497th iteration, the training loss is 54639465999.86742\n",
            "For 5498th iteration, the training loss is 54639128565.311516\n",
            "For 5499th iteration, the training loss is 54638791274.42898\n",
            "For 5500th iteration, the training loss is 54638454223.12385\n",
            "For 5501th iteration, the training loss is 54638117409.17598\n",
            "For 5502th iteration, the training loss is 54637780227.076515\n",
            "For 5503th iteration, the training loss is 54637443390.73919\n",
            "For 5504th iteration, the training loss is 54637106686.981415\n",
            "For 5505th iteration, the training loss is 54636769526.65311\n",
            "For 5506th iteration, the training loss is 54636433150.06792\n",
            "For 5507th iteration, the training loss is 54636096598.8693\n",
            "For 5508th iteration, the training loss is 54635760221.58587\n",
            "For 5509th iteration, the training loss is 54635424014.9604\n",
            "For 5510th iteration, the training loss is 54635087509.137535\n",
            "For 5511th iteration, the training loss is 54634750971.46432\n",
            "For 5512th iteration, the training loss is 54634414403.221535\n",
            "For 5513th iteration, the training loss is 54634077863.550735\n",
            "For 5514th iteration, the training loss is 54633741627.591324\n",
            "For 5515th iteration, the training loss is 54633405744.530815\n",
            "For 5516th iteration, the training loss is 54633069386.54845\n",
            "For 5517th iteration, the training loss is 54632733512.49048\n",
            "For 5518th iteration, the training loss is 54632397088.02719\n",
            "For 5519th iteration, the training loss is 54632060893.06656\n",
            "For 5520th iteration, the training loss is 54631724568.531166\n",
            "For 5521th iteration, the training loss is 54631388994.425934\n",
            "For 5522th iteration, the training loss is 54631052906.36765\n",
            "For 5523th iteration, the training loss is 54630717579.80787\n",
            "For 5524th iteration, the training loss is 54630381589.960686\n",
            "For 5525th iteration, the training loss is 54630045812.63052\n",
            "For 5526th iteration, the training loss is 54629709931.4474\n",
            "For 5527th iteration, the training loss is 54629374177.35795\n",
            "For 5528th iteration, the training loss is 54629038688.272\n",
            "For 5529th iteration, the training loss is 54628703335.42315\n",
            "For 5530th iteration, the training loss is 54628368210.025566\n",
            "For 5531th iteration, the training loss is 54628033137.797424\n",
            "For 5532th iteration, the training loss is 54627698208.219536\n",
            "For 5533th iteration, the training loss is 54627363401.0\n",
            "For 5534th iteration, the training loss is 54627028579.977264\n",
            "For 5535th iteration, the training loss is 54626693320.29845\n",
            "For 5536th iteration, the training loss is 54626358838.70015\n",
            "For 5537th iteration, the training loss is 54626024048.21453\n",
            "For 5538th iteration, the training loss is 54625689215.92658\n",
            "For 5539th iteration, the training loss is 54625354819.63872\n",
            "For 5540th iteration, the training loss is 54625020584.00675\n",
            "For 5541th iteration, the training loss is 54624686037.20766\n",
            "For 5542th iteration, the training loss is 54624351447.3369\n",
            "For 5543th iteration, the training loss is 54624017288.503975\n",
            "For 5544th iteration, the training loss is 54623683293.72874\n",
            "For 5545th iteration, the training loss is 54623348985.30055\n",
            "For 5546th iteration, the training loss is 54623014632.62263\n",
            "For 5547th iteration, the training loss is 54622680705.1043\n",
            "For 5548th iteration, the training loss is 54622346946.44319\n",
            "For 5549th iteration, the training loss is 54622012871.45147\n",
            "For 5550th iteration, the training loss is 54621678751.11642\n",
            "For 5551th iteration, the training loss is 54621345049.210724\n",
            "For 5552th iteration, the training loss is 54621011418.60612\n",
            "For 5553th iteration, the training loss is 54620677506.26755\n",
            "For 5554th iteration, the training loss is 54620344013.35173\n",
            "For 5555th iteration, the training loss is 54620010690.972565\n",
            "For 5556th iteration, the training loss is 54619677048.2893\n",
            "For 5557th iteration, the training loss is 54619343837.60303\n",
            "For 5558th iteration, the training loss is 54619010669.96737\n",
            "For 5559th iteration, the training loss is 54618677223.03676\n",
            "For 5560th iteration, the training loss is 54618344206.954834\n",
            "For 5561th iteration, the training loss is 54618011236.44178\n",
            "For 5562th iteration, the training loss is 54617677981.457085\n",
            "For 5563th iteration, the training loss is 54617345155.50391\n",
            "For 5564th iteration, the training loss is 54617012476.84097\n",
            "For 5565th iteration, the training loss is 54616679476.11709\n",
            "For 5566th iteration, the training loss is 54616346423.232834\n",
            "For 5567th iteration, the training loss is 54616013787.29817\n",
            "For 5568th iteration, the training loss is 54615681211.405\n",
            "For 5569th iteration, the training loss is 54615348345.07364\n",
            "For 5570th iteration, the training loss is 54615015481.86027\n",
            "For 5571th iteration, the training loss is 54614682815.182014\n",
            "For 5572th iteration, the training loss is 54614350206.371376\n",
            "For 5573th iteration, the training loss is 54614017861.458\n",
            "For 5574th iteration, the training loss is 54613685558.93996\n",
            "For 5575th iteration, the training loss is 54613353421.33794\n",
            "For 5576th iteration, the training loss is 54613021039.879425\n",
            "For 5577th iteration, the training loss is 54612688941.78127\n",
            "For 5578th iteration, the training loss is 54612356767.384\n",
            "For 5579th iteration, the training loss is 54612024916.866486\n",
            "For 5580th iteration, the training loss is 54611692764.905685\n",
            "For 5581th iteration, the training loss is 54611360911.23262\n",
            "For 5582th iteration, the training loss is 54611028960.37085\n",
            "For 5583th iteration, the training loss is 54610697270.05652\n",
            "For 5584th iteration, the training loss is 54610365824.9861\n",
            "For 5585th iteration, the training loss is 54610034406.0601\n",
            "For 5586th iteration, the training loss is 54609702537.072395\n",
            "For 5587th iteration, the training loss is 54609371401.27817\n",
            "For 5588th iteration, the training loss is 54609039937.731125\n",
            "For 5589th iteration, the training loss is 54608708412.30914\n",
            "For 5590th iteration, the training loss is 54608377297.59012\n",
            "For 5591th iteration, the training loss is 54608046326.93195\n",
            "For 5592th iteration, the training loss is 54607715022.89077\n",
            "For 5593th iteration, the training loss is 54607384133.72853\n",
            "For 5594th iteration, the training loss is 54607053379.50259\n",
            "For 5595th iteration, the training loss is 54606722291.65587\n",
            "For 5596th iteration, the training loss is 54606391140.58095\n",
            "For 5597th iteration, the training loss is 54606059971.70858\n",
            "For 5598th iteration, the training loss is 54605729425.935814\n",
            "For 5599th iteration, the training loss is 54605398586.954285\n",
            "For 5600th iteration, the training loss is 54605067683.37653\n",
            "For 5601th iteration, the training loss is 54604736542.66113\n",
            "For 5602th iteration, the training loss is 54604406258.57208\n",
            "For 5603th iteration, the training loss is 54604075679.55663\n",
            "For 5604th iteration, the training loss is 54603745034.38906\n",
            "For 5605th iteration, the training loss is 54603414781.16325\n",
            "For 5606th iteration, the training loss is 54603084685.06955\n",
            "For 5607th iteration, the training loss is 54602754247.58735\n",
            "For 5608th iteration, the training loss is 54602424203.79992\n",
            "For 5609th iteration, the training loss is 54602094311.70833\n",
            "For 5610th iteration, the training loss is 54601764077.4802\n",
            "For 5611th iteration, the training loss is 54601434237.91192\n",
            "For 5612th iteration, the training loss is 54601104442.62621\n",
            "For 5613th iteration, the training loss is 54600774342.36241\n",
            "For 5614th iteration, the training loss is 54600444593.20727\n",
            "For 5615th iteration, the training loss is 54600114984.37218\n",
            "For 5616th iteration, the training loss is 54599785481.02899\n",
            "For 5617th iteration, the training loss is 54599455412.92003\n",
            "For 5618th iteration, the training loss is 54599125652.35025\n",
            "For 5619th iteration, the training loss is 54598795695.7329\n",
            "For 5620th iteration, the training loss is 54598466404.189964\n",
            "For 5621th iteration, the training loss is 54598136651.40475\n",
            "For 5622th iteration, the training loss is 54597807426.28723\n",
            "For 5623th iteration, the training loss is 54597477754.4753\n",
            "For 5624th iteration, the training loss is 54597148286.56078\n",
            "For 5625th iteration, the training loss is 54596819054.6109\n",
            "For 5626th iteration, the training loss is 54596490402.74142\n",
            "For 5627th iteration, the training loss is 54596161051.034134\n",
            "For 5628th iteration, the training loss is 54595831745.13802\n",
            "For 5629th iteration, the training loss is 54595503114.53087\n",
            "For 5630th iteration, the training loss is 54595174467.34158\n",
            "For 5631th iteration, the training loss is 54594845958.23814\n",
            "For 5632th iteration, the training loss is 54594517100.8837\n",
            "For 5633th iteration, the training loss is 54594188626.60157\n",
            "For 5634th iteration, the training loss is 54593860293.388664\n",
            "For 5635th iteration, the training loss is 54593531609.999565\n",
            "For 5636th iteration, the training loss is 54593203872.50719\n",
            "For 5637th iteration, the training loss is 54592875649.49032\n",
            "For 5638th iteration, the training loss is 54592547529.87463\n",
            "For 5639th iteration, the training loss is 54592219485.835686\n",
            "For 5640th iteration, the training loss is 54591891605.28277\n",
            "For 5641th iteration, the training loss is 54591563737.248024\n",
            "For 5642th iteration, the training loss is 54591236089.20679\n",
            "For 5643th iteration, the training loss is 54590908378.14709\n",
            "For 5644th iteration, the training loss is 54590580644.2766\n",
            "For 5645th iteration, the training loss is 54590253043.381516\n",
            "For 5646th iteration, the training loss is 54589925087.821724\n",
            "For 5647th iteration, the training loss is 54589597505.46777\n",
            "For 5648th iteration, the training loss is 54589270064.04249\n",
            "For 5649th iteration, the training loss is 54588942265.3244\n",
            "For 5650th iteration, the training loss is 54588615398.45997\n",
            "For 5651th iteration, the training loss is 54588287967.11397\n",
            "For 5652th iteration, the training loss is 54587960440.567085\n",
            "For 5653th iteration, the training loss is 54587633255.7895\n",
            "For 5654th iteration, the training loss is 54587306248.681885\n",
            "For 5655th iteration, the training loss is 54586979172.18865\n",
            "For 5656th iteration, the training loss is 54586652338.37054\n",
            "For 5657th iteration, the training loss is 54586325493.36684\n",
            "For 5658th iteration, the training loss is 54585998164.927216\n",
            "For 5659th iteration, the training loss is 54585671548.659424\n",
            "For 5660th iteration, the training loss is 54585344576.18105\n",
            "For 5661th iteration, the training loss is 54585017984.76933\n",
            "For 5662th iteration, the training loss is 54584691507.37068\n",
            "For 5663th iteration, the training loss is 54584364670.23504\n",
            "For 5664th iteration, the training loss is 54584038202.804214\n",
            "For 5665th iteration, the training loss is 54583711863.78187\n",
            "For 5666th iteration, the training loss is 54583389382.93342\n",
            "For 5667th iteration, the training loss is 54583067559.12898\n",
            "For 5668th iteration, the training loss is 54582745357.84493\n",
            "For 5669th iteration, the training loss is 54582423224.171936\n",
            "For 5670th iteration, the training loss is 54582101283.66312\n",
            "For 5671th iteration, the training loss is 54581779335.4156\n",
            "For 5672th iteration, the training loss is 54581457549.00929\n",
            "For 5673th iteration, the training loss is 54581135994.30404\n",
            "For 5674th iteration, the training loss is 54580814427.611565\n",
            "For 5675th iteration, the training loss is 54580492498.290565\n",
            "For 5676th iteration, the training loss is 54580171239.44052\n",
            "For 5677th iteration, the training loss is 54579849622.010414\n",
            "For 5678th iteration, the training loss is 54579527910.48775\n",
            "For 5679th iteration, the training loss is 54579206554.736984\n",
            "For 5680th iteration, the training loss is 54578885204.969284\n",
            "For 5681th iteration, the training loss is 54578563758.75095\n",
            "For 5682th iteration, the training loss is 54578242683.195915\n",
            "For 5683th iteration, the training loss is 54577921714.15082\n",
            "For 5684th iteration, the training loss is 54577600378.34485\n",
            "For 5685th iteration, the training loss is 54577279397.76237\n",
            "For 5686th iteration, the training loss is 54576958418.54515\n",
            "For 5687th iteration, the training loss is 54576637340.8472\n",
            "For 5688th iteration, the training loss is 54576316631.97363\n",
            "For 5689th iteration, the training loss is 54575995925.64571\n",
            "For 5690th iteration, the training loss is 54575675355.93246\n",
            "For 5691th iteration, the training loss is 54575354885.35002\n",
            "For 5692th iteration, the training loss is 54575034045.805756\n",
            "For 5693th iteration, the training loss is 54574713719.549095\n",
            "For 5694th iteration, the training loss is 54574393056.05698\n",
            "For 5695th iteration, the training loss is 54574072379.25392\n",
            "For 5696th iteration, the training loss is 54573751971.06828\n",
            "For 5697th iteration, the training loss is 54573431454.81527\n",
            "For 5698th iteration, the training loss is 54573111190.33778\n",
            "For 5699th iteration, the training loss is 54572790830.9513\n",
            "For 5700th iteration, the training loss is 54572470785.149666\n",
            "For 5701th iteration, the training loss is 54572150888.01262\n",
            "For 5702th iteration, the training loss is 54571831023.13454\n",
            "For 5703th iteration, the training loss is 54571511288.04018\n",
            "For 5704th iteration, the training loss is 54571191548.43388\n",
            "For 5705th iteration, the training loss is 54570872025.48142\n",
            "For 5706th iteration, the training loss is 54570552364.4037\n",
            "For 5707th iteration, the training loss is 54570232951.89781\n",
            "For 5708th iteration, the training loss is 54569913493.33113\n",
            "For 5709th iteration, the training loss is 54569594069.56556\n",
            "For 5710th iteration, the training loss is 54569274747.91728\n",
            "For 5711th iteration, the training loss is 54568955049.16472\n",
            "For 5712th iteration, the training loss is 54568635810.24008\n",
            "For 5713th iteration, the training loss is 54568316671.3656\n",
            "For 5714th iteration, the training loss is 54567997154.4779\n",
            "For 5715th iteration, the training loss is 54567678096.22236\n",
            "For 5716th iteration, the training loss is 54567359137.0335\n",
            "For 5717th iteration, the training loss is 54567039798.78606\n",
            "For 5718th iteration, the training loss is 54566721498.47685\n",
            "For 5719th iteration, the training loss is 54566402553.28837\n",
            "For 5720th iteration, the training loss is 54566083519.81915\n",
            "For 5721th iteration, the training loss is 54565764705.8057\n",
            "For 5722th iteration, the training loss is 54565445799.96425\n",
            "For 5723th iteration, the training loss is 54565127192.48687\n",
            "For 5724th iteration, the training loss is 54564808508.35233\n",
            "For 5725th iteration, the training loss is 54564490079.115395\n",
            "For 5726th iteration, the training loss is 54564171768.95402\n",
            "For 5727th iteration, the training loss is 54563853452.815025\n",
            "For 5728th iteration, the training loss is 54563535327.58685\n",
            "For 5729th iteration, the training loss is 54563217078.91925\n",
            "For 5730th iteration, the training loss is 54562899038.34713\n",
            "For 5731th iteration, the training loss is 54562580980.50729\n",
            "For 5732th iteration, the training loss is 54562262504.12569\n",
            "For 5733th iteration, the training loss is 54561944695.13197\n",
            "For 5734th iteration, the training loss is 54561626506.51301\n",
            "For 5735th iteration, the training loss is 54561308653.866684\n",
            "For 5736th iteration, the training loss is 54560990903.555176\n",
            "For 5737th iteration, the training loss is 54560673223.88795\n",
            "For 5738th iteration, the training loss is 54560355633.377045\n",
            "For 5739th iteration, the training loss is 54560037657.12027\n",
            "For 5740th iteration, the training loss is 54559720124.70532\n",
            "For 5741th iteration, the training loss is 54559402686.522736\n",
            "For 5742th iteration, the training loss is 54559085319.57114\n",
            "For 5743th iteration, the training loss is 54558768037.38322\n",
            "For 5744th iteration, the training loss is 54558450367.93577\n",
            "For 5745th iteration, the training loss is 54558133141.39675\n",
            "For 5746th iteration, the training loss is 54557815898.82318\n",
            "For 5747th iteration, the training loss is 54557498799.4843\n",
            "For 5748th iteration, the training loss is 54557181791.60125\n",
            "For 5749th iteration, the training loss is 54556864853.63107\n",
            "For 5750th iteration, the training loss is 54556547894.935715\n",
            "For 5751th iteration, the training loss is 54556231038.80842\n",
            "For 5752th iteration, the training loss is 54555914145.70233\n",
            "For 5753th iteration, the training loss is 54555597131.4696\n",
            "For 5754th iteration, the training loss is 54555280451.7252\n",
            "For 5755th iteration, the training loss is 54554963630.26503\n",
            "For 5756th iteration, the training loss is 54554646728.21698\n",
            "For 5757th iteration, the training loss is 54554330146.38433\n",
            "For 5758th iteration, the training loss is 54554013541.2307\n",
            "For 5759th iteration, the training loss is 54553696814.2394\n",
            "For 5760th iteration, the training loss is 54553380964.04411\n",
            "For 5761th iteration, the training loss is 54553064519.60872\n",
            "For 5762th iteration, the training loss is 54552747890.31243\n",
            "For 5763th iteration, the training loss is 54552431579.8826\n",
            "For 5764th iteration, the training loss is 54552115346.337166\n",
            "For 5765th iteration, the training loss is 54551799244.03664\n",
            "For 5766th iteration, the training loss is 54551483084.301765\n",
            "For 5767th iteration, the training loss is 54551167185.40688\n",
            "For 5768th iteration, the training loss is 54550851353.61127\n",
            "For 5769th iteration, the training loss is 54550535548.10181\n",
            "For 5770th iteration, the training loss is 54550219856.52077\n",
            "For 5771th iteration, the training loss is 54549904197.45454\n",
            "For 5772th iteration, the training loss is 54549588376.743416\n",
            "For 5773th iteration, the training loss is 54549272818.45153\n",
            "For 5774th iteration, the training loss is 54548957373.06434\n",
            "For 5775th iteration, the training loss is 54548641863.09797\n",
            "For 5776th iteration, the training loss is 54548326455.46098\n",
            "For 5777th iteration, the training loss is 54548011141.87781\n",
            "For 5778th iteration, the training loss is 54547695953.6504\n",
            "For 5779th iteration, the training loss is 54547380836.32415\n",
            "For 5780th iteration, the training loss is 54547065776.00615\n",
            "For 5781th iteration, the training loss is 54546750787.21384\n",
            "For 5782th iteration, the training loss is 54546435856.80963\n",
            "For 5783th iteration, the training loss is 54546120994.9073\n",
            "For 5784th iteration, the training loss is 54545806192.33901\n",
            "For 5785th iteration, the training loss is 54545491455.74364\n",
            "For 5786th iteration, the training loss is 54545176779.00963\n",
            "For 5787th iteration, the training loss is 54544862166.19673\n",
            "For 5788th iteration, the training loss is 54544547613.368805\n",
            "For 5789th iteration, the training loss is 54544233122.87022\n",
            "For 5790th iteration, the training loss is 54543918692.09085\n",
            "For 5791th iteration, the training loss is 54543604222.65279\n",
            "For 5792th iteration, the training loss is 54543289836.58601\n",
            "For 5793th iteration, the training loss is 54542975400.3356\n",
            "For 5794th iteration, the training loss is 54542660830.33117\n",
            "For 5795th iteration, the training loss is 54542346566.9302\n",
            "For 5796th iteration, the training loss is 54542032262.752884\n",
            "For 5797th iteration, the training loss is 54541717824.659836\n",
            "For 5798th iteration, the training loss is 54541404379.35465\n",
            "For 5799th iteration, the training loss is 54541090269.96628\n",
            "For 5800th iteration, the training loss is 54540776010.85598\n",
            "For 5801th iteration, the training loss is 54540462017.3604\n",
            "For 5802th iteration, the training loss is 54540148695.49511\n",
            "For 5803th iteration, the training loss is 54539834810.541626\n",
            "For 5804th iteration, the training loss is 54539521188.9822\n",
            "For 5805th iteration, the training loss is 54539207582.15038\n",
            "For 5806th iteration, the training loss is 54538893792.746864\n",
            "For 5807th iteration, the training loss is 54538580271.07148\n",
            "For 5808th iteration, the training loss is 54538266820.48809\n",
            "For 5809th iteration, the training loss is 54537953332.285736\n",
            "For 5810th iteration, the training loss is 54537639670.33488\n",
            "For 5811th iteration, the training loss is 54537326367.98483\n",
            "For 5812th iteration, the training loss is 54537013721.69918\n",
            "For 5813th iteration, the training loss is 54536700559.34068\n",
            "For 5814th iteration, the training loss is 54536387877.83685\n",
            "For 5815th iteration, the training loss is 54536075104.90093\n",
            "For 5816th iteration, the training loss is 54535761930.95862\n",
            "For 5817th iteration, the training loss is 54535449062.161156\n",
            "For 5818th iteration, the training loss is 54535136134.26553\n",
            "For 5819th iteration, the training loss is 54534823064.794014\n",
            "For 5820th iteration, the training loss is 54534510411.99638\n",
            "For 5821th iteration, the training loss is 54534197813.92256\n",
            "For 5822th iteration, the training loss is 54533885251.572845\n",
            "For 5823th iteration, the training loss is 54533572625.303116\n",
            "For 5824th iteration, the training loss is 54533259855.92492\n",
            "For 5825th iteration, the training loss is 54532947503.2516\n",
            "For 5826th iteration, the training loss is 54532635100.254005\n",
            "For 5827th iteration, the training loss is 54532322758.43438\n",
            "For 5828th iteration, the training loss is 54532010365.099915\n",
            "For 5829th iteration, the training loss is 54531697828.16613\n",
            "For 5830th iteration, the training loss is 54531386254.507164\n",
            "For 5831th iteration, the training loss is 54531074041.52441\n",
            "For 5832th iteration, the training loss is 54530761622.8968\n",
            "For 5833th iteration, the training loss is 54530449506.516464\n",
            "For 5834th iteration, the training loss is 54530137615.79874\n",
            "For 5835th iteration, the training loss is 54529825671.44754\n",
            "For 5836th iteration, the training loss is 54529513542.01617\n",
            "For 5837th iteration, the training loss is 54529201773.51027\n",
            "For 5838th iteration, the training loss is 54528890630.29937\n",
            "For 5839th iteration, the training loss is 54528578988.84117\n",
            "For 5840th iteration, the training loss is 54528267975.74168\n",
            "For 5841th iteration, the training loss is 54527956473.64604\n",
            "For 5842th iteration, the training loss is 54527645538.259705\n",
            "For 5843th iteration, the training loss is 54527334123.61763\n",
            "For 5844th iteration, the training loss is 54527023315.24506\n",
            "For 5845th iteration, the training loss is 54526712024.87655\n",
            "For 5846th iteration, the training loss is 54526401341.14712\n",
            "For 5847th iteration, the training loss is 54526090087.7372\n",
            "For 5848th iteration, the training loss is 54525779058.3523\n",
            "For 5849th iteration, the training loss is 54525468066.2509\n",
            "For 5850th iteration, the training loss is 54525156822.91012\n",
            "For 5851th iteration, the training loss is 54524845917.40291\n",
            "For 5852th iteration, the training loss is 54524535453.806206\n",
            "For 5853th iteration, the training loss is 54524224902.903305\n",
            "For 5854th iteration, the training loss is 54523913938.84396\n",
            "For 5855th iteration, the training loss is 54523603372.53565\n",
            "For 5856th iteration, the training loss is 54523292853.49007\n",
            "For 5857th iteration, the training loss is 54522982346.471985\n",
            "For 5858th iteration, the training loss is 54522671773.4008\n",
            "For 5859th iteration, the training loss is 54522361502.83746\n",
            "For 5860th iteration, the training loss is 54522051159.45494\n",
            "For 5861th iteration, the training loss is 54521740915.12705\n",
            "For 5862th iteration, the training loss is 54521430596.95216\n",
            "For 5863th iteration, the training loss is 54521120124.28146\n",
            "For 5864th iteration, the training loss is 54520810420.58759\n",
            "For 5865th iteration, the training loss is 54520500504.729065\n",
            "For 5866th iteration, the training loss is 54520190217.97797\n",
            "For 5867th iteration, the training loss is 54519880700.88228\n",
            "For 5868th iteration, the training loss is 54519570971.79456\n",
            "For 5869th iteration, the training loss is 54519260867.35755\n",
            "For 5870th iteration, the training loss is 54518951532.06296\n",
            "For 5871th iteration, the training loss is 54518642082.6508\n",
            "For 5872th iteration, the training loss is 54518332217.411736\n",
            "For 5873th iteration, the training loss is 54518022624.2019\n",
            "For 5874th iteration, the training loss is 54517712964.51204\n",
            "For 5875th iteration, the training loss is 54517403595.04272\n",
            "For 5876th iteration, the training loss is 54517094263.82833\n",
            "For 5877th iteration, the training loss is 54516784941.62593\n",
            "For 5878th iteration, the training loss is 54516475434.80982\n",
            "For 5879th iteration, the training loss is 54516166299.12043\n",
            "For 5880th iteration, the training loss is 54515857100.4047\n",
            "For 5881th iteration, the training loss is 54515548627.69096\n",
            "For 5882th iteration, the training loss is 54515239473.520226\n",
            "For 5883th iteration, the training loss is 54514930105.74794\n",
            "For 5884th iteration, the training loss is 54514621123.316864\n",
            "For 5885th iteration, the training loss is 54514312644.63805\n",
            "For 5886th iteration, the training loss is 54514003729.57125\n",
            "For 5887th iteration, the training loss is 54513695121.92185\n",
            "For 5888th iteration, the training loss is 54513386321.85211\n",
            "For 5889th iteration, the training loss is 54513077658.88414\n",
            "For 5890th iteration, the training loss is 54512768957.48367\n",
            "For 5891th iteration, the training loss is 54512460625.95903\n",
            "For 5892th iteration, the training loss is 54512151609.06525\n",
            "For 5893th iteration, the training loss is 54511843295.0438\n",
            "For 5894th iteration, the training loss is 54511534903.381805\n",
            "For 5895th iteration, the training loss is 54511226775.810036\n",
            "For 5896th iteration, the training loss is 54510918503.94427\n",
            "For 5897th iteration, the training loss is 54510610395.26611\n",
            "For 5898th iteration, the training loss is 54510302323.667336\n",
            "For 5899th iteration, the training loss is 54509994551.45143\n",
            "For 5900th iteration, the training loss is 54509686596.839935\n",
            "For 5901th iteration, the training loss is 54509378875.85785\n",
            "For 5902th iteration, the training loss is 54509071038.76324\n",
            "For 5903th iteration, the training loss is 54508762900.8148\n",
            "For 5904th iteration, the training loss is 54508455152.40741\n",
            "For 5905th iteration, the training loss is 54508147850.36467\n",
            "For 5906th iteration, the training loss is 54507840098.74678\n",
            "For 5907th iteration, the training loss is 54507532862.67225\n",
            "For 5908th iteration, the training loss is 54507225205.86972\n",
            "For 5909th iteration, the training loss is 54506918035.59951\n",
            "For 5910th iteration, the training loss is 54506610879.10486\n",
            "For 5911th iteration, the training loss is 54506303298.51553\n",
            "For 5912th iteration, the training loss is 54505996344.07021\n",
            "For 5913th iteration, the training loss is 54505689291.50032\n",
            "For 5914th iteration, the training loss is 54505381809.77613\n",
            "For 5915th iteration, the training loss is 54505075240.709526\n",
            "For 5916th iteration, the training loss is 54504768123.366714\n",
            "For 5917th iteration, the training loss is 54504465047.65165\n",
            "For 5918th iteration, the training loss is 54504162123.562706\n",
            "For 5919th iteration, the training loss is 54503859710.18864\n",
            "For 5920th iteration, the training loss is 54503556873.719536\n",
            "For 5921th iteration, the training loss is 54503254513.55915\n",
            "For 5922th iteration, the training loss is 54502952165.57805\n",
            "For 5923th iteration, the training loss is 54502649389.00723\n",
            "For 5924th iteration, the training loss is 54502347363.229866\n",
            "For 5925th iteration, the training loss is 54502045096.65019\n",
            "For 5926th iteration, the training loss is 54501742440.196075\n",
            "For 5927th iteration, the training loss is 54501440694.99635\n",
            "For 5928th iteration, the training loss is 54501138313.51855\n",
            "For 5929th iteration, the training loss is 54500836456.81879\n",
            "For 5930th iteration, the training loss is 54500533767.68121\n",
            "For 5931th iteration, the training loss is 54500231623.60139\n",
            "For 5932th iteration, the training loss is 54499929554.828964\n",
            "For 5933th iteration, the training loss is 54499627548.7733\n",
            "For 5934th iteration, the training loss is 54499325595.06916\n",
            "For 5935th iteration, the training loss is 54499023924.87392\n",
            "For 5936th iteration, the training loss is 54498722131.827385\n",
            "For 5937th iteration, the training loss is 54498420682.95679\n",
            "For 5938th iteration, the training loss is 54498119038.31375\n",
            "For 5939th iteration, the training loss is 54497817571.92757\n",
            "For 5940th iteration, the training loss is 54497516039.367744\n",
            "For 5941th iteration, the training loss is 54497214775.43839\n",
            "For 5942th iteration, the training loss is 54496913320.98661\n",
            "For 5943th iteration, the training loss is 54496612106.257576\n",
            "For 5944th iteration, the training loss is 54496310716.878456\n",
            "For 5945th iteration, the training loss is 54496009642.96239\n",
            "For 5946th iteration, the training loss is 54495708411.731674\n",
            "For 5947th iteration, the training loss is 54495407383.09911\n",
            "For 5948th iteration, the training loss is 54495106264.81805\n",
            "For 5949th iteration, the training loss is 54494805339.34585\n",
            "For 5950th iteration, the training loss is 54494504367.69137\n",
            "For 5951th iteration, the training loss is 54494203631.67243\n",
            "For 5952th iteration, the training loss is 54493902772.245476\n",
            "For 5953th iteration, the training loss is 54493602164.15753\n",
            "For 5954th iteration, the training loss is 54493301381.488525\n",
            "For 5955th iteration, the training loss is 54493000807.106964\n",
            "For 5956th iteration, the training loss is 54492700088.65746\n",
            "For 5957th iteration, the training loss is 54492400103.879364\n",
            "For 5958th iteration, the training loss is 54492099518.88766\n",
            "For 5959th iteration, the training loss is 54491798758.94685\n",
            "For 5960th iteration, the training loss is 54491498332.046486\n",
            "For 5961th iteration, the training loss is 54491198324.62722\n",
            "For 5962th iteration, the training loss is 54490897874.459564\n",
            "For 5963th iteration, the training loss is 54490597879.1409\n",
            "For 5964th iteration, the training loss is 54490297894.35561\n",
            "For 5965th iteration, the training loss is 54489997471.704285\n",
            "For 5966th iteration, the training loss is 54489697935.85825\n",
            "For 5967th iteration, the training loss is 54489397829.65127\n",
            "For 5968th iteration, the training loss is 54489098012.242485\n",
            "For 5969th iteration, the training loss is 54488798247.05355\n",
            "For 5970th iteration, the training loss is 54488498850.77269\n",
            "For 5971th iteration, the training loss is 54488199300.488716\n",
            "For 5972th iteration, the training loss is 54487899311.32837\n",
            "For 5973th iteration, the training loss is 54487600216.18706\n",
            "For 5974th iteration, the training loss is 54487300531.28235\n",
            "For 5975th iteration, the training loss is 54487001146.80615\n",
            "For 5976th iteration, the training loss is 54486701802.735275\n",
            "For 5977th iteration, the training loss is 54486402455.4905\n",
            "For 5978th iteration, the training loss is 54486103110.3539\n",
            "For 5979th iteration, the training loss is 54485804256.75774\n",
            "For 5980th iteration, the training loss is 54485504879.057724\n",
            "For 5981th iteration, the training loss is 54485205962.43263\n",
            "For 5982th iteration, the training loss is 54484906837.7936\n",
            "For 5983th iteration, the training loss is 54484608271.033936\n",
            "For 5984th iteration, the training loss is 54484309148.21472\n",
            "For 5985th iteration, the training loss is 54484010860.928185\n",
            "For 5986th iteration, the training loss is 54483711910.940414\n",
            "For 5987th iteration, the training loss is 54483413401.41183\n",
            "For 5988th iteration, the training loss is 54483114859.45481\n",
            "For 5989th iteration, the training loss is 54482815873.68885\n",
            "For 5990th iteration, the training loss is 54482517780.3258\n",
            "For 5991th iteration, the training loss is 54482219093.04438\n",
            "For 5992th iteration, the training loss is 54481920693.71093\n",
            "For 5993th iteration, the training loss is 54481622329.40224\n",
            "For 5994th iteration, the training loss is 54481323948.01115\n",
            "For 5995th iteration, the training loss is 54481025439.1123\n",
            "For 5996th iteration, the training loss is 54480727174.7004\n",
            "For 5997th iteration, the training loss is 54480428780.39505\n",
            "For 5998th iteration, the training loss is 54480130631.28791\n",
            "For 5999th iteration, the training loss is 54479832481.87663\n",
            "For 6000th iteration, the training loss is 54479534949.42512\n",
            "For 6001th iteration, the training loss is 54479236738.225685\n",
            "For 6002th iteration, the training loss is 54478939026.627426\n",
            "For 6003th iteration, the training loss is 54478641105.7936\n",
            "For 6004th iteration, the training loss is 54478343724.5159\n",
            "For 6005th iteration, the training loss is 54478045817.59368\n",
            "For 6006th iteration, the training loss is 54477748400.70433\n",
            "For 6007th iteration, the training loss is 54477450940.88874\n",
            "For 6008th iteration, the training loss is 54477153033.18444\n",
            "For 6009th iteration, the training loss is 54476856003.2143\n",
            "For 6010th iteration, the training loss is 54476558309.21998\n",
            "For 6011th iteration, the training loss is 54476261084.81919\n",
            "For 6012th iteration, the training loss is 54475963677.02325\n",
            "For 6013th iteration, the training loss is 54475666781.52059\n",
            "For 6014th iteration, the training loss is 54475369375.59312\n",
            "For 6015th iteration, the training loss is 54475072436.75398\n",
            "For 6016th iteration, the training loss is 54474775465.23378\n",
            "For 6017th iteration, the training loss is 54474478041.8986\n",
            "For 6018th iteration, the training loss is 54474181478.21805\n",
            "For 6019th iteration, the training loss is 54473884377.44625\n",
            "For 6020th iteration, the training loss is 54473587764.05425\n",
            "For 6021th iteration, the training loss is 54473291099.788055\n",
            "For 6022th iteration, the training loss is 54472993984.03553\n",
            "For 6023th iteration, the training loss is 54472697736.09357\n",
            "For 6024th iteration, the training loss is 54472400847.35277\n",
            "For 6025th iteration, the training loss is 54472104457.8918\n",
            "For 6026th iteration, the training loss is 54471808038.82807\n",
            "For 6027th iteration, the training loss is 54471511164.962814\n",
            "For 6028th iteration, the training loss is 54471215136.76158\n",
            "For 6029th iteration, the training loss is 54470918487.723366\n",
            "For 6030th iteration, the training loss is 54470622363.68485\n",
            "For 6031th iteration, the training loss is 54470326215.07288\n",
            "For 6032th iteration, the training loss is 54470030048.59026\n",
            "For 6033th iteration, the training loss is 54469733864.70628\n",
            "For 6034th iteration, the training loss is 54469438112.999626\n",
            "For 6035th iteration, the training loss is 54469142084.59511\n",
            "For 6036th iteration, the training loss is 54468846111.36855\n",
            "For 6037th iteration, the training loss is 54468549994.65877\n",
            "For 6038th iteration, the training loss is 54468254103.37633\n",
            "For 6039th iteration, the training loss is 54467958073.317566\n",
            "For 6040th iteration, the training loss is 54467662631.31777\n",
            "For 6041th iteration, the training loss is 54467366929.073044\n",
            "For 6042th iteration, the training loss is 54467071601.10576\n",
            "For 6043th iteration, the training loss is 54466776112.67348\n",
            "For 6044th iteration, the training loss is 54466480599.694336\n",
            "For 6045th iteration, the training loss is 54466185069.84368\n",
            "For 6046th iteration, the training loss is 54465890132.23786\n",
            "For 6047th iteration, the training loss is 54465594520.11508\n",
            "For 6048th iteration, the training loss is 54465299489.19281\n",
            "For 6049th iteration, the training loss is 54465004080.86106\n",
            "For 6050th iteration, the training loss is 54464709523.2047\n",
            "For 6051th iteration, the training loss is 54464414269.02346\n",
            "For 6052th iteration, the training loss is 54464119423.7511\n",
            "For 6053th iteration, the training loss is 54463824535.43403\n",
            "For 6054th iteration, the training loss is 54463529626.74337\n",
            "For 6055th iteration, the training loss is 54463234690.14919\n",
            "For 6056th iteration, the training loss is 54462940354.08362\n",
            "For 6057th iteration, the training loss is 54462645429.08204\n",
            "For 6058th iteration, the training loss is 54462351379.42005\n",
            "For 6059th iteration, the training loss is 54462056581.3371\n",
            "For 6060th iteration, the training loss is 54461762177.44968\n",
            "For 6061th iteration, the training loss is 54461467733.09645\n",
            "For 6062th iteration, the training loss is 54461173260.457184\n",
            "For 6063th iteration, the training loss is 54460878629.793816\n",
            "For 6064th iteration, the training loss is 54460584217.0958\n",
            "For 6065th iteration, the training loss is 54460289655.59913\n",
            "For 6066th iteration, the training loss is 54459995669.39182\n",
            "For 6067th iteration, the training loss is 54459701519.79872\n",
            "For 6068th iteration, the training loss is 54459407331.1061\n",
            "For 6069th iteration, the training loss is 54459112991.50556\n",
            "For 6070th iteration, the training loss is 54458819224.997284\n",
            "For 6071th iteration, the training loss is 54458525294.65089\n",
            "For 6072th iteration, the training loss is 54458231323.93665\n",
            "For 6073th iteration, the training loss is 54457937201.43443\n",
            "For 6074th iteration, the training loss is 54457643648.32428\n",
            "For 6075th iteration, the training loss is 54457349833.70644\n",
            "For 6076th iteration, the training loss is 54457056535.8013\n",
            "For 6077th iteration, the training loss is 54456762608.75993\n",
            "For 6078th iteration, the training loss is 54456469125.838524\n",
            "For 6079th iteration, the training loss is 54456175630.940765\n",
            "For 6080th iteration, the training loss is 54455882455.54269\n",
            "For 6081th iteration, the training loss is 54455589103.99545\n",
            "For 6082th iteration, the training loss is 54455295713.02241\n",
            "For 6083th iteration, the training loss is 54455002163.24514\n",
            "For 6084th iteration, the training loss is 54454709182.15863\n",
            "For 6085th iteration, the training loss is 54454415935.53783\n",
            "For 6086th iteration, the training loss is 54454123341.573326\n",
            "For 6087th iteration, the training loss is 54453830015.41486\n",
            "For 6088th iteration, the training loss is 54453537639.69849\n",
            "For 6089th iteration, the training loss is 54453244510.7031\n",
            "For 6090th iteration, the training loss is 54452951753.93235\n",
            "For 6091th iteration, the training loss is 54452658962.33523\n",
            "For 6092th iteration, the training loss is 54452366125.55538\n",
            "For 6093th iteration, the training loss is 54452073129.11271\n",
            "For 6094th iteration, the training loss is 54451780826.58238\n",
            "For 6095th iteration, the training loss is 54451488308.54703\n",
            "For 6096th iteration, the training loss is 54451195321.304085\n",
            "For 6097th iteration, the training loss is 54450903130.61951\n",
            "For 6098th iteration, the training loss is 54450610429.930336\n",
            "For 6099th iteration, the training loss is 54450318246.473724\n",
            "For 6100th iteration, the training loss is 54450025958.39686\n",
            "For 6101th iteration, the training loss is 54449733625.39991\n",
            "For 6102th iteration, the training loss is 54449441128.618416\n",
            "For 6103th iteration, the training loss is 54449149321.00152\n",
            "For 6104th iteration, the training loss is 54448857196.804565\n",
            "For 6105th iteration, the training loss is 54448565437.27413\n",
            "For 6106th iteration, the training loss is 54448273486.446\n",
            "For 6107th iteration, the training loss is 54447981490.84642\n",
            "For 6108th iteration, the training loss is 54447689327.98615\n",
            "For 6109th iteration, the training loss is 54447398029.497955\n",
            "For 6110th iteration, the training loss is 54447105977.083\n",
            "For 6111th iteration, the training loss is 54446814875.333084\n",
            "For 6112th iteration, the training loss is 54446523010.56789\n",
            "For 6113th iteration, the training loss is 54446231507.356064\n",
            "For 6114th iteration, the training loss is 54445939971.836136\n",
            "For 6115th iteration, the training loss is 54445648743.3607\n",
            "For 6116th iteration, the training loss is 54445357329.80985\n",
            "For 6117th iteration, the training loss is 54445066226.396065\n",
            "For 6118th iteration, the training loss is 54444774933.2616\n",
            "For 6119th iteration, the training loss is 54444483952.72316\n",
            "For 6120th iteration, the training loss is 54444192778.51025\n",
            "For 6121th iteration, the training loss is 54443901550.68981\n",
            "For 6122th iteration, the training loss is 54443610154.88631\n",
            "For 6123th iteration, the training loss is 54443319605.81764\n",
            "For 6124th iteration, the training loss is 54443028322.9903\n",
            "For 6125th iteration, the training loss is 54442737950.27007\n",
            "For 6126th iteration, the training loss is 54442446849.90327\n",
            "For 6127th iteration, the training loss is 54442156201.07294\n",
            "For 6128th iteration, the training loss is 54441865450.50526\n",
            "For 6129th iteration, the training loss is 54441575134.15892\n",
            "For 6130th iteration, the training loss is 54441284579.539894\n",
            "For 6131th iteration, the training loss is 54440993549.3055\n",
            "For 6132th iteration, the training loss is 54440703295.377266\n",
            "For 6133th iteration, the training loss is 54440412547.08213\n",
            "For 6134th iteration, the training loss is 54440122797.82144\n",
            "For 6135th iteration, the training loss is 54439832233.4325\n",
            "For 6136th iteration, the training loss is 54439542048.424965\n",
            "For 6137th iteration, the training loss is 54439251809.91763\n",
            "For 6138th iteration, the training loss is 54438961630.36551\n",
            "For 6139th iteration, the training loss is 54438671382.31671\n",
            "For 6140th iteration, the training loss is 54438381680.335976\n",
            "For 6141th iteration, the training loss is 54438091408.213234\n",
            "For 6142th iteration, the training loss is 54437801894.91493\n",
            "For 6143th iteration, the training loss is 54437511714.97943\n",
            "For 6144th iteration, the training loss is 54437222496.11688\n",
            "For 6145th iteration, the training loss is 54436932583.4449\n",
            "For 6146th iteration, the training loss is 54436642961.38147\n",
            "For 6147th iteration, the training loss is 54436353279.40711\n",
            "For 6148th iteration, the training loss is 54436063650.94203\n",
            "For 6149th iteration, the training loss is 54435773953.84473\n",
            "For 6150th iteration, the training loss is 54435484795.04251\n",
            "For 6151th iteration, the training loss is 54435195071.559586\n",
            "For 6152th iteration, the training loss is 54434905741.683266\n",
            "For 6153th iteration, the training loss is 54434616365.07053\n",
            "For 6154th iteration, the training loss is 54434327404.34092\n",
            "For 6155th iteration, the training loss is 54434038208.75874\n",
            "For 6156th iteration, the training loss is 54433748957.565834\n",
            "For 6157th iteration, the training loss is 54433459522.0169\n",
            "For 6158th iteration, the training loss is 54433170924.80347\n",
            "For 6159th iteration, the training loss is 54432881585.34883\n",
            "For 6160th iteration, the training loss is 54432593128.958336\n",
            "For 6161th iteration, the training loss is 54432303958.12157\n",
            "For 6162th iteration, the training loss is 54432015633.48225\n",
            "For 6163th iteration, the training loss is 54431726606.26767\n",
            "For 6164th iteration, the training loss is 54431437895.43252\n",
            "For 6165th iteration, the training loss is 54431149152.09432\n",
            "For 6166th iteration, the training loss is 54430860980.12894\n",
            "For 6167th iteration, the training loss is 54430572167.75919\n",
            "For 6168th iteration, the training loss is 54430284221.57125\n",
            "For 6169th iteration, the training loss is 54429995620.78514\n",
            "For 6170th iteration, the training loss is 54429707262.9996\n",
            "For 6171th iteration, the training loss is 54429418862.59922\n",
            "For 6172th iteration, the training loss is 54429130857.81046\n",
            "For 6173th iteration, the training loss is 54428842628.19669\n",
            "For 6174th iteration, the training loss is 54428554445.16261\n",
            "For 6175th iteration, the training loss is 54428266185.86103\n",
            "For 6176th iteration, the training loss is 54427982450.34315\n",
            "For 6177th iteration, the training loss is 54427698153.80575\n",
            "For 6178th iteration, the training loss is 54427414352.948616\n",
            "For 6179th iteration, the training loss is 54427130419.77565\n",
            "For 6180th iteration, the training loss is 54426846895.45375\n",
            "For 6181th iteration, the training loss is 54426563029.91016\n",
            "For 6182th iteration, the training loss is 54426279619.0122\n",
            "For 6183th iteration, the training loss is 54425995960.83955\n",
            "For 6184th iteration, the training loss is 54425712235.18732\n",
            "For 6185th iteration, the training loss is 54425428320.202866\n",
            "For 6186th iteration, the training loss is 54425145221.35848\n",
            "For 6187th iteration, the training loss is 54424861403.54183\n",
            "For 6188th iteration, the training loss is 54424578409.30135\n",
            "For 6189th iteration, the training loss is 54424294748.732735\n",
            "For 6190th iteration, the training loss is 54424011997.35298\n",
            "For 6191th iteration, the training loss is 54423728585.13785\n",
            "For 6192th iteration, the training loss is 54423445401.722466\n",
            "For 6193th iteration, the training loss is 54423162174.951836\n",
            "For 6194th iteration, the training loss is 54422879501.741234\n",
            "For 6195th iteration, the training loss is 54422596213.15366\n",
            "For 6196th iteration, the training loss is 54422313327.538\n",
            "For 6197th iteration, the training loss is 54422030363.68252\n",
            "For 6198th iteration, the training loss is 54421747799.36304\n",
            "For 6199th iteration, the training loss is 54421464988.944084\n",
            "For 6200th iteration, the training loss is 54421182221.75824\n",
            "For 6201th iteration, the training loss is 54420899366.61605\n",
            "For 6202th iteration, the training loss is 54420617025.59622\n",
            "For 6203th iteration, the training loss is 54420334037.605515\n",
            "For 6204th iteration, the training loss is 54420052087.06435\n",
            "For 6205th iteration, the training loss is 54419769766.55233\n",
            "For 6206th iteration, the training loss is 54419487785.92286\n",
            "For 6207th iteration, the training loss is 54419205189.276825\n",
            "For 6208th iteration, the training loss is 54418923386.4181\n",
            "For 6209th iteration, the training loss is 54418640864.45649\n",
            "For 6210th iteration, the training loss is 54418359196.70563\n",
            "For 6211th iteration, the training loss is 54418076870.202065\n",
            "For 6212th iteration, the training loss is 54417794852.422585\n",
            "For 6213th iteration, the training loss is 54417512751.25798\n",
            "For 6214th iteration, the training loss is 54417231039.0265\n",
            "For 6215th iteration, the training loss is 54416949081.91944\n",
            "For 6216th iteration, the training loss is 54416667154.54443\n",
            "For 6217th iteration, the training loss is 54416385008.04361\n",
            "For 6218th iteration, the training loss is 54416103502.85497\n",
            "For 6219th iteration, the training loss is 54415821752.05842\n",
            "For 6220th iteration, the training loss is 54415540030.95458\n",
            "For 6221th iteration, the training loss is 54415258225.653915\n",
            "For 6222th iteration, the training loss is 54414976907.28426\n",
            "For 6223th iteration, the training loss is 54414695336.98479\n",
            "For 6224th iteration, the training loss is 54414413726.518875\n",
            "For 6225th iteration, the training loss is 54414131924.040886\n",
            "For 6226th iteration, the training loss is 54413850897.00747\n",
            "For 6227th iteration, the training loss is 54413569203.766235\n",
            "For 6228th iteration, the training loss is 54413288544.28705\n",
            "For 6229th iteration, the training loss is 54413007505.699135\n",
            "For 6230th iteration, the training loss is 54412726790.789024\n",
            "For 6231th iteration, the training loss is 54412445468.03809\n",
            "For 6232th iteration, the training loss is 54412165046.445435\n",
            "For 6233th iteration, the training loss is 54411884330.054924\n",
            "For 6234th iteration, the training loss is 54411603890.84627\n",
            "For 6235th iteration, the training loss is 54411322806.3397\n",
            "For 6236th iteration, the training loss is 54411042511.71333\n",
            "For 6237th iteration, the training loss is 54410761990.141335\n",
            "For 6238th iteration, the training loss is 54410481792.1364\n",
            "For 6239th iteration, the training loss is 54410200936.64145\n",
            "For 6240th iteration, the training loss is 54409920877.0879\n",
            "For 6241th iteration, the training loss is 54409640510.283516\n",
            "For 6242th iteration, the training loss is 54409360564.854965\n",
            "For 6243th iteration, the training loss is 54409080418.6179\n",
            "For 6244th iteration, the training loss is 54408800554.19313\n",
            "For 6245th iteration, the training loss is 54408520052.866615\n",
            "For 6246th iteration, the training loss is 54408239815.51389\n",
            "For 6247th iteration, the training loss is 54407959506.017265\n",
            "For 6248th iteration, the training loss is 54407679547.97915\n",
            "For 6249th iteration, the training loss is 54407399364.24669\n",
            "For 6250th iteration, the training loss is 54407119540.831184\n",
            "For 6251th iteration, the training loss is 54406839481.04754\n",
            "For 6252th iteration, the training loss is 54406559789.58035\n",
            "For 6253th iteration, the training loss is 54406279851.99862\n",
            "For 6254th iteration, the training loss is 54406000289.9044\n",
            "For 6255th iteration, the training loss is 54405720368.1089\n",
            "For 6256th iteration, the training loss is 54405440899.521385\n",
            "For 6257th iteration, the training loss is 54405161180.01947\n",
            "For 6258th iteration, the training loss is 54404881464.56464\n",
            "For 6259th iteration, the training loss is 54404601529.86936\n",
            "For 6260th iteration, the training loss is 54404322368.5079\n",
            "For 6261th iteration, the training loss is 54404042515.5882\n",
            "For 6262th iteration, the training loss is 54403763687.40125\n",
            "For 6263th iteration, the training loss is 54403484482.197784\n",
            "For 6264th iteration, the training loss is 54403205680.68091\n",
            "For 6265th iteration, the training loss is 54402926619.66037\n",
            "For 6266th iteration, the training loss is 54402647921.91305\n",
            "For 6267th iteration, the training loss is 54402368567.33045\n",
            "For 6268th iteration, the training loss is 54402089978.336655\n",
            "For 6269th iteration, the training loss is 54401810770.92528\n",
            "For 6270th iteration, the training loss is 54401532294.9242\n",
            "For 6271th iteration, the training loss is 54401253178.850586\n",
            "For 6272th iteration, the training loss is 54400974866.9199\n",
            "For 6273th iteration, the training loss is 54400696321.30344\n",
            "For 6274th iteration, the training loss is 54400418128.133484\n",
            "For 6275th iteration, the training loss is 54400139637.70443\n",
            "For 6276th iteration, the training loss is 54399861657.58749\n",
            "For 6277th iteration, the training loss is 54399583298.49928\n",
            "For 6278th iteration, the training loss is 54399305243.23682\n",
            "For 6279th iteration, the training loss is 54399027021.46568\n",
            "For 6280th iteration, the training loss is 54398749134.43226\n",
            "For 6281th iteration, the training loss is 54398471074.5291\n",
            "For 6282th iteration, the training loss is 54398193232.904915\n",
            "For 6283th iteration, the training loss is 54397914767.72231\n",
            "For 6284th iteration, the training loss is 54397637077.11084\n",
            "For 6285th iteration, the training loss is 54397358733.41103\n",
            "For 6286th iteration, the training loss is 54397081190.0547\n",
            "For 6287th iteration, the training loss is 54396802966.59866\n",
            "For 6288th iteration, the training loss is 54396525004.545555\n",
            "For 6289th iteration, the training loss is 54396246950.803185\n",
            "For 6290th iteration, the training loss is 54395969400.57755\n",
            "For 6291th iteration, the training loss is 54395691631.47094\n",
            "For 6292th iteration, the training loss is 54395413773.4023\n",
            "For 6293th iteration, the training loss is 54395135688.80211\n",
            "For 6294th iteration, the training loss is 54394858201.784256\n",
            "For 6295th iteration, the training loss is 54394580472.760216\n",
            "For 6296th iteration, the training loss is 54394303252.8701\n",
            "For 6297th iteration, the training loss is 54394025336.51906\n",
            "For 6298th iteration, the training loss is 54393748532.1031\n",
            "For 6299th iteration, the training loss is 54393471265.545166\n",
            "For 6300th iteration, the training loss is 54393194259.64429\n",
            "For 6301th iteration, the training loss is 54392916652.77939\n",
            "For 6302th iteration, the training loss is 54392639885.34932\n",
            "For 6303th iteration, the training loss is 54392362476.7897\n",
            "For 6304th iteration, the training loss is 54392085838.96194\n",
            "For 6305th iteration, the training loss is 54391808563.90707\n",
            "For 6306th iteration, the training loss is 54391531999.56292\n",
            "For 6307th iteration, the training loss is 54391254814.721695\n",
            "For 6308th iteration, the training loss is 54390978091.57478\n",
            "For 6309th iteration, the training loss is 54390701192.362526\n",
            "For 6310th iteration, the training loss is 54390424291.825935\n",
            "For 6311th iteration, the training loss is 54390147149.772575\n",
            "For 6312th iteration, the training loss is 54389870595.8643\n",
            "For 6313th iteration, the training loss is 54389593798.7291\n",
            "For 6314th iteration, the training loss is 54389317495.954124\n",
            "For 6315th iteration, the training loss is 54389040873.39968\n",
            "For 6316th iteration, the training loss is 54388764302.94602\n",
            "For 6317th iteration, the training loss is 54388487483.00432\n",
            "For 6318th iteration, the training loss is 54388211253.65173\n",
            "For 6319th iteration, the training loss is 54387934773.12026\n",
            "For 6320th iteration, the training loss is 54387658789.52988\n",
            "For 6321th iteration, the training loss is 54387382479.3332\n",
            "For 6322th iteration, the training loss is 54387106104.541985\n",
            "For 6323th iteration, the training loss is 54386829512.33039\n",
            "For 6324th iteration, the training loss is 54386553637.35531\n",
            "For 6325th iteration, the training loss is 54386277570.44648\n",
            "For 6326th iteration, the training loss is 54386001509.5523\n",
            "For 6327th iteration, the training loss is 54385725195.79688\n",
            "For 6328th iteration, the training loss is 54385449635.225914\n",
            "For 6329th iteration, the training loss is 54385173367.36796\n",
            "For 6330th iteration, the training loss is 54384898068.9354\n",
            "For 6331th iteration, the training loss is 54384622424.48344\n",
            "For 6332th iteration, the training loss is 54384347077.210915\n",
            "For 6333th iteration, the training loss is 54384071557.65753\n",
            "For 6334th iteration, the training loss is 54383796366.97134\n",
            "For 6335th iteration, the training loss is 54383521037.63208\n",
            "For 6336th iteration, the training loss is 54383246100.88139\n",
            "For 6337th iteration, the training loss is 54382970842.3494\n",
            "For 6338th iteration, the training loss is 54382696050.44455\n",
            "For 6339th iteration, the training loss is 54382420978.46641\n",
            "For 6340th iteration, the training loss is 54382146160.677284\n",
            "For 6341th iteration, the training loss is 54381871134.04269\n",
            "For 6342th iteration, the training loss is 54381596418.18914\n",
            "For 6343th iteration, the training loss is 54381321531.83511\n",
            "For 6344th iteration, the training loss is 54381046915.3509\n",
            "For 6345th iteration, the training loss is 54380772171.966095\n",
            "For 6346th iteration, the training loss is 54380497798.6522\n",
            "For 6347th iteration, the training loss is 54380223157.603035\n",
            "For 6348th iteration, the training loss is 54379948751.99455\n",
            "For 6349th iteration, the training loss is 54379674154.29975\n",
            "For 6350th iteration, the training loss is 54379399839.38026\n",
            "For 6351th iteration, the training loss is 54379125309.80533\n",
            "For 6352th iteration, the training loss is 54378851127.71297\n",
            "For 6353th iteration, the training loss is 54378576780.729836\n",
            "For 6354th iteration, the training loss is 54378302684.97067\n",
            "For 6355th iteration, the training loss is 54378028456.12023\n",
            "For 6356th iteration, the training loss is 54377754505.98933\n",
            "For 6357th iteration, the training loss is 54377480416.02944\n",
            "For 6358th iteration, the training loss is 54377206694.72073\n",
            "For 6359th iteration, the training loss is 54376932633.934616\n",
            "For 6360th iteration, the training loss is 54376658751.86768\n",
            "For 6361th iteration, the training loss is 54376384377.187225\n",
            "For 6362th iteration, the training loss is 54376110711.79314\n",
            "For 6363th iteration, the training loss is 54375836441.16895\n",
            "For 6364th iteration, the training loss is 54375562577.08339\n",
            "For 6365th iteration, the training loss is 54375288553.01562\n",
            "For 6366th iteration, the training loss is 54375014849.7578\n",
            "For 6367th iteration, the training loss is 54374740885.7858\n",
            "For 6368th iteration, the training loss is 54374467388.47116\n",
            "For 6369th iteration, the training loss is 54374193558.46854\n",
            "For 6370th iteration, the training loss is 54373919793.63925\n",
            "For 6371th iteration, the training loss is 54373645775.06407\n",
            "For 6372th iteration, the training loss is 54373372475.95776\n",
            "For 6373th iteration, the training loss is 54373098853.52495\n",
            "For 6374th iteration, the training loss is 54372825248.901794\n",
            "For 6375th iteration, the training loss is 54372551399.19382\n",
            "For 6376th iteration, the training loss is 54372278249.29377\n",
            "For 6377th iteration, the training loss is 54372004891.14095\n",
            "For 6378th iteration, the training loss is 54371731512.52782\n",
            "For 6379th iteration, the training loss is 54371457880.6573\n",
            "For 6380th iteration, the training loss is 54371184954.57883\n",
            "For 6381th iteration, the training loss is 54370911711.477425\n",
            "For 6382th iteration, the training loss is 54370638847.252174\n",
            "For 6383th iteration, the training loss is 54370365705.42624\n",
            "For 6384th iteration, the training loss is 54370093034.80143\n",
            "For 6385th iteration, the training loss is 54369820026.5952\n",
            "For 6386th iteration, the training loss is 54369547409.62069\n",
            "For 6387th iteration, the training loss is 54369274498.454865\n",
            "For 6388th iteration, the training loss is 54369001901.00688\n",
            "For 6389th iteration, the training loss is 54368729039.71685\n",
            "For 6390th iteration, the training loss is 54368456627.71903\n",
            "For 6391th iteration, the training loss is 54368183898.72419\n",
            "For 6392th iteration, the training loss is 54367911542.3849\n",
            "For 6393th iteration, the training loss is 54367638907.80703\n",
            "For 6394th iteration, the training loss is 54367366734.67623\n",
            "For 6395th iteration, the training loss is 54367094231.03537\n",
            "For 6396th iteration, the training loss is 54366822107.147545\n",
            "For 6397th iteration, the training loss is 54366549693.722916\n",
            "For 6398th iteration, the training loss is 54366277750.456116\n",
            "For 6399th iteration, the training loss is 54366005558.825165\n",
            "For 6400th iteration, the training loss is 54365733243.03025\n",
            "For 6401th iteration, the training loss is 54365460689.46481\n",
            "For 6402th iteration, the training loss is 54365188803.08102\n",
            "For 6403th iteration, the training loss is 54364916633.15542\n",
            "For 6404th iteration, the training loss is 54364644970.017715\n",
            "For 6405th iteration, the training loss is 54364373065.63795\n",
            "For 6406th iteration, the training loss is 54364101388.51631\n",
            "For 6407th iteration, the training loss is 54363829447.37594\n",
            "For 6408th iteration, the training loss is 54363557949.28702\n",
            "For 6409th iteration, the training loss is 54363286130.17133\n",
            "For 6410th iteration, the training loss is 54363014675.467064\n",
            "For 6411th iteration, the training loss is 54362742943.33667\n",
            "For 6412th iteration, the training loss is 54362471655.39858\n",
            "For 6413th iteration, the training loss is 54362200147.37403\n",
            "For 6414th iteration, the training loss is 54361928931.74599\n",
            "For 6415th iteration, the training loss is 54361657424.599236\n",
            "For 6416th iteration, the training loss is 54361386373.51827\n",
            "For 6417th iteration, the training loss is 54361114983.37738\n",
            "For 6418th iteration, the training loss is 54360843966.15667\n",
            "For 6419th iteration, the training loss is 54360572658.36898\n",
            "For 6420th iteration, the training loss is 54360301801.72559\n",
            "For 6421th iteration, the training loss is 54360030704.65148\n",
            "For 6422th iteration, the training loss is 54359759824.80675\n",
            "For 6423th iteration, the training loss is 54359488684.1411\n",
            "For 6424th iteration, the training loss is 54359218093.62345\n",
            "For 6425th iteration, the training loss is 54358947481.13965\n",
            "For 6426th iteration, the training loss is 54358676954.40315\n",
            "For 6427th iteration, the training loss is 54358406138.63096\n",
            "For 6428th iteration, the training loss is 54358135652.339485\n",
            "For 6429th iteration, the training loss is 54357864865.5678\n",
            "For 6430th iteration, the training loss is 54357594532.42527\n",
            "For 6431th iteration, the training loss is 54357324232.35242\n",
            "For 6432th iteration, the training loss is 54357053894.8753\n",
            "For 6433th iteration, the training loss is 54356783354.62428\n",
            "For 6434th iteration, the training loss is 54356513123.67763\n",
            "For 6435th iteration, the training loss is 54356242610.69205\n",
            "For 6436th iteration, the training loss is 54355972525.054825\n",
            "For 6437th iteration, the training loss is 54355702118.965164\n",
            "For 6438th iteration, the training loss is 54355432225.30992\n",
            "For 6439th iteration, the training loss is 54355162452.27036\n",
            "For 6440th iteration, the training loss is 54354892707.53605\n",
            "For 6441th iteration, the training loss is 54354623016.2521\n",
            "For 6442th iteration, the training loss is 54354353273.222855\n",
            "For 6443th iteration, the training loss is 54354087554.5778\n",
            "For 6444th iteration, the training loss is 54353821891.3217\n",
            "For 6445th iteration, the training loss is 54353556196.96243\n",
            "For 6446th iteration, the training loss is 54353290579.73723\n",
            "For 6447th iteration, the training loss is 54353024669.158615\n",
            "For 6448th iteration, the training loss is 54352759075.65673\n",
            "For 6449th iteration, the training loss is 54352493183.787895\n",
            "For 6450th iteration, the training loss is 54352227726.262764\n",
            "For 6451th iteration, the training loss is 54351962314.865074\n",
            "For 6452th iteration, the training loss is 54351696963.68541\n",
            "For 6453th iteration, the training loss is 54351431332.221405\n",
            "For 6454th iteration, the training loss is 54351166004.0642\n",
            "For 6455th iteration, the training loss is 54350900389.25347\n",
            "For 6456th iteration, the training loss is 54350635190.51848\n",
            "For 6457th iteration, the training loss is 54350370143.99211\n",
            "For 6458th iteration, the training loss is 54350105000.58547\n",
            "For 6459th iteration, the training loss is 54349839559.23875\n",
            "For 6460th iteration, the training loss is 54349574590.840416\n",
            "For 6461th iteration, the training loss is 54349309759.92922\n",
            "For 6462th iteration, the training loss is 54349044969.12521\n",
            "For 6463th iteration, the training loss is 54348780244.620865\n",
            "For 6464th iteration, the training loss is 54348515437.807724\n",
            "For 6465th iteration, the training loss is 54348250410.16183\n",
            "For 6466th iteration, the training loss is 54347985680.66107\n",
            "For 6467th iteration, the training loss is 54347720664.04463\n",
            "For 6468th iteration, the training loss is 54347456054.01227\n",
            "For 6469th iteration, the training loss is 54347191506.16785\n",
            "For 6470th iteration, the training loss is 54346926987.81704\n",
            "For 6471th iteration, the training loss is 54346662215.82529\n",
            "For 6472th iteration, the training loss is 54346397879.64716\n",
            "For 6473th iteration, the training loss is 54346133569.67572\n",
            "For 6474th iteration, the training loss is 54345869321.49004\n",
            "For 6475th iteration, the training loss is 54345605163.281944\n",
            "For 6476th iteration, the training loss is 54345340891.55789\n",
            "For 6477th iteration, the training loss is 54345076423.82399\n",
            "For 6478th iteration, the training loss is 54344812391.23164\n",
            "For 6479th iteration, the training loss is 54344548382.960686\n",
            "For 6480th iteration, the training loss is 54344284433.51525\n",
            "For 6481th iteration, the training loss is 54344020573.397865\n",
            "For 6482th iteration, the training loss is 54343756595.380455\n",
            "For 6483th iteration, the training loss is 54343492422.89827\n",
            "For 6484th iteration, the training loss is 54343228679.092834\n",
            "For 6485th iteration, the training loss is 54342964964.86785\n",
            "For 6486th iteration, the training loss is 54342701299.66862\n",
            "For 6487th iteration, the training loss is 54342437729.989876\n",
            "For 6488th iteration, the training loss is 54342174031.92176\n",
            "For 6489th iteration, the training loss is 54341910146.64722\n",
            "For 6490th iteration, the training loss is 54341646678.38895\n",
            "For 6491th iteration, the training loss is 54341383350.87513\n",
            "For 6492th iteration, the training loss is 54341119991.863914\n",
            "For 6493th iteration, the training loss is 54340856723.4485\n",
            "For 6494th iteration, the training loss is 54340593326.18586\n",
            "For 6495th iteration, the training loss is 54340329739.92354\n",
            "For 6496th iteration, the training loss is 54340066567.323494\n",
            "For 6497th iteration, the training loss is 54339803433.500565\n",
            "For 6498th iteration, the training loss is 54339540330.603966\n",
            "For 6499th iteration, the training loss is 54339276959.281334\n",
            "For 6500th iteration, the training loss is 54339014011.94672\n",
            "For 6501th iteration, the training loss is 54338751190.52505\n",
            "For 6502th iteration, the training loss is 54338488217.195435\n",
            "For 6503th iteration, the training loss is 54338225041.2004\n",
            "For 6504th iteration, the training loss is 54337962284.82345\n",
            "For 6505th iteration, the training loss is 54337699556.70458\n",
            "For 6506th iteration, the training loss is 54337436863.32217\n",
            "For 6507th iteration, the training loss is 54337174270.798935\n",
            "For 6508th iteration, the training loss is 54336911529.15505\n",
            "For 6509th iteration, the training loss is 54336648612.24312\n",
            "For 6510th iteration, the training loss is 54336386084.95738\n",
            "For 6511th iteration, the training loss is 54336123706.69169\n",
            "For 6512th iteration, the training loss is 54335861318.101006\n",
            "For 6513th iteration, the training loss is 54335598923.44499\n",
            "For 6514th iteration, the training loss is 54335336573.6071\n",
            "For 6515th iteration, the training loss is 54335073968.9967\n",
            "For 6516th iteration, the training loss is 54334811762.09353\n",
            "For 6517th iteration, the training loss is 54334549600.63308\n",
            "For 6518th iteration, the training loss is 54334287322.795\n",
            "For 6519th iteration, the training loss is 54334024880.82994\n",
            "For 6520th iteration, the training loss is 54333762810.18318\n",
            "For 6521th iteration, the training loss is 54333500903.54632\n",
            "For 6522th iteration, the training loss is 54333238838.66817\n",
            "For 6523th iteration, the training loss is 54332976602.54151\n",
            "For 6524th iteration, the training loss is 54332714741.00756\n",
            "For 6525th iteration, the training loss is 54332452946.9162\n",
            "For 6526th iteration, the training loss is 54332191681.474014\n",
            "For 6527th iteration, the training loss is 54331929886.629135\n",
            "For 6528th iteration, the training loss is 54331668273.69745\n",
            "For 6529th iteration, the training loss is 54331406823.46755\n",
            "For 6530th iteration, the training loss is 54331145619.35141\n",
            "For 6531th iteration, the training loss is 54330884020.60025\n",
            "For 6532th iteration, the training loss is 54330622646.3988\n",
            "For 6533th iteration, the training loss is 54330361185.48617\n",
            "For 6534th iteration, the training loss is 54330099861.673386\n",
            "For 6535th iteration, the training loss is 54329838488.80437\n",
            "For 6536th iteration, the training loss is 54329577215.12589\n",
            "For 6537th iteration, the training loss is 54329315930.24153\n",
            "For 6538th iteration, the training loss is 54329054706.452095\n",
            "For 6539th iteration, the training loss is 54328793786.457\n",
            "For 6540th iteration, the training loss is 54328532607.658615\n",
            "For 6541th iteration, the training loss is 54328271260.30311\n",
            "For 6542th iteration, the training loss is 54328010269.80003\n",
            "For 6543th iteration, the training loss is 54327749448.36396\n",
            "For 6544th iteration, the training loss is 54327488984.99511\n",
            "For 6545th iteration, the training loss is 54327228085.90161\n",
            "For 6546th iteration, the training loss is 54326967325.42178\n",
            "For 6547th iteration, the training loss is 54326706792.06317\n",
            "For 6548th iteration, the training loss is 54326446149.8489\n",
            "For 6549th iteration, the training loss is 54326185654.53672\n",
            "For 6550th iteration, the training loss is 54325924994.131065\n",
            "For 6551th iteration, the training loss is 54325664154.98272\n",
            "For 6552th iteration, the training loss is 54325403673.62503\n",
            "For 6553th iteration, the training loss is 54325143367.19365\n",
            "For 6554th iteration, the training loss is 54324883352.6662\n",
            "For 6555th iteration, the training loss is 54324622943.947556\n",
            "For 6556th iteration, the training loss is 54324362736.096924\n",
            "For 6557th iteration, the training loss is 54324102487.728485\n",
            "For 6558th iteration, the training loss is 54323842251.57051\n",
            "For 6559th iteration, the training loss is 54323582324.029625\n",
            "For 6560th iteration, the training loss is 54323322657.0667\n",
            "For 6561th iteration, the training loss is 54323062565.56467\n",
            "For 6562th iteration, the training loss is 54322802701.201744\n",
            "For 6563th iteration, the training loss is 54322542741.36152\n",
            "For 6564th iteration, the training loss is 54322282895.695786\n",
            "For 6565th iteration, the training loss is 54322023016.67279\n",
            "For 6566th iteration, the training loss is 54321763190.57735\n",
            "For 6567th iteration, the training loss is 54321503664.019424\n",
            "For 6568th iteration, the training loss is 54321244395.61382\n",
            "For 6569th iteration, the training loss is 54320984702.86678\n",
            "For 6570th iteration, the training loss is 54320725231.07532\n",
            "For 6571th iteration, the training loss is 54320465668.409836\n",
            "For 6572th iteration, the training loss is 54320206207.270966\n",
            "For 6573th iteration, the training loss is 54319947002.74181\n",
            "For 6574th iteration, the training loss is 54319687543.132385\n",
            "For 6575th iteration, the training loss is 54319427896.24442\n",
            "For 6576th iteration, the training loss is 54319168595.018295\n",
            "For 6577th iteration, the training loss is 54318909078.74542\n",
            "For 6578th iteration, the training loss is 54318649766.448074\n",
            "For 6579th iteration, the training loss is 54318390067.25515\n",
            "For 6580th iteration, the training loss is 54318130965.81783\n",
            "For 6581th iteration, the training loss is 54317872021.63575\n",
            "For 6582th iteration, the training loss is 54317613407.83787\n",
            "For 6583th iteration, the training loss is 54317354380.26248\n",
            "For 6584th iteration, the training loss is 54317095550.704285\n",
            "For 6585th iteration, the training loss is 54316836587.49022\n",
            "For 6586th iteration, the training loss is 54316578249.35271\n",
            "For 6587th iteration, the training loss is 54316319437.76841\n",
            "For 6588th iteration, the training loss is 54316060859.71442\n",
            "For 6589th iteration, the training loss is 54315802174.62162\n",
            "For 6590th iteration, the training loss is 54315543589.14425\n",
            "For 6591th iteration, the training loss is 54315285254.45335\n",
            "For 6592th iteration, the training loss is 54315026654.43747\n",
            "For 6593th iteration, the training loss is 54314767872.14695\n",
            "For 6594th iteration, the training loss is 54314509416.752\n",
            "For 6595th iteration, the training loss is 54314250757.06628\n",
            "For 6596th iteration, the training loss is 54313992443.03453\n",
            "For 6597th iteration, the training loss is 54313734280.84291\n",
            "For 6598th iteration, the training loss is 54313476438.64087\n",
            "For 6599th iteration, the training loss is 54313218195.407326\n",
            "For 6600th iteration, the training loss is 54312960124.73323\n",
            "For 6601th iteration, the training loss is 54312702284.83968\n",
            "For 6602th iteration, the training loss is 54312444186.09559\n",
            "For 6603th iteration, the training loss is 54312185897.54597\n",
            "For 6604th iteration, the training loss is 54311927934.95482\n",
            "For 6605th iteration, the training loss is 54311670143.3307\n",
            "For 6606th iteration, the training loss is 54311412638.5471\n",
            "For 6607th iteration, the training loss is 54311154776.327515\n",
            "For 6608th iteration, the training loss is 54310897032.444435\n",
            "For 6609th iteration, the training loss is 54310639561.70927\n",
            "For 6610th iteration, the training loss is 54310382327.6672\n",
            "For 6611th iteration, the training loss is 54310124684.13815\n",
            "For 6612th iteration, the training loss is 54309867208.91665\n",
            "For 6613th iteration, the training loss is 54309609962.14149\n",
            "For 6614th iteration, the training loss is 54309352449.725845\n",
            "For 6615th iteration, the training loss is 54309094747.20726\n",
            "For 6616th iteration, the training loss is 54308837361.19425\n",
            "For 6617th iteration, the training loss is 54308579770.73378\n",
            "For 6618th iteration, the training loss is 54308322508.54205\n",
            "For 6619th iteration, the training loss is 54308065407.21894\n",
            "For 6620th iteration, the training loss is 54307808590.521614\n",
            "For 6621th iteration, the training loss is 54307551414.363884\n",
            "For 6622th iteration, the training loss is 54307294344.406815\n",
            "For 6623th iteration, the training loss is 54307037552.68965\n",
            "For 6624th iteration, the training loss is 54306780980.36405\n",
            "For 6625th iteration, the training loss is 54306524016.8046\n",
            "For 6626th iteration, the training loss is 54306267188.255585\n",
            "For 6627th iteration, the training loss is 54306010610.536316\n",
            "For 6628th iteration, the training loss is 54305754271.46655\n",
            "For 6629th iteration, the training loss is 54305497607.726364\n",
            "For 6630th iteration, the training loss is 54305241051.74547\n",
            "For 6631th iteration, the training loss is 54304984420.1346\n",
            "For 6632th iteration, the training loss is 54304728411.332436\n",
            "For 6633th iteration, the training loss is 54304471859.9548\n",
            "For 6634th iteration, the training loss is 54304215413.71931\n",
            "For 6635th iteration, the training loss is 54303959247.486465\n",
            "For 6636th iteration, the training loss is 54303702807.40225\n",
            "For 6637th iteration, the training loss is 54303446175.343216\n",
            "For 6638th iteration, the training loss is 54303189843.96138\n",
            "For 6639th iteration, the training loss is 54302933313.777664\n",
            "For 6640th iteration, the training loss is 54302677089.16854\n",
            "For 6641th iteration, the training loss is 54302420659.7539\n",
            "For 6642th iteration, the training loss is 54302164540.05851\n",
            "For 6643th iteration, the training loss is 54301908590.32978\n",
            "For 6644th iteration, the training loss is 54301652888.73167\n",
            "For 6645th iteration, the training loss is 54301396870.6114\n",
            "For 6646th iteration, the training loss is 54301141477.71651\n",
            "For 6647th iteration, the training loss is 54300885591.73296\n",
            "For 6648th iteration, the training loss is 54300629899.04354\n",
            "For 6649th iteration, the training loss is 54300374406.06249\n",
            "For 6650th iteration, the training loss is 54300118640.27807\n",
            "For 6651th iteration, the training loss is 54299862680.11567\n",
            "For 6652th iteration, the training loss is 54299607012.25024\n",
            "For 6653th iteration, the training loss is 54299351147.79124\n",
            "For 6654th iteration, the training loss is 54299095576.30942\n",
            "For 6655th iteration, the training loss is 54298840187.5213\n",
            "For 6656th iteration, the training loss is 54298585018.591064\n",
            "For 6657th iteration, the training loss is 54298329569.70104\n",
            "For 6658th iteration, the training loss is 54298074688.48845\n",
            "For 6659th iteration, the training loss is 54297819373.15988\n",
            "For 6660th iteration, the training loss is 54297564191.33123\n",
            "For 6661th iteration, the training loss is 54297309249.66404\n",
            "For 6662th iteration, the training loss is 54297054521.822075\n",
            "For 6663th iteration, the training loss is 54296799467.06592\n",
            "For 6664th iteration, the training loss is 54296544545.5382\n",
            "For 6665th iteration, the training loss is 54296289821.69409\n",
            "For 6666th iteration, the training loss is 54296035343.54508\n",
            "For 6667th iteration, the training loss is 54295780519.372284\n",
            "For 6668th iteration, the training loss is 54295525791.63435\n",
            "For 6669th iteration, the training loss is 54295271263.29408\n",
            "For 6670th iteration, the training loss is 54295016975.44429\n",
            "For 6671th iteration, the training loss is 54294762346.91886\n",
            "For 6672th iteration, the training loss is 54294507804.98493\n",
            "For 6673th iteration, the training loss is 54294253469.29997\n",
            "For 6674th iteration, the training loss is 54293999364.58423\n",
            "For 6675th iteration, the training loss is 54293744930.09032\n",
            "For 6676th iteration, the training loss is 54293490566.543915\n",
            "For 6677th iteration, the training loss is 54293236420.8747\n",
            "For 6678th iteration, the training loss is 54292982492.639\n",
            "For 6679th iteration, the training loss is 54292728226.681915\n",
            "For 6680th iteration, the training loss is 54292474088.395134\n",
            "For 6681th iteration, the training loss is 54292220147.96118\n",
            "For 6682th iteration, the training loss is 54291966437.97328\n",
            "For 6683th iteration, the training loss is 54291712301.877144\n",
            "For 6684th iteration, the training loss is 54291458282.71882\n",
            "For 6685th iteration, the training loss is 54291204512.5071\n",
            "For 6686th iteration, the training loss is 54290950926.052635\n",
            "For 6687th iteration, the training loss is 54290697041.468765\n",
            "For 6688th iteration, the training loss is 54290443234.62528\n",
            "For 6689th iteration, the training loss is 54290189665.03047\n",
            "For 6690th iteration, the training loss is 54289936285.209236\n",
            "For 6691th iteration, the training loss is 54289682528.791466\n",
            "For 6692th iteration, the training loss is 54289429418.96083\n",
            "For 6693th iteration, the training loss is 54289175779.56547\n",
            "For 6694th iteration, the training loss is 54288922176.76998\n",
            "For 6695th iteration, the training loss is 54288668923.76153\n",
            "For 6696th iteration, the training loss is 54288415374.39861\n",
            "For 6697th iteration, the training loss is 54288161503.04104\n",
            "For 6698th iteration, the training loss is 54287908028.8136\n",
            "For 6699th iteration, the training loss is 54287654652.1517\n",
            "For 6700th iteration, the training loss is 54287401057.902\n",
            "For 6701th iteration, the training loss is 54287148254.18031\n",
            "For 6702th iteration, the training loss is 54286895019.1988\n",
            "For 6703th iteration, the training loss is 54286641889.7106\n",
            "For 6704th iteration, the training loss is 54286389012.87078\n",
            "For 6705th iteration, the training loss is 54286136299.68362\n",
            "For 6706th iteration, the training loss is 54285883307.37058\n",
            "For 6707th iteration, the training loss is 54285630355.724144\n",
            "For 6708th iteration, the training loss is 54285377698.73743\n",
            "For 6709th iteration, the training loss is 54285124735.16866\n",
            "For 6710th iteration, the training loss is 54284871868.5204\n",
            "For 6711th iteration, the training loss is 54284619167.640564\n",
            "For 6712th iteration, the training loss is 54284366633.561935\n",
            "For 6713th iteration, the training loss is 54284114115.38703\n",
            "For 6714th iteration, the training loss is 54283861771.96565\n",
            "For 6715th iteration, the training loss is 54283609195.472115\n",
            "For 6716th iteration, the training loss is 54283357187.58584\n",
            "For 6717th iteration, the training loss is 54283104674.345184\n",
            "For 6718th iteration, the training loss is 54282856074.1467\n",
            "For 6719th iteration, the training loss is 54282607701.84236\n",
            "For 6720th iteration, the training loss is 54282359500.52335\n",
            "For 6721th iteration, the training loss is 54282111003.21809\n",
            "For 6722th iteration, the training loss is 54281862549.97817\n",
            "For 6723th iteration, the training loss is 54281614384.2817\n",
            "For 6724th iteration, the training loss is 54281366065.19371\n",
            "For 6725th iteration, the training loss is 54281117868.1527\n",
            "For 6726th iteration, the training loss is 54280869903.30455\n",
            "For 6727th iteration, the training loss is 54280621606.36823\n",
            "For 6728th iteration, the training loss is 54280373863.30722\n",
            "For 6729th iteration, the training loss is 54280125686.55258\n",
            "For 6730th iteration, the training loss is 54279877574.56789\n",
            "For 6731th iteration, the training loss is 54279629768.3103\n",
            "For 6732th iteration, the training loss is 54279381790.781364\n",
            "For 6733th iteration, the training loss is 54279133950.90403\n",
            "For 6734th iteration, the training loss is 54278886316.11663\n",
            "For 6735th iteration, the training loss is 54278638453.00663\n",
            "For 6736th iteration, the training loss is 54278391133.827515\n",
            "For 6737th iteration, the training loss is 54278143332.642525\n",
            "For 6738th iteration, the training loss is 54277895629.22901\n",
            "For 6739th iteration, the training loss is 54277648175.20264\n",
            "For 6740th iteration, the training loss is 54277400853.12424\n",
            "For 6741th iteration, the training loss is 54277153277.8591\n",
            "For 6742th iteration, the training loss is 54276906271.99315\n",
            "For 6743th iteration, the training loss is 54276658756.8662\n",
            "For 6744th iteration, the training loss is 54276411355.97754\n",
            "For 6745th iteration, the training loss is 54276164189.4502\n",
            "For 6746th iteration, the training loss is 54275917160.99072\n",
            "For 6747th iteration, the training loss is 54275669869.22011\n",
            "For 6748th iteration, the training loss is 54275423154.12849\n",
            "For 6749th iteration, the training loss is 54275175922.46235\n",
            "For 6750th iteration, the training loss is 54274928805.05671\n",
            "For 6751th iteration, the training loss is 54274681919.37194\n",
            "For 6752th iteration, the training loss is 54274435167.4537\n",
            "For 6753th iteration, the training loss is 54274188155.31624\n",
            "For 6754th iteration, the training loss is 54273941710.82574\n",
            "For 6755th iteration, the training loss is 54273694760.3284\n",
            "For 6756th iteration, the training loss is 54273447768.96884\n",
            "For 6757th iteration, the training loss is 54273201162.342865\n",
            "For 6758th iteration, the training loss is 54272954352.7411\n",
            "For 6759th iteration, the training loss is 54272707704.2282\n",
            "For 6760th iteration, the training loss is 54272461208.70166\n",
            "For 6761th iteration, the training loss is 54272214802.29722\n",
            "For 6762th iteration, the training loss is 54271968540.53998\n",
            "For 6763th iteration, the training loss is 54271722000.83075\n",
            "For 6764th iteration, the training loss is 54271476038.48175\n",
            "For 6765th iteration, the training loss is 54271229555.24834\n",
            "For 6766th iteration, the training loss is 54270983174.0867\n",
            "For 6767th iteration, the training loss is 54270737031.63674\n",
            "For 6768th iteration, the training loss is 54270491002.79687\n",
            "For 6769th iteration, the training loss is 54270244732.98887\n",
            "For 6770th iteration, the training loss is 54269998989.664894\n",
            "For 6771th iteration, the training loss is 54269752781.881485\n",
            "For 6772th iteration, the training loss is 54269506623.61148\n",
            "For 6773th iteration, the training loss is 54269260768.53028\n",
            "For 6774th iteration, the training loss is 54269014707.82743\n",
            "For 6775th iteration, the training loss is 54268768805.36897\n",
            "For 6776th iteration, the training loss is 54268523046.04576\n",
            "For 6777th iteration, the training loss is 54268277379.183464\n",
            "For 6778th iteration, the training loss is 54268031839.279434\n",
            "For 6779th iteration, the training loss is 54267786038.054634\n",
            "For 6780th iteration, the training loss is 54267540778.36733\n",
            "For 6781th iteration, the training loss is 54267295033.538795\n",
            "For 6782th iteration, the training loss is 54267049346.43237\n",
            "For 6783th iteration, the training loss is 54266803956.55251\n",
            "For 6784th iteration, the training loss is 54266558356.75288\n",
            "For 6785th iteration, the training loss is 54266312916.2221\n",
            "For 6786th iteration, the training loss is 54266067609.132034\n",
            "For 6787th iteration, the training loss is 54265822400.37003\n",
            "For 6788th iteration, the training loss is 54265577304.06952\n",
            "For 6789th iteration, the training loss is 54265331894.26776\n",
            "For 6790th iteration, the training loss is 54265087378.35979\n",
            "For 6791th iteration, the training loss is 54264841931.304756\n",
            "For 6792th iteration, the training loss is 54264597037.23838\n",
            "For 6793th iteration, the training loss is 54264351957.9014\n",
            "For 6794th iteration, the training loss is 54264106867.6471\n",
            "For 6795th iteration, the training loss is 54263862004.77427\n",
            "For 6796th iteration, the training loss is 54263617405.26193\n",
            "For 6797th iteration, the training loss is 54263372465.74091\n",
            "For 6798th iteration, the training loss is 54263127552.787636\n",
            "For 6799th iteration, the training loss is 54262882919.870514\n",
            "For 6800th iteration, the training loss is 54262638076.10322\n",
            "For 6801th iteration, the training loss is 54262393228.74523\n",
            "For 6802th iteration, the training loss is 54262148865.740616\n",
            "For 6803th iteration, the training loss is 54261904121.4107\n",
            "For 6804th iteration, the training loss is 54261659918.53896\n",
            "For 6805th iteration, the training loss is 54261415287.135315\n",
            "For 6806th iteration, the training loss is 54261171223.15721\n",
            "For 6807th iteration, the training loss is 54260926778.40156\n",
            "For 6808th iteration, the training loss is 54260682306.28702\n",
            "For 6809th iteration, the training loss is 54260438119.185295\n",
            "For 6810th iteration, the training loss is 54260193709.13211\n",
            "For 6811th iteration, the training loss is 54259949388.35892\n",
            "For 6812th iteration, the training loss is 54259705056.79862\n",
            "For 6813th iteration, the training loss is 54259460734.76145\n",
            "For 6814th iteration, the training loss is 54259216869.4986\n",
            "For 6815th iteration, the training loss is 54258972723.84679\n",
            "For 6816th iteration, the training loss is 54258729109.33012\n",
            "For 6817th iteration, the training loss is 54258485018.87988\n",
            "For 6818th iteration, the training loss is 54258241529.53769\n",
            "For 6819th iteration, the training loss is 54257997537.95215\n",
            "For 6820th iteration, the training loss is 54257753444.033936\n",
            "For 6821th iteration, the training loss is 54257509759.19952\n",
            "For 6822th iteration, the training loss is 54257266323.25215\n",
            "For 6823th iteration, the training loss is 54257022553.29822\n",
            "For 6824th iteration, the training loss is 54256778787.651726\n",
            "For 6825th iteration, the training loss is 54256535314.000916\n",
            "For 6826th iteration, the training loss is 54256291601.11857\n",
            "For 6827th iteration, the training loss is 54256047987.90695\n",
            "For 6828th iteration, the training loss is 54255804343.327515\n",
            "For 6829th iteration, the training loss is 54255560807.27603\n",
            "For 6830th iteration, the training loss is 54255317749.1135\n",
            "For 6831th iteration, the training loss is 54255074361.80338\n",
            "For 6832th iteration, the training loss is 54254831497.1243\n",
            "For 6833th iteration, the training loss is 54254588177.12795\n",
            "For 6834th iteration, the training loss is 54254344928.86185\n",
            "For 6835th iteration, the training loss is 54254101882.930405\n",
            "For 6836th iteration, the training loss is 54253859088.33327\n",
            "For 6837th iteration, the training loss is 54253615951.039116\n",
            "For 6838th iteration, the training loss is 54253372815.70076\n",
            "For 6839th iteration, the training loss is 54253129970.53667\n",
            "For 6840th iteration, the training loss is 54252886879.183815\n",
            "For 6841th iteration, the training loss is 54252644176.00048\n",
            "For 6842th iteration, the training loss is 54252401421.894264\n",
            "For 6843th iteration, the training loss is 54252158719.30227\n",
            "For 6844th iteration, the training loss is 54251916236.905556\n",
            "For 6845th iteration, the training loss is 54251673383.943474\n",
            "For 6846th iteration, the training loss is 54251431434.23994\n",
            "For 6847th iteration, the training loss is 54251188538.833916\n",
            "For 6848th iteration, the training loss is 54250946372.741714\n",
            "For 6849th iteration, the training loss is 54250703761.889465\n",
            "For 6850th iteration, the training loss is 54250461155.98705\n",
            "For 6851th iteration, the training loss is 54250218846.88584\n",
            "For 6852th iteration, the training loss is 54249976578.37632\n",
            "For 6853th iteration, the training loss is 54249734385.22675\n",
            "For 6854th iteration, the training loss is 54249492268.84505\n",
            "For 6855th iteration, the training loss is 54249250190.1106\n",
            "For 6856th iteration, the training loss is 54249008221.86567\n",
            "For 6857th iteration, the training loss is 54248765992.4575\n",
            "For 6858th iteration, the training loss is 54248524642.246025\n",
            "For 6859th iteration, the training loss is 54248282312.35915\n",
            "For 6860th iteration, the training loss is 54248040730.88262\n",
            "For 6861th iteration, the training loss is 54247798774.2053\n",
            "For 6862th iteration, the training loss is 54247556670.66405\n",
            "For 6863th iteration, the training loss is 54247314856.342766\n",
            "For 6864th iteration, the training loss is 54247073185.31413\n",
            "For 6865th iteration, the training loss is 54246831565.4996\n",
            "For 6866th iteration, the training loss is 54246590034.08328\n",
            "For 6867th iteration, the training loss is 54246348524.07025\n",
            "For 6868th iteration, the training loss is 54246107128.74025\n",
            "For 6869th iteration, the training loss is 54245865462.64848\n",
            "For 6870th iteration, the training loss is 54245624674.00394\n",
            "For 6871th iteration, the training loss is 54245382905.170815\n",
            "For 6872th iteration, the training loss is 54245141869.83929\n",
            "For 6873th iteration, the training loss is 54244900472.760765\n",
            "For 6874th iteration, the training loss is 54244659149.33692\n",
            "For 6875th iteration, the training loss is 54244417990.34602\n",
            "For 6876th iteration, the training loss is 54244176909.05988\n",
            "For 6877th iteration, the training loss is 54243935856.583435\n",
            "For 6878th iteration, the training loss is 54243694902.73493\n",
            "For 6879th iteration, the training loss is 54243453695.553535\n",
            "For 6880th iteration, the training loss is 54243213333.89156\n",
            "For 6881th iteration, the training loss is 54242972031.75605\n",
            "For 6882th iteration, the training loss is 54242731410.39487\n",
            "For 6883th iteration, the training loss is 54242490444.627014\n",
            "For 6884th iteration, the training loss is 54242249448.416985\n",
            "For 6885th iteration, the training loss is 54242008756.568\n",
            "For 6886th iteration, the training loss is 54241767819.19452\n",
            "For 6887th iteration, the training loss is 54241526963.79657\n",
            "For 6888th iteration, the training loss is 54241286562.331924\n",
            "For 6889th iteration, the training loss is 54241045824.80372\n",
            "For 6890th iteration, the training loss is 54240805607.6878\n",
            "For 6891th iteration, the training loss is 54240564956.5341\n",
            "For 6892th iteration, the training loss is 54240324315.45376\n",
            "For 6893th iteration, the training loss is 54240083905.79001\n",
            "For 6894th iteration, the training loss is 54239843665.82599\n",
            "For 6895th iteration, the training loss is 54239603435.60342\n",
            "For 6896th iteration, the training loss is 54239363306.76114\n",
            "For 6897th iteration, the training loss is 54239122916.97775\n",
            "For 6898th iteration, the training loss is 54238883361.22702\n",
            "For 6899th iteration, the training loss is 54238642873.41883\n",
            "For 6900th iteration, the training loss is 54238403036.737434\n",
            "For 6901th iteration, the training loss is 54238162822.35664\n",
            "For 6902th iteration, the training loss is 54237922651.24244\n",
            "For 6903th iteration, the training loss is 54237682749.01119\n",
            "For 6904th iteration, the training loss is 54237443084.0762\n",
            "For 6905th iteration, the training loss is 54237203074.734375\n",
            "For 6906th iteration, the training loss is 54236963581.459656\n",
            "For 6907th iteration, the training loss is 54236723749.420166\n",
            "For 6908th iteration, the training loss is 54236483855.977425\n",
            "For 6909th iteration, the training loss is 54236244178.19932\n",
            "For 6910th iteration, the training loss is 54236004670.44045\n",
            "For 6911th iteration, the training loss is 54235765165.53013\n",
            "For 6912th iteration, the training loss is 54235525754.89185\n",
            "For 6913th iteration, the training loss is 54235286344.40943\n",
            "For 6914th iteration, the training loss is 54235047028.9286\n",
            "For 6915th iteration, the training loss is 54234807712.1749\n",
            "For 6916th iteration, the training loss is 54234568489.959915\n",
            "For 6917th iteration, the training loss is 54234329266.262215\n",
            "For 6918th iteration, the training loss is 54234090135.49043\n",
            "For 6919th iteration, the training loss is 54233851004.20137\n",
            "For 6920th iteration, the training loss is 54233611963.116516\n",
            "For 6921th iteration, the training loss is 54233372825.44978\n",
            "For 6922th iteration, the training loss is 54233133834.88374\n",
            "For 6923th iteration, the training loss is 54232894874.40199\n",
            "For 6924th iteration, the training loss is 54232655971.512245\n",
            "For 6925th iteration, the training loss is 54232417102.10397\n",
            "For 6926th iteration, the training loss is 54232178419.250786\n",
            "For 6927th iteration, the training loss is 54231939336.1328\n",
            "For 6928th iteration, the training loss is 54231701010.45952\n",
            "For 6929th iteration, the training loss is 54231462197.40134\n",
            "For 6930th iteration, the training loss is 54231223263.582\n",
            "For 6931th iteration, the training loss is 54230984622.64246\n",
            "For 6932th iteration, the training loss is 54230746180.12483\n",
            "For 6933th iteration, the training loss is 54230507439.79635\n",
            "For 6934th iteration, the training loss is 54230269538.88129\n",
            "For 6935th iteration, the training loss is 54230030822.716194\n",
            "For 6936th iteration, the training loss is 54229792564.25304\n",
            "For 6937th iteration, the training loss is 54229554242.7722\n",
            "For 6938th iteration, the training loss is 54229315746.74055\n",
            "For 6939th iteration, the training loss is 54229077447.76359\n",
            "For 6940th iteration, the training loss is 54228839308.37434\n",
            "For 6941th iteration, the training loss is 54228601176.33635\n",
            "For 6942th iteration, the training loss is 54228363107.725235\n",
            "For 6943th iteration, the training loss is 54228125085.94427\n",
            "For 6944th iteration, the training loss is 54227886829.60107\n",
            "For 6945th iteration, the training loss is 54227648625.26738\n",
            "For 6946th iteration, the training loss is 54227410860.81136\n",
            "For 6947th iteration, the training loss is 54227172760.316895\n",
            "For 6948th iteration, the training loss is 54226935531.64843\n",
            "For 6949th iteration, the training loss is 54226697442.30185\n",
            "For 6950th iteration, the training loss is 54226459841.698784\n",
            "For 6951th iteration, the training loss is 54226222061.288414\n",
            "For 6952th iteration, the training loss is 54225984406.12054\n",
            "For 6953th iteration, the training loss is 54225746568.27341\n",
            "For 6954th iteration, the training loss is 54225509538.39365\n",
            "For 6955th iteration, the training loss is 54225271909.4276\n",
            "For 6956th iteration, the training loss is 54225034223.36685\n",
            "For 6957th iteration, the training loss is 54224796774.973785\n",
            "For 6958th iteration, the training loss is 54224559545.47777\n",
            "For 6959th iteration, the training loss is 54224321983.060524\n",
            "For 6960th iteration, the training loss is 54224084863.322235\n",
            "For 6961th iteration, the training loss is 54223847564.39857\n",
            "For 6962th iteration, the training loss is 54223610142.35585\n",
            "For 6963th iteration, the training loss is 54223372980.41335\n",
            "For 6964th iteration, the training loss is 54223135550.51951\n",
            "For 6965th iteration, the training loss is 54222898476.10056\n",
            "For 6966th iteration, the training loss is 54222661286.85398\n",
            "For 6967th iteration, the training loss is 54222424180.47709\n",
            "For 6968th iteration, the training loss is 54222187145.24767\n",
            "For 6969th iteration, the training loss is 54221950224.2609\n",
            "For 6970th iteration, the training loss is 54221713515.0793\n",
            "For 6971th iteration, the training loss is 54221476385.70428\n",
            "For 6972th iteration, the training loss is 54221240137.5112\n",
            "For 6973th iteration, the training loss is 54221003291.09853\n",
            "For 6974th iteration, the training loss is 54220766377.65853\n",
            "For 6975th iteration, the training loss is 54220529712.82249\n",
            "For 6976th iteration, the training loss is 54220293241.390724\n",
            "For 6977th iteration, the training loss is 54220056588.9229\n",
            "For 6978th iteration, the training loss is 54219820583.52022\n",
            "For 6979th iteration, the training loss is 54219584004.82812\n",
            "For 6980th iteration, the training loss is 54219347334.40887\n",
            "For 6981th iteration, the training loss is 54219110926.78857\n",
            "For 6982th iteration, the training loss is 54218874694.39835\n",
            "For 6983th iteration, the training loss is 54218638179.79378\n",
            "For 6984th iteration, the training loss is 54218402432.732216\n",
            "For 6985th iteration, the training loss is 54218166119.33195\n",
            "For 6986th iteration, the training loss is 54217929704.2453\n",
            "For 6987th iteration, the training loss is 54217693556.88096\n",
            "For 6988th iteration, the training loss is 54217457573.868416\n",
            "For 6989th iteration, the training loss is 54217221690.642715\n",
            "For 6990th iteration, the training loss is 54216985715.13662\n",
            "For 6991th iteration, the training loss is 54216749801.54796\n",
            "For 6992th iteration, the training loss is 54216513614.408\n",
            "For 6993th iteration, the training loss is 54216277775.47579\n",
            "For 6994th iteration, the training loss is 54216041808.86996\n",
            "For 6995th iteration, the training loss is 54215806007.515785\n",
            "For 6996th iteration, the training loss is 54215570304.92343\n",
            "For 6997th iteration, the training loss is 54215334630.15475\n",
            "For 6998th iteration, the training loss is 54215098954.750305\n",
            "For 6999th iteration, the training loss is 54214863372.04875\n",
            "For 7000th iteration, the training loss is 54214627995.866844\n",
            "For 7001th iteration, the training loss is 54214392340.93154\n",
            "For 7002th iteration, the training loss is 54214157299.794495\n",
            "For 7003th iteration, the training loss is 54213921811.890816\n",
            "For 7004th iteration, the training loss is 54213690006.960075\n",
            "For 7005th iteration, the training loss is 54213458306.95607\n",
            "For 7006th iteration, the training loss is 54213226735.566864\n",
            "For 7007th iteration, the training loss is 54212995176.9592\n",
            "For 7008th iteration, the training loss is 54212763623.66167\n",
            "For 7009th iteration, the training loss is 54212532152.45858\n",
            "For 7010th iteration, the training loss is 54212300889.0911\n",
            "For 7011th iteration, the training loss is 54212069346.15275\n",
            "For 7012th iteration, the training loss is 54211838407.95215\n",
            "For 7013th iteration, the training loss is 54211607028.173294\n",
            "For 7014th iteration, the training loss is 54211375652.75432\n",
            "For 7015th iteration, the training loss is 54211144385.17848\n",
            "For 7016th iteration, the training loss is 54210913235.19755\n",
            "For 7017th iteration, the training loss is 54210682131.74845\n",
            "For 7018th iteration, the training loss is 54210450749.47184\n",
            "For 7019th iteration, the training loss is 54210219708.38226\n",
            "For 7020th iteration, the training loss is 54209988527.852234\n",
            "For 7021th iteration, the training loss is 54209757517.97103\n",
            "For 7022th iteration, the training loss is 54209526710.32087\n",
            "For 7023th iteration, the training loss is 54209295959.64948\n",
            "For 7024th iteration, the training loss is 54209065199.85038\n",
            "For 7025th iteration, the training loss is 54208834546.216515\n",
            "For 7026th iteration, the training loss is 54208603970.86902\n",
            "For 7027th iteration, the training loss is 54208373116.25624\n",
            "For 7028th iteration, the training loss is 54208142847.84808\n",
            "For 7029th iteration, the training loss is 54207912152.9731\n",
            "For 7030th iteration, the training loss is 54207681441.871765\n",
            "For 7031th iteration, the training loss is 54207450850.54696\n",
            "For 7032th iteration, the training loss is 54207220352.12524\n",
            "For 7033th iteration, the training loss is 54206989919.64958\n",
            "For 7034th iteration, the training loss is 54206759690.26725\n",
            "For 7035th iteration, the training loss is 54206529247.83144\n",
            "For 7036th iteration, the training loss is 54206299427.351814\n",
            "For 7037th iteration, the training loss is 54206069086.626434\n",
            "For 7038th iteration, the training loss is 54205838791.39249\n",
            "For 7039th iteration, the training loss is 54205608570.545586\n",
            "For 7040th iteration, the training loss is 54205378477.041115\n",
            "For 7041th iteration, the training loss is 54205148386.45901\n",
            "For 7042th iteration, the training loss is 54204918283.734436\n",
            "For 7043th iteration, the training loss is 54204688268.16444\n",
            "For 7044th iteration, the training loss is 54204458427.43244\n",
            "For 7045th iteration, the training loss is 54204228654.02351\n",
            "For 7046th iteration, the training loss is 54203998908.93616\n",
            "For 7047th iteration, the training loss is 54203769083.82523\n",
            "For 7048th iteration, the training loss is 54203539255.51498\n",
            "For 7049th iteration, the training loss is 54203309503.89705\n",
            "For 7050th iteration, the training loss is 54203079932.02663\n",
            "For 7051th iteration, the training loss is 54202850108.62796\n",
            "For 7052th iteration, the training loss is 54202620806.3865\n",
            "For 7053th iteration, the training loss is 54202391137.93762\n",
            "For 7054th iteration, the training loss is 54202161493.489136\n",
            "For 7055th iteration, the training loss is 54201932012.14125\n",
            "For 7056th iteration, the training loss is 54201702729.181595\n",
            "For 7057th iteration, the training loss is 54201473234.10112\n",
            "For 7058th iteration, the training loss is 54201244334.91416\n",
            "For 7059th iteration, the training loss is 54201014936.97382\n",
            "For 7060th iteration, the training loss is 54200785554.6612\n",
            "For 7061th iteration, the training loss is 54200556264.26815\n",
            "For 7062th iteration, the training loss is 54200327066.63589\n",
            "For 7063th iteration, the training loss is 54200097923.97007\n",
            "For 7064th iteration, the training loss is 54199868970.02977\n",
            "For 7065th iteration, the training loss is 54199639815.442894\n",
            "For 7066th iteration, the training loss is 54199411233.317375\n",
            "For 7067th iteration, the training loss is 54199182173.890884\n",
            "For 7068th iteration, the training loss is 54198953109.72865\n",
            "For 7069th iteration, the training loss is 54198724151.22193\n",
            "For 7070th iteration, the training loss is 54198495265.85915\n",
            "For 7071th iteration, the training loss is 54198266452.71314\n",
            "For 7072th iteration, the training loss is 54198037805.600914\n",
            "For 7073th iteration, the training loss is 54197809226.37989\n",
            "For 7074th iteration, the training loss is 54197580519.492294\n",
            "For 7075th iteration, the training loss is 54197351880.50514\n",
            "For 7076th iteration, the training loss is 54197123408.346016\n",
            "For 7077th iteration, the training loss is 54196895019.50714\n",
            "For 7078th iteration, the training loss is 54196666570.71507\n",
            "For 7079th iteration, the training loss is 54196438108.87784\n",
            "For 7080th iteration, the training loss is 54196209823.28326\n",
            "For 7081th iteration, the training loss is 54195981609.1529\n",
            "For 7082th iteration, the training loss is 54195753343.680984\n",
            "For 7083th iteration, the training loss is 54195525055.984566\n",
            "For 7084th iteration, the training loss is 54195296949.66513\n",
            "For 7085th iteration, the training loss is 54195068583.59517\n",
            "For 7086th iteration, the training loss is 54194840713.49118\n",
            "For 7087th iteration, the training loss is 54194612495.42145\n",
            "For 7088th iteration, the training loss is 54194384262.852\n",
            "For 7089th iteration, the training loss is 54194156212.780815\n",
            "For 7090th iteration, the training loss is 54193928316.30105\n",
            "For 7091th iteration, the training loss is 54193700376.31255\n",
            "For 7092th iteration, the training loss is 54193472430.020706\n",
            "For 7093th iteration, the training loss is 54193244551.00726\n",
            "For 7094th iteration, the training loss is 54193016825.12537\n",
            "For 7095th iteration, the training loss is 54192789174.47035\n",
            "For 7096th iteration, the training loss is 54192561505.730736\n",
            "For 7097th iteration, the training loss is 54192333810.386284\n",
            "For 7098th iteration, the training loss is 54192106289.31775\n",
            "For 7099th iteration, the training loss is 54191878740.49211\n",
            "For 7100th iteration, the training loss is 54191651189.246086\n",
            "For 7101th iteration, the training loss is 54191423643.25681\n",
            "For 7102th iteration, the training loss is 54191196238.99308\n",
            "For 7103th iteration, the training loss is 54190968920.66249\n",
            "For 7104th iteration, the training loss is 54190741568.07114\n",
            "For 7105th iteration, the training loss is 54190514201.24118\n",
            "For 7106th iteration, the training loss is 54190286990.8404\n",
            "For 7107th iteration, the training loss is 54190059770.71278\n",
            "For 7108th iteration, the training loss is 54189832524.991\n",
            "For 7109th iteration, the training loss is 54189605303.43307\n",
            "For 7110th iteration, the training loss is 54189378199.760635\n",
            "For 7111th iteration, the training loss is 54189151226.73617\n",
            "For 7112th iteration, the training loss is 54188924303.32615\n",
            "For 7113th iteration, the training loss is 54188697209.62215\n",
            "For 7114th iteration, the training loss is 54188470537.905014\n",
            "For 7115th iteration, the training loss is 54188243498.54415\n",
            "For 7116th iteration, the training loss is 54188016797.37235\n",
            "For 7117th iteration, the training loss is 54187789871.02621\n",
            "For 7118th iteration, the training loss is 54187563593.15427\n",
            "For 7119th iteration, the training loss is 54187336750.9595\n",
            "For 7120th iteration, the training loss is 54187109933.34689\n",
            "For 7121th iteration, the training loss is 54186883263.4025\n",
            "For 7122th iteration, the training loss is 54186656711.45336\n",
            "For 7123th iteration, the training loss is 54186430121.0834\n",
            "For 7124th iteration, the training loss is 54186203495.61625\n",
            "For 7125th iteration, the training loss is 54185976954.40508\n",
            "For 7126th iteration, the training loss is 54185750525.02835\n",
            "For 7127th iteration, the training loss is 54185524108.72693\n",
            "For 7128th iteration, the training loss is 54185297869.81847\n",
            "For 7129th iteration, the training loss is 54185071429.80315\n",
            "For 7130th iteration, the training loss is 54184845489.431114\n",
            "For 7131th iteration, the training loss is 54184619129.89837\n",
            "For 7132th iteration, the training loss is 54184393137.59067\n",
            "For 7133th iteration, the training loss is 54184166891.724686\n",
            "For 7134th iteration, the training loss is 54183941308.66792\n",
            "For 7135th iteration, the training loss is 54183715141.88064\n",
            "For 7136th iteration, the training loss is 54183488869.519966\n",
            "For 7137th iteration, the training loss is 54183263107.29374\n",
            "For 7138th iteration, the training loss is 54183036946.94926\n",
            "For 7139th iteration, the training loss is 54182811195.984\n",
            "For 7140th iteration, the training loss is 54182585492.66323\n",
            "For 7141th iteration, the training loss is 54182359450.137314\n",
            "For 7142th iteration, the training loss is 54182134070.45056\n",
            "For 7143th iteration, the training loss is 54181908234.1394\n",
            "For 7144th iteration, the training loss is 54181682785.58498\n",
            "For 7145th iteration, the training loss is 54181457059.4151\n",
            "For 7146th iteration, the training loss is 54181232008.15963\n",
            "For 7147th iteration, the training loss is 54181006324.096466\n",
            "For 7148th iteration, the training loss is 54180781426.6986\n",
            "For 7149th iteration, the training loss is 54180555923.03633\n",
            "For 7150th iteration, the training loss is 54180330603.179565\n",
            "For 7151th iteration, the training loss is 54180104994.73105\n",
            "For 7152th iteration, the training loss is 54179880082.38008\n",
            "For 7153th iteration, the training loss is 54179654747.42838\n",
            "For 7154th iteration, the training loss is 54179429236.22733\n",
            "For 7155th iteration, the training loss is 54179204239.31035\n",
            "For 7156th iteration, the training loss is 54178978830.780266\n",
            "For 7157th iteration, the training loss is 54178753693.12556\n",
            "For 7158th iteration, the training loss is 54178528389.86405\n",
            "For 7159th iteration, the training loss is 54178303492.6778\n",
            "For 7160th iteration, the training loss is 54178078627.814415\n",
            "For 7161th iteration, the training loss is 54177853673.27761\n",
            "For 7162th iteration, the training loss is 54177628703.366165\n",
            "For 7163th iteration, the training loss is 54177403788.753876\n",
            "For 7164th iteration, the training loss is 54177178982.5448\n",
            "For 7165th iteration, the training loss is 54176954179.83577\n",
            "For 7166th iteration, the training loss is 54176729532.932014\n",
            "For 7167th iteration, the training loss is 54176504857.539734\n",
            "For 7168th iteration, the training loss is 54176280131.26717\n",
            "For 7169th iteration, the training loss is 54176055436.81802\n",
            "For 7170th iteration, the training loss is 54175830803.52169\n",
            "For 7171th iteration, the training loss is 54175606220.2727\n",
            "For 7172th iteration, the training loss is 54175381744.578316\n",
            "For 7173th iteration, the training loss is 54175157388.6924\n",
            "For 7174th iteration, the training loss is 54174933043.72529\n",
            "For 7175th iteration, the training loss is 54174708688.42083\n",
            "For 7176th iteration, the training loss is 54174484257.5873\n",
            "For 7177th iteration, the training loss is 54174259953.140594\n",
            "For 7178th iteration, the training loss is 54174035742.8275\n",
            "For 7179th iteration, the training loss is 54173811641.13465\n",
            "For 7180th iteration, the training loss is 54173587556.475464\n",
            "For 7181th iteration, the training loss is 54173363453.69688\n",
            "For 7182th iteration, the training loss is 54173139277.58798\n",
            "For 7183th iteration, the training loss is 54172915483.93446\n",
            "For 7184th iteration, the training loss is 54172691305.05946\n",
            "For 7185th iteration, the training loss is 54172467505.09219\n",
            "For 7186th iteration, the training loss is 54172243255.97912\n",
            "For 7187th iteration, the training loss is 54172019696.0008\n",
            "For 7188th iteration, the training loss is 54171795832.02377\n",
            "For 7189th iteration, the training loss is 54171571785.06277\n",
            "For 7190th iteration, the training loss is 54171348005.7888\n",
            "For 7191th iteration, the training loss is 54171124044.03768\n",
            "For 7192th iteration, the training loss is 54170900492.75785\n",
            "For 7193th iteration, the training loss is 54170677070.194916\n",
            "For 7194th iteration, the training loss is 54170453515.13076\n",
            "For 7195th iteration, the training loss is 54170229920.94833\n",
            "For 7196th iteration, the training loss is 54170006467.85107\n",
            "For 7197th iteration, the training loss is 54169783058.37846\n",
            "For 7198th iteration, the training loss is 54169559638.71108\n",
            "For 7199th iteration, the training loss is 54169336326.55375\n",
            "For 7200th iteration, the training loss is 54169113076.593445\n",
            "For 7201th iteration, the training loss is 54168889806.8568\n",
            "For 7202th iteration, the training loss is 54168666650.11745\n",
            "For 7203th iteration, the training loss is 54168443489.28061\n",
            "For 7204th iteration, the training loss is 54168220205.09942\n",
            "For 7205th iteration, the training loss is 54167996959.72889\n",
            "For 7206th iteration, the training loss is 54167774100.8682\n",
            "For 7207th iteration, the training loss is 54167551151.20045\n",
            "For 7208th iteration, the training loss is 54167328411.92866\n",
            "For 7209th iteration, the training loss is 54167105771.545074\n",
            "For 7210th iteration, the training loss is 54166882966.9572\n",
            "For 7211th iteration, the training loss is 54166660281.66202\n",
            "For 7212th iteration, the training loss is 54166437476.182236\n",
            "For 7213th iteration, the training loss is 54166214606.63052\n",
            "For 7214th iteration, the training loss is 54165992021.983795\n",
            "For 7215th iteration, the training loss is 54165769022.271164\n",
            "For 7216th iteration, the training loss is 54165546693.96592\n",
            "For 7217th iteration, the training loss is 54165324194.882095\n",
            "For 7218th iteration, the training loss is 54165101823.901726\n",
            "For 7219th iteration, the training loss is 54164879316.47735\n",
            "For 7220th iteration, the training loss is 54164656755.382225\n",
            "For 7221th iteration, the training loss is 54164434585.91372\n",
            "For 7222th iteration, the training loss is 54164211868.284035\n",
            "For 7223th iteration, the training loss is 54163989822.0196\n",
            "For 7224th iteration, the training loss is 54163767608.42993\n",
            "For 7225th iteration, the training loss is 54163545508.75636\n",
            "For 7226th iteration, the training loss is 54163323290.0201\n",
            "For 7227th iteration, the training loss is 54163100995.780876\n",
            "For 7228th iteration, the training loss is 54162879108.36758\n",
            "For 7229th iteration, the training loss is 54162657150.56328\n",
            "For 7230th iteration, the training loss is 54162435192.34278\n",
            "For 7231th iteration, the training loss is 54162213187.25717\n",
            "For 7232th iteration, the training loss is 54161991145.57259\n",
            "For 7233th iteration, the training loss is 54161769183.00557\n",
            "For 7234th iteration, the training loss is 54161547350.549736\n",
            "For 7235th iteration, the training loss is 54161325605.96866\n",
            "For 7236th iteration, the training loss is 54161103780.71869\n",
            "For 7237th iteration, the training loss is 54160882173.40244\n",
            "For 7238th iteration, the training loss is 54160660524.34225\n",
            "For 7239th iteration, the training loss is 54160438777.2405\n",
            "For 7240th iteration, the training loss is 54160217037.25902\n",
            "For 7241th iteration, the training loss is 54159995328.35131\n",
            "For 7242th iteration, the training loss is 54159773678.0744\n",
            "For 7243th iteration, the training loss is 54159552073.670685\n",
            "For 7244th iteration, the training loss is 54159330547.75768\n",
            "For 7245th iteration, the training loss is 54159109074.933685\n",
            "For 7246th iteration, the training loss is 54158887835.89633\n",
            "For 7247th iteration, the training loss is 54158666502.77505\n",
            "For 7248th iteration, the training loss is 54158445501.092384\n",
            "For 7249th iteration, the training loss is 54158224382.024475\n",
            "For 7250th iteration, the training loss is 54158002812.8282\n",
            "For 7251th iteration, the training loss is 54157781905.30565\n",
            "For 7252th iteration, the training loss is 54157561195.8239\n",
            "For 7253th iteration, the training loss is 54157340330.68816\n",
            "For 7254th iteration, the training loss is 54157119551.60667\n",
            "For 7255th iteration, the training loss is 54156898857.46038\n",
            "For 7256th iteration, the training loss is 54156677985.33213\n",
            "For 7257th iteration, the training loss is 54156457216.34615\n",
            "For 7258th iteration, the training loss is 54156236318.86835\n",
            "For 7259th iteration, the training loss is 54156015332.16382\n",
            "For 7260th iteration, the training loss is 54155794760.9875\n",
            "For 7261th iteration, the training loss is 54155574220.858376\n",
            "For 7262th iteration, the training loss is 54155353509.27525\n",
            "For 7263th iteration, the training loss is 54155132746.48192\n",
            "For 7264th iteration, the training loss is 54154912364.4067\n",
            "For 7265th iteration, the training loss is 54154691907.43405\n",
            "For 7266th iteration, the training loss is 54154471364.081535\n",
            "For 7267th iteration, the training loss is 54154250751.35146\n",
            "For 7268th iteration, the training loss is 54154030411.56982\n",
            "For 7269th iteration, the training loss is 54153810124.50611\n",
            "For 7270th iteration, the training loss is 54153589751.31317\n",
            "For 7271th iteration, the training loss is 54153369305.92886\n",
            "For 7272th iteration, the training loss is 54153149131.47245\n",
            "For 7273th iteration, the training loss is 54152929008.01003\n",
            "For 7274th iteration, the training loss is 54152708876.58437\n",
            "For 7275th iteration, the training loss is 54152488673.5314\n",
            "For 7276th iteration, the training loss is 54152268444.35295\n",
            "For 7277th iteration, the training loss is 54152048383.877266\n",
            "For 7278th iteration, the training loss is 54151828372.1936\n",
            "For 7279th iteration, the training loss is 54151608293.71803\n",
            "For 7280th iteration, the training loss is 54151388368.20488\n",
            "For 7281th iteration, the training loss is 54151168428.27392\n",
            "For 7282th iteration, the training loss is 54150948562.886856\n",
            "For 7283th iteration, the training loss is 54150728604.25676\n",
            "For 7284th iteration, the training loss is 54150508834.55438\n",
            "For 7285th iteration, the training loss is 54150289031.59245\n",
            "For 7286th iteration, the training loss is 54150069547.07352\n",
            "For 7287th iteration, the training loss is 54149849963.19219\n",
            "For 7288th iteration, the training loss is 54149630364.20702\n",
            "For 7289th iteration, the training loss is 54149410746.9517\n",
            "For 7290th iteration, the training loss is 54149191239.6277\n",
            "For 7291th iteration, the training loss is 54148971766.863266\n",
            "For 7292th iteration, the training loss is 54148752364.9788\n",
            "For 7293th iteration, the training loss is 54148532994.3936\n",
            "For 7294th iteration, the training loss is 54148317205.808914\n",
            "For 7295th iteration, the training loss is 54148101326.41736\n",
            "For 7296th iteration, the training loss is 54147885528.79793\n",
            "For 7297th iteration, the training loss is 54147669854.62995\n",
            "For 7298th iteration, the training loss is 54147454182.82855\n",
            "For 7299th iteration, the training loss is 54147238808.1974\n",
            "For 7300th iteration, the training loss is 54147023206.32073\n",
            "For 7301th iteration, the training loss is 54146807916.58572\n",
            "For 7302th iteration, the training loss is 54146592507.15263\n",
            "For 7303th iteration, the training loss is 54146377105.67318\n",
            "For 7304th iteration, the training loss is 54146161638.56487\n",
            "For 7305th iteration, the training loss is 54145946387.90248\n",
            "For 7306th iteration, the training loss is 54145731080.82452\n",
            "For 7307th iteration, the training loss is 54145515642.96682\n",
            "For 7308th iteration, the training loss is 54145300545.75742\n",
            "For 7309th iteration, the training loss is 54145085326.0744\n",
            "For 7310th iteration, the training loss is 54144870414.87196\n",
            "For 7311th iteration, the training loss is 54144655379.89562\n",
            "For 7312th iteration, the training loss is 54144440350.8706\n",
            "For 7313th iteration, the training loss is 54144225253.59239\n",
            "For 7314th iteration, the training loss is 54144010368.98417\n",
            "For 7315th iteration, the training loss is 54143795445.30003\n",
            "For 7316th iteration, the training loss is 54143580493.390625\n",
            "For 7317th iteration, the training loss is 54143365426.395355\n",
            "For 7318th iteration, the training loss is 54143150569.3956\n",
            "For 7319th iteration, the training loss is 54142935761.58778\n",
            "For 7320th iteration, the training loss is 54142720990.18232\n",
            "For 7321th iteration, the training loss is 54142506261.140434\n",
            "For 7322th iteration, the training loss is 54142291573.7766\n",
            "For 7323th iteration, the training loss is 54142077168.34002\n",
            "For 7324th iteration, the training loss is 54141862532.361534\n",
            "For 7325th iteration, the training loss is 54141648199.958405\n",
            "For 7326th iteration, the training loss is 54141433747.678665\n",
            "For 7327th iteration, the training loss is 54141219284.61657\n",
            "For 7328th iteration, the training loss is 54141004773.2615\n",
            "For 7329th iteration, the training loss is 54140790440.952614\n",
            "For 7330th iteration, the training loss is 54140575978.43575\n",
            "For 7331th iteration, the training loss is 54140361595.8748\n",
            "For 7332th iteration, the training loss is 54140147231.92307\n",
            "For 7333th iteration, the training loss is 54139932912.535866\n",
            "For 7334th iteration, the training loss is 54139718800.32818\n",
            "For 7335th iteration, the training loss is 54139504564.020485\n",
            "For 7336th iteration, the training loss is 54139290628.323265\n",
            "For 7337th iteration, the training loss is 54139076589.44939\n",
            "For 7338th iteration, the training loss is 54138862636.27219\n",
            "For 7339th iteration, the training loss is 54138648565.551315\n",
            "For 7340th iteration, the training loss is 54138434665.75392\n",
            "For 7341th iteration, the training loss is 54138220755.76682\n",
            "For 7342th iteration, the training loss is 54138006774.886635\n",
            "For 7343th iteration, the training loss is 54137793161.03588\n",
            "For 7344th iteration, the training loss is 54137579299.341576\n",
            "For 7345th iteration, the training loss is 54137365734.76746\n",
            "For 7346th iteration, the training loss is 54137152063.8698\n",
            "For 7347th iteration, the training loss is 54136938475.1265\n",
            "For 7348th iteration, the training loss is 54136724768.6449\n",
            "For 7349th iteration, the training loss is 54136511227.33977\n",
            "For 7350th iteration, the training loss is 54136297678.96093\n",
            "For 7351th iteration, the training loss is 54136084049.69921\n",
            "For 7352th iteration, the training loss is 54135870677.17435\n",
            "For 7353th iteration, the training loss is 54135657182.53551\n",
            "For 7354th iteration, the training loss is 54135443981.70478\n",
            "For 7355th iteration, the training loss is 54135230673.44331\n",
            "For 7356th iteration, the training loss is 54135017441.203514\n",
            "For 7357th iteration, the training loss is 54134804101.95706\n",
            "For 7358th iteration, the training loss is 54134590843.32402\n",
            "For 7359th iteration, the training loss is 54134377629.242615\n",
            "For 7360th iteration, the training loss is 54134164426.520164\n",
            "For 7361th iteration, the training loss is 54133951522.67235\n",
            "For 7362th iteration, the training loss is 54133738809.21904\n",
            "For 7363th iteration, the training loss is 54133526007.08375\n",
            "For 7364th iteration, the training loss is 54133313341.53806\n",
            "For 7365th iteration, the training loss is 54133100479.02423\n",
            "For 7366th iteration, the training loss is 54132887922.91013\n",
            "For 7367th iteration, the training loss is 54132675156.39197\n",
            "For 7368th iteration, the training loss is 54132462258.06747\n",
            "For 7369th iteration, the training loss is 54132249648.35672\n",
            "For 7370th iteration, the training loss is 54132036937.96733\n",
            "For 7371th iteration, the training loss is 54131824277.07619\n",
            "For 7372th iteration, the training loss is 54131611531.05175\n",
            "For 7373th iteration, the training loss is 54131398833.57342\n",
            "For 7374th iteration, the training loss is 54131186453.81036\n",
            "For 7375th iteration, the training loss is 54130974243.2193\n",
            "For 7376th iteration, the training loss is 54130761948.64096\n",
            "For 7377th iteration, the training loss is 54130549946.35659\n",
            "For 7378th iteration, the training loss is 54130337308.921135\n",
            "For 7379th iteration, the training loss is 54130124816.792015\n",
            "For 7380th iteration, the training loss is 54129912743.1759\n",
            "For 7381th iteration, the training loss is 54129700400.253235\n",
            "For 7382th iteration, the training loss is 54129488340.580505\n",
            "For 7383th iteration, the training loss is 54129276166.85855\n",
            "For 7384th iteration, the training loss is 54129064054.84724\n",
            "For 7385th iteration, the training loss is 54128851838.52502\n",
            "For 7386th iteration, the training loss is 54128639679.3935\n",
            "For 7387th iteration, the training loss is 54128427581.37683\n",
            "For 7388th iteration, the training loss is 54128215457.75147\n",
            "For 7389th iteration, the training loss is 54128003739.46712\n",
            "For 7390th iteration, the training loss is 54127791754.00657\n",
            "For 7391th iteration, the training loss is 54127580048.71273\n",
            "For 7392th iteration, the training loss is 54127368226.13876\n",
            "For 7393th iteration, the training loss is 54127156465.63672\n",
            "For 7394th iteration, the training loss is 54126944597.189064\n",
            "For 7395th iteration, the training loss is 54126732783.5092\n",
            "For 7396th iteration, the training loss is 54126521274.45252\n",
            "For 7397th iteration, the training loss is 54126309926.88773\n",
            "For 7398th iteration, the training loss is 54126098575.42845\n",
            "For 7399th iteration, the training loss is 54125886956.26516\n",
            "For 7400th iteration, the training loss is 54125675613.97795\n",
            "For 7401th iteration, the training loss is 54125464153.01215\n",
            "For 7402th iteration, the training loss is 54125252747.21575\n",
            "For 7403th iteration, the training loss is 54125041236.49139\n",
            "For 7404th iteration, the training loss is 54124829771.04961\n",
            "For 7405th iteration, the training loss is 54124618617.81895\n",
            "For 7406th iteration, the training loss is 54124407614.55208\n",
            "For 7407th iteration, the training loss is 54124196498.1907\n",
            "For 7408th iteration, the training loss is 54123985238.71811\n",
            "For 7409th iteration, the training loss is 54123774252.98651\n",
            "For 7410th iteration, the training loss is 54123563148.894516\n",
            "For 7411th iteration, the training loss is 54123352091.0081\n",
            "For 7412th iteration, the training loss is 54123140933.02626\n",
            "For 7413th iteration, the training loss is 54122929809.33015\n",
            "For 7414th iteration, the training loss is 54122719086.041115\n",
            "For 7415th iteration, the training loss is 54122508088.159515\n",
            "For 7416th iteration, the training loss is 54122297361.983406\n",
            "For 7417th iteration, the training loss is 54122086874.80043\n",
            "For 7418th iteration, the training loss is 54121876316.90811\n",
            "For 7419th iteration, the training loss is 54121665611.23585\n",
            "For 7420th iteration, the training loss is 54121455262.08579\n",
            "For 7421th iteration, the training loss is 54121244425.53782\n",
            "For 7422th iteration, the training loss is 54121033534.846466\n",
            "For 7423th iteration, the training loss is 54120823117.55268\n",
            "For 7424th iteration, the training loss is 54120612937.34781\n",
            "For 7425th iteration, the training loss is 54120402264.635185\n",
            "For 7426th iteration, the training loss is 54120191540.918465\n",
            "For 7427th iteration, the training loss is 54119981166.10049\n",
            "For 7428th iteration, the training loss is 54119771169.60063\n",
            "For 7429th iteration, the training loss is 54119560742.155075\n",
            "For 7430th iteration, the training loss is 54119350279.831566\n",
            "For 7431th iteration, the training loss is 54119140220.28053\n",
            "For 7432th iteration, the training loss is 54118930320.91109\n",
            "For 7433th iteration, the training loss is 54118719972.35495\n",
            "For 7434th iteration, the training loss is 54118509596.05673\n",
            "For 7435th iteration, the training loss is 54118299546.243614\n",
            "For 7436th iteration, the training loss is 54118089758.45335\n",
            "For 7437th iteration, the training loss is 54117879874.04148\n",
            "For 7438th iteration, the training loss is 54117670251.102135\n",
            "For 7439th iteration, the training loss is 54117460227.99361\n",
            "For 7440th iteration, the training loss is 54117250087.82355\n",
            "For 7441th iteration, the training loss is 54117040274.36054\n",
            "For 7442th iteration, the training loss is 54116830718.23372\n",
            "For 7443th iteration, the training loss is 54116621081.417336\n",
            "For 7444th iteration, the training loss is 54116411644.7601\n",
            "For 7445th iteration, the training loss is 54116202025.75729\n",
            "For 7446th iteration, the training loss is 54115992246.54354\n",
            "For 7447th iteration, the training loss is 54115782728.61384\n",
            "For 7448th iteration, the training loss is 54115573447.66074\n",
            "For 7449th iteration, the training loss is 54115364080.54197\n",
            "For 7450th iteration, the training loss is 54115154579.37019\n",
            "For 7451th iteration, the training loss is 54114945118.09502\n",
            "For 7452th iteration, the training loss is 54114735537.593735\n",
            "For 7453th iteration, the training loss is 54114526160.88107\n",
            "For 7454th iteration, the training loss is 54114316695.31133\n",
            "For 7455th iteration, the training loss is 54114107093.381775\n",
            "For 7456th iteration, the training loss is 54113897967.96837\n",
            "For 7457th iteration, the training loss is 54113689052.3862\n",
            "For 7458th iteration, the training loss is 54113480066.09866\n",
            "For 7459th iteration, the training loss is 54113271222.61432\n",
            "For 7460th iteration, the training loss is 54113062021.3683\n",
            "For 7461th iteration, the training loss is 54112852757.7881\n",
            "For 7462th iteration, the training loss is 54112643796.82455\n",
            "For 7463th iteration, the training loss is 54112435098.9581\n",
            "For 7464th iteration, the training loss is 54112225968.108574\n",
            "For 7465th iteration, the training loss is 54112016769.035835\n",
            "For 7466th iteration, the training loss is 54111807922.73896\n",
            "For 7467th iteration, the training loss is 54111599422.17968\n",
            "For 7468th iteration, the training loss is 54111390757.004684\n",
            "For 7469th iteration, the training loss is 54111182330.73299\n",
            "For 7470th iteration, the training loss is 54110973823.31405\n",
            "For 7471th iteration, the training loss is 54110765459.773865\n",
            "For 7472th iteration, the training loss is 54110556531.79361\n",
            "For 7473th iteration, the training loss is 54110347684.6465\n",
            "For 7474th iteration, the training loss is 54110139285.88995\n",
            "For 7475th iteration, the training loss is 54109931107.2488\n",
            "For 7476th iteration, the training loss is 54109722519.2096\n",
            "For 7477th iteration, the training loss is 54109513841.47361\n",
            "For 7478th iteration, the training loss is 54109305484.234116\n",
            "For 7479th iteration, the training loss is 54109097362.21697\n",
            "For 7480th iteration, the training loss is 54108889247.00407\n",
            "For 7481th iteration, the training loss is 54108681337.75005\n",
            "For 7482th iteration, the training loss is 54108472996.133125\n",
            "For 7483th iteration, the training loss is 54108264584.65193\n",
            "For 7484th iteration, the training loss is 54108056475.16166\n",
            "For 7485th iteration, the training loss is 54107848611.69688\n",
            "For 7486th iteration, the training loss is 54107640562.8387\n",
            "For 7487th iteration, the training loss is 54107432483.40571\n",
            "For 7488th iteration, the training loss is 54107224392.872894\n",
            "For 7489th iteration, the training loss is 54107016272.774055\n",
            "For 7490th iteration, the training loss is 54106808535.00533\n",
            "For 7491th iteration, the training loss is 54106600930.62028\n",
            "For 7492th iteration, the training loss is 54106392769.69186\n",
            "For 7493th iteration, the training loss is 54106184672.5957\n",
            "For 7494th iteration, the training loss is 54105976914.2045\n",
            "For 7495th iteration, the training loss is 54105769363.90785\n",
            "For 7496th iteration, the training loss is 54105561831.61062\n",
            "For 7497th iteration, the training loss is 54105354525.57518\n",
            "For 7498th iteration, the training loss is 54105146796.18577\n",
            "For 7499th iteration, the training loss is 54104938978.92162\n",
            "For 7500th iteration, the training loss is 54104731473.45295\n",
            "For 7501th iteration, the training loss is 54104524193.5839\n",
            "For 7502th iteration, the training loss is 54104316820.491135\n",
            "For 7503th iteration, the training loss is 54104109706.75473\n",
            "For 7504th iteration, the training loss is 54103902512.81054\n",
            "For 7505th iteration, the training loss is 54103695439.121445\n",
            "For 7506th iteration, the training loss is 54103487901.483536\n",
            "For 7507th iteration, the training loss is 54103280400.74605\n",
            "For 7508th iteration, the training loss is 54103073327.88474\n",
            "For 7509th iteration, the training loss is 54102866466.53616\n",
            "For 7510th iteration, the training loss is 54102659346.194786\n",
            "For 7511th iteration, the training loss is 54102452184.21833\n",
            "For 7512th iteration, the training loss is 54102245018.04474\n",
            "For 7513th iteration, the training loss is 54102037799.416565\n",
            "For 7514th iteration, the training loss is 54101830858.1865\n",
            "For 7515th iteration, the training loss is 54101624159.39665\n",
            "For 7516th iteration, the training loss is 54101417269.77473\n",
            "For 7517th iteration, the training loss is 54101210610.7904\n",
            "For 7518th iteration, the training loss is 54101003799.8818\n",
            "For 7519th iteration, the training loss is 54100797194.7774\n",
            "For 7520th iteration, the training loss is 54100590484.8049\n",
            "For 7521th iteration, the training loss is 54100384127.5266\n",
            "For 7522th iteration, the training loss is 54100177351.807495\n",
            "For 7523th iteration, the training loss is 54099970424.538\n",
            "For 7524th iteration, the training loss is 54099763948.780655\n",
            "For 7525th iteration, the training loss is 54099557652.98313\n",
            "For 7526th iteration, the training loss is 54099351292.74023\n",
            "For 7527th iteration, the training loss is 54099145022.276566\n",
            "For 7528th iteration, the training loss is 54098938531.935814\n",
            "For 7529th iteration, the training loss is 54098732471.30462\n",
            "For 7530th iteration, the training loss is 54098525985.94611\n",
            "For 7531th iteration, the training loss is 54098319392.962845\n",
            "For 7532th iteration, the training loss is 54098113120.9883\n",
            "For 7533th iteration, the training loss is 54097907044.061935\n",
            "For 7534th iteration, the training loss is 54097700895.78663\n",
            "For 7535th iteration, the training loss is 54097494964.39295\n",
            "For 7536th iteration, the training loss is 54097288867.0329\n",
            "For 7537th iteration, the training loss is 54097083103.7859\n",
            "For 7538th iteration, the training loss is 54096876922.87095\n",
            "For 7539th iteration, the training loss is 54096670621.93236\n",
            "For 7540th iteration, the training loss is 54096464767.776665\n",
            "For 7541th iteration, the training loss is 54096259086.0008\n",
            "For 7542th iteration, the training loss is 54096053252.72888\n",
            "For 7543th iteration, the training loss is 54095847513.929184\n",
            "For 7544th iteration, the training loss is 54095641704.07567\n",
            "For 7545th iteration, the training loss is 54095436198.297386\n",
            "For 7546th iteration, the training loss is 54095230622.30059\n",
            "For 7547th iteration, the training loss is 54095025128.13427\n",
            "For 7548th iteration, the training loss is 54094819517.45462\n",
            "For 7549th iteration, the training loss is 54094614250.4851\n",
            "For 7550th iteration, the training loss is 54094408465.745415\n",
            "For 7551th iteration, the training loss is 54094202575.56777\n",
            "For 7552th iteration, the training loss is 54093997049.72491\n",
            "For 7553th iteration, the training loss is 54093791796.64516\n",
            "For 7554th iteration, the training loss is 54093586502.65048\n",
            "For 7555th iteration, the training loss is 54093381385.40407\n",
            "For 7556th iteration, the training loss is 54093176196.26359\n",
            "For 7557th iteration, the training loss is 54092971083.14998\n",
            "For 7558th iteration, the training loss is 54092765867.205635\n",
            "For 7559th iteration, the training loss is 54092560934.72074\n",
            "For 7560th iteration, the training loss is 54092355838.91376\n",
            "For 7561th iteration, the training loss is 54092150918.728035\n",
            "For 7562th iteration, the training loss is 54091945833.20322\n",
            "For 7563th iteration, the training loss is 54091740935.33839\n",
            "For 7564th iteration, the training loss is 54091535963.10559\n",
            "For 7565th iteration, the training loss is 54091330914.824234\n",
            "For 7566th iteration, the training loss is 54091125866.76373\n",
            "For 7567th iteration, the training loss is 54090920680.650764\n",
            "For 7568th iteration, the training loss is 54090715810.082115\n",
            "For 7569th iteration, the training loss is 54090511114.39333\n",
            "For 7570th iteration, the training loss is 54090306444.95547\n",
            "For 7571th iteration, the training loss is 54090101942.96387\n",
            "For 7572th iteration, the training loss is 54089897372.97854\n",
            "For 7573th iteration, the training loss is 54089692992.28404\n",
            "For 7574th iteration, the training loss is 54089488122.15496\n",
            "For 7575th iteration, the training loss is 54089283428.2348\n",
            "For 7576th iteration, the training loss is 54089078728.091034\n",
            "For 7577th iteration, the training loss is 54088873906.41287\n",
            "For 7578th iteration, the training loss is 54088669408.5413\n",
            "For 7579th iteration, the training loss is 54088465070.26929\n",
            "For 7580th iteration, the training loss is 54088260654.01107\n",
            "For 7581th iteration, the training loss is 54088056397.866684\n",
            "For 7582th iteration, the training loss is 54087852179.49225\n",
            "For 7583th iteration, the training loss is 54087648109.327705\n",
            "For 7584th iteration, the training loss is 54087443897.8735\n",
            "For 7585th iteration, the training loss is 54087239595.5383\n",
            "For 7586th iteration, the training loss is 54087035288.157295\n",
            "For 7587th iteration, the training loss is 54086830878.50258\n",
            "For 7588th iteration, the training loss is 54086626774.435356\n",
            "For 7589th iteration, the training loss is 54086422838.10537\n",
            "For 7590th iteration, the training loss is 54086218929.189545\n",
            "For 7591th iteration, the training loss is 54086015174.19334\n",
            "For 7592th iteration, the training loss is 54085811151.11901\n",
            "For 7593th iteration, the training loss is 54085610897.48985\n",
            "For 7594th iteration, the training loss is 54085410592.84461\n",
            "For 7595th iteration, the training loss is 54085210446.982056\n",
            "For 7596th iteration, the training loss is 54085010233.00757\n",
            "For 7597th iteration, the training loss is 54084810064.597786\n",
            "For 7598th iteration, the training loss is 54084609799.342834\n",
            "For 7599th iteration, the training loss is 54084409825.820786\n",
            "For 7600th iteration, the training loss is 54084209685.0343\n",
            "For 7601th iteration, the training loss is 54084009741.44672\n",
            "For 7602th iteration, the training loss is 54083809746.50617\n",
            "For 7603th iteration, the training loss is 54083609904.83045\n",
            "For 7604th iteration, the training loss is 54083409880.58725\n",
            "For 7605th iteration, the training loss is 54083210031.14464\n",
            "For 7606th iteration, the training loss is 54083010194.94449\n",
            "For 7607th iteration, the training loss is 54082810513.914986\n",
            "For 7608th iteration, the training loss is 54082610434.52364\n",
            "For 7609th iteration, the training loss is 54082410212.82165\n",
            "For 7610th iteration, the training loss is 54082210353.044785\n",
            "For 7611th iteration, the training loss is 54082010451.91915\n",
            "For 7612th iteration, the training loss is 54081810574.12353\n",
            "For 7613th iteration, the training loss is 54081610506.45621\n",
            "For 7614th iteration, the training loss is 54081410905.31208\n",
            "For 7615th iteration, the training loss is 54081211407.40276\n",
            "For 7616th iteration, the training loss is 54081011892.30742\n",
            "For 7617th iteration, the training loss is 54080812362.532\n",
            "For 7618th iteration, the training loss is 54080613233.09997\n",
            "For 7619th iteration, the training loss is 54080413834.93922\n",
            "For 7620th iteration, the training loss is 54080214542.45924\n",
            "For 7621th iteration, the training loss is 54080015009.19615\n",
            "For 7622th iteration, the training loss is 54079815797.09137\n",
            "For 7623th iteration, the training loss is 54079616559.41567\n",
            "For 7624th iteration, the training loss is 54079417437.32168\n",
            "For 7625th iteration, the training loss is 54079218293.97228\n",
            "For 7626th iteration, the training loss is 54079018944.755424\n",
            "For 7627th iteration, the training loss is 54078819526.65264\n",
            "For 7628th iteration, the training loss is 54078619967.88703\n",
            "For 7629th iteration, the training loss is 54078421217.47352\n",
            "For 7630th iteration, the training loss is 54078222640.80539\n",
            "For 7631th iteration, the training loss is 54078023898.18256\n",
            "For 7632th iteration, the training loss is 54077825013.41456\n",
            "For 7633th iteration, the training loss is 54077626422.52968\n",
            "For 7634th iteration, the training loss is 54077427893.023384\n",
            "For 7635th iteration, the training loss is 54077229094.74745\n",
            "For 7636th iteration, the training loss is 54077030114.00807\n",
            "For 7637th iteration, the training loss is 54076831066.398964\n",
            "For 7638th iteration, the training loss is 54076631869.80678\n",
            "For 7639th iteration, the training loss is 54076433484.41859\n",
            "For 7640th iteration, the training loss is 54076235270.39189\n",
            "For 7641th iteration, the training loss is 54076036990.633865\n",
            "For 7642th iteration, the training loss is 54075838327.50815\n",
            "For 7643th iteration, the training loss is 54075639884.900375\n",
            "For 7644th iteration, the training loss is 54075441423.47868\n",
            "For 7645th iteration, the training loss is 54075243057.47892\n",
            "For 7646th iteration, the training loss is 54075044672.323135\n",
            "For 7647th iteration, the training loss is 54074846381.531494\n",
            "For 7648th iteration, the training loss is 54074647983.18797\n",
            "For 7649th iteration, the training loss is 54074449416.062965\n",
            "For 7650th iteration, the training loss is 54074250912.108925\n",
            "For 7651th iteration, the training loss is 54074052199.12467\n",
            "For 7652th iteration, the training loss is 54073854292.31805\n",
            "For 7653th iteration, the training loss is 54073656553.955925\n",
            "For 7654th iteration, the training loss is 54073458746.565956\n",
            "For 7655th iteration, the training loss is 54073260893.16033\n",
            "For 7656th iteration, the training loss is 54073062890.19783\n",
            "For 7657th iteration, the training loss is 54072865068.61095\n",
            "For 7658th iteration, the training loss is 54072667359.4099\n",
            "For 7659th iteration, the training loss is 54072469706.2682\n",
            "For 7660th iteration, the training loss is 54072272108.59248\n",
            "For 7661th iteration, the training loss is 54072074676.91883\n",
            "For 7662th iteration, the training loss is 54071877174.42367\n",
            "For 7663th iteration, the training loss is 54071679624.38493\n",
            "For 7664th iteration, the training loss is 54071481919.338615\n",
            "For 7665th iteration, the training loss is 54071284505.03785\n",
            "For 7666th iteration, the training loss is 54071087148.14072\n",
            "For 7667th iteration, the training loss is 54070889666.8698\n",
            "For 7668th iteration, the training loss is 54070692130.88678\n",
            "For 7669th iteration, the training loss is 54070494403.74274\n",
            "For 7670th iteration, the training loss is 54070296601.56502\n",
            "For 7671th iteration, the training loss is 54070098636.23748\n",
            "For 7672th iteration, the training loss is 54069901486.01506\n",
            "For 7673th iteration, the training loss is 54069704387.67926\n",
            "For 7674th iteration, the training loss is 54069507239.077484\n",
            "For 7675th iteration, the training loss is 54069309932.42561\n",
            "For 7676th iteration, the training loss is 54069112918.891884\n",
            "For 7677th iteration, the training loss is 54068915640.32846\n",
            "For 7678th iteration, the training loss is 54068718133.12096\n",
            "For 7679th iteration, the training loss is 54068520628.10379\n",
            "For 7680th iteration, the training loss is 54068323873.50204\n",
            "For 7681th iteration, the training loss is 54068126372.170334\n",
            "For 7682th iteration, the training loss is 54067929641.4706\n",
            "For 7683th iteration, the training loss is 54067732215.575195\n",
            "For 7684th iteration, the training loss is 54067535508.837616\n",
            "For 7685th iteration, the training loss is 54067338158.380295\n",
            "For 7686th iteration, the training loss is 54067141475.66282\n",
            "For 7687th iteration, the training loss is 54066944285.0605\n",
            "For 7688th iteration, the training loss is 54066747670.84305\n",
            "For 7689th iteration, the training loss is 54066550523.25475\n",
            "For 7690th iteration, the training loss is 54066354032.43927\n",
            "For 7691th iteration, the training loss is 54066156983.76832\n",
            "For 7692th iteration, the training loss is 54065960556.58442\n",
            "For 7693th iteration, the training loss is 54065763579.293655\n",
            "For 7694th iteration, the training loss is 54065567214.436676\n",
            "For 7695th iteration, the training loss is 54065370279.17756\n",
            "For 7696th iteration, the training loss is 54065174031.721725\n",
            "For 7697th iteration, the training loss is 54064977195.81082\n",
            "For 7698th iteration, the training loss is 54064781006.25446\n",
            "For 7699th iteration, the training loss is 54064584212.485565\n",
            "For 7700th iteration, the training loss is 54064387981.99274\n",
            "For 7701th iteration, the training loss is 54064191253.32899\n",
            "For 7702th iteration, the training loss is 54063995155.174065\n",
            "For 7703th iteration, the training loss is 54063798800.333084\n",
            "For 7704th iteration, the training loss is 54063602838.50497\n",
            "For 7705th iteration, the training loss is 54063406646.27167\n",
            "For 7706th iteration, the training loss is 54063210663.58172\n",
            "For 7707th iteration, the training loss is 54063014161.19364\n",
            "For 7708th iteration, the training loss is 54062818287.58053\n",
            "For 7709th iteration, the training loss is 54062621856.22207\n",
            "For 7710th iteration, the training loss is 54062426088.79361\n",
            "For 7711th iteration, the training loss is 54062230081.717674\n",
            "For 7712th iteration, the training loss is 54062034352.98503\n",
            "For 7713th iteration, the training loss is 54061838363.16364\n",
            "For 7714th iteration, the training loss is 54061642761.3903\n",
            "For 7715th iteration, the training loss is 54061446901.00647\n",
            "For 7716th iteration, the training loss is 54061251172.1255\n",
            "For 7717th iteration, the training loss is 54061055034.77959\n",
            "For 7718th iteration, the training loss is 54060859327.76783\n",
            "For 7719th iteration, the training loss is 54060663261.0712\n",
            "For 7720th iteration, the training loss is 54060467725.84383\n",
            "For 7721th iteration, the training loss is 54060271729.7938\n",
            "For 7722th iteration, the training loss is 54060076142.462494\n",
            "For 7723th iteration, the training loss is 54059880216.96252\n",
            "For 7724th iteration, the training loss is 54059684994.687515\n",
            "For 7725th iteration, the training loss is 54059489431.33328\n",
            "For 7726th iteration, the training loss is 54059293972.444176\n",
            "For 7727th iteration, the training loss is 54059098193.253365\n",
            "For 7728th iteration, the training loss is 54058903096.13982\n",
            "For 7729th iteration, the training loss is 54058707683.415016\n",
            "For 7730th iteration, the training loss is 54058512347.23598\n",
            "For 7731th iteration, the training loss is 54058316714.08253\n",
            "For 7732th iteration, the training loss is 54058121736.204636\n",
            "For 7733th iteration, the training loss is 54057926557.37298\n",
            "For 7734th iteration, the training loss is 54057731382.219536\n",
            "For 7735th iteration, the training loss is 54057535895.62229\n",
            "For 7736th iteration, the training loss is 54057341076.648384\n",
            "For 7737th iteration, the training loss is 54057146012.17206\n",
            "For 7738th iteration, the training loss is 54056951045.475685\n",
            "For 7739th iteration, the training loss is 54056755706.13085\n",
            "For 7740th iteration, the training loss is 54056560743.94517\n",
            "For 7741th iteration, the training loss is 54056365348.383286\n",
            "For 7742th iteration, the training loss is 54056170419.694374\n",
            "For 7743th iteration, the training loss is 54055975218.66404\n",
            "For 7744th iteration, the training loss is 54055780636.77852\n",
            "For 7745th iteration, the training loss is 54055585797.87452\n",
            "For 7746th iteration, the training loss is 54055391314.15352\n",
            "For 7747th iteration, the training loss is 54055196639.29514\n",
            "For 7748th iteration, the training loss is 54055001945.50021\n",
            "For 7749th iteration, the training loss is 54054806838.586075\n",
            "For 7750th iteration, the training loss is 54054612172.21265\n",
            "For 7751th iteration, the training loss is 54054417259.82633\n",
            "For 7752th iteration, the training loss is 54054222934.42872\n",
            "For 7753th iteration, the training loss is 54054028388.008606\n",
            "For 7754th iteration, the training loss is 54053833998.65598\n",
            "For 7755th iteration, the training loss is 54053639586.67405\n",
            "For 7756th iteration, the training loss is 54053445268.47133\n",
            "For 7757th iteration, the training loss is 54053250450.4875\n",
            "For 7758th iteration, the training loss is 54053056080.05123\n",
            "For 7759th iteration, the training loss is 54052861456.31435\n",
            "For 7760th iteration, the training loss is 54052667266.51572\n",
            "For 7761th iteration, the training loss is 54052473012.42161\n",
            "For 7762th iteration, the training loss is 54052278979.943886\n",
            "For 7763th iteration, the training loss is 54052084854.885765\n",
            "For 7764th iteration, the training loss is 54051890664.61697\n",
            "For 7765th iteration, the training loss is 54051696329.89923\n",
            "For 7766th iteration, the training loss is 54051502174.73827\n",
            "For 7767th iteration, the training loss is 54051308301.906685\n",
            "For 7768th iteration, the training loss is 54051114254.97642\n",
            "For 7769th iteration, the training loss is 54050920367.23375\n",
            "For 7770th iteration, the training loss is 54050726630.129616\n",
            "For 7771th iteration, the training loss is 54050532723.55729\n",
            "For 7772th iteration, the training loss is 54050338974.7084\n",
            "For 7773th iteration, the training loss is 54050145370.0761\n",
            "For 7774th iteration, the training loss is 54049951599.993835\n",
            "For 7775th iteration, the training loss is 54049757993.188934\n",
            "For 7776th iteration, the training loss is 54049564204.20206\n",
            "For 7777th iteration, the training loss is 54049370572.89549\n",
            "For 7778th iteration, the training loss is 54049177098.4666\n",
            "For 7779th iteration, the training loss is 54048983445.85588\n",
            "For 7780th iteration, the training loss is 54048789949.54452\n",
            "For 7781th iteration, the training loss is 54048596604.423615\n",
            "For 7782th iteration, the training loss is 54048403084.54183\n",
            "For 7783th iteration, the training loss is 54048209719.654526\n",
            "For 7784th iteration, the training loss is 54048016500.94488\n",
            "For 7785th iteration, the training loss is 54047823110.34648\n",
            "For 7786th iteration, the training loss is 54047629980.53928\n",
            "For 7787th iteration, the training loss is 54047436770.18009\n",
            "For 7788th iteration, the training loss is 54047243816.386795\n",
            "For 7789th iteration, the training loss is 54047050563.354515\n",
            "For 7790th iteration, the training loss is 54046857463.144356\n",
            "For 7791th iteration, the training loss is 54046664511.11323\n",
            "For 7792th iteration, the training loss is 54046471343.1096\n",
            "For 7793th iteration, the training loss is 54046278327.58826\n",
            "For 7794th iteration, the training loss is 54046085459.76424\n",
            "For 7795th iteration, the training loss is 54045892414.41248\n",
            "For 7796th iteration, the training loss is 54045699520.447685\n",
            "For 7797th iteration, the training loss is 54045506775.20746\n",
            "For 7798th iteration, the training loss is 54045313925.81195\n",
            "For 7799th iteration, the training loss is 54045121261.17448\n",
            "For 7800th iteration, the training loss is 54044928512.63583\n",
            "For 7801th iteration, the training loss is 54044735911.84365\n",
            "For 7802th iteration, the training loss is 54044543205.34372\n",
            "For 7803th iteration, the training loss is 54044350683.38798\n",
            "For 7804th iteration, the training loss is 54044158186.81831\n",
            "For 7805th iteration, the training loss is 54043965824.19201\n",
            "For 7806th iteration, the training loss is 54043773265.68617\n",
            "For 7807th iteration, the training loss is 54043580891.41798\n",
            "For 7808th iteration, the training loss is 54043388431.16153\n",
            "For 7809th iteration, the training loss is 54043196121.68598\n",
            "For 7810th iteration, the training loss is 54043003667.29074\n",
            "For 7811th iteration, the training loss is 54042811290.877014\n",
            "For 7812th iteration, the training loss is 54042619172.60234\n",
            "For 7813th iteration, the training loss is 54042426855.811714\n",
            "For 7814th iteration, the training loss is 54042234614.917984\n",
            "For 7815th iteration, the training loss is 54042042523.68939\n",
            "For 7816th iteration, the training loss is 54041850285.88641\n",
            "For 7817th iteration, the training loss is 54041658124.38864\n",
            "For 7818th iteration, the training loss is 54041466218.638084\n",
            "For 7819th iteration, the training loss is 54041274113.96543\n",
            "For 7820th iteration, the training loss is 54041082191.32835\n",
            "For 7821th iteration, the training loss is 54040890179.75406\n",
            "For 7822th iteration, the training loss is 54040698421.22461\n",
            "For 7823th iteration, the training loss is 54040506463.90207\n",
            "For 7824th iteration, the training loss is 54040314687.77478\n",
            "For 7825th iteration, the training loss is 54040122821.948524\n",
            "For 7826th iteration, the training loss is 54039931104.79189\n",
            "For 7827th iteration, the training loss is 54039739661.52485\n",
            "For 7828th iteration, the training loss is 54039547577.153076\n",
            "For 7829th iteration, the training loss is 54039355921.32895\n",
            "For 7830th iteration, the training loss is 54039163963.13685\n",
            "For 7831th iteration, the training loss is 54038972560.7112\n",
            "For 7832th iteration, the training loss is 54038780710.524765\n",
            "For 7833th iteration, the training loss is 54038588981.464195\n",
            "For 7834th iteration, the training loss is 54038397230.7618\n",
            "For 7835th iteration, the training loss is 54038205587.98495\n",
            "For 7836th iteration, the training loss is 54038013887.33442\n",
            "For 7837th iteration, the training loss is 54037822619.43992\n",
            "For 7838th iteration, the training loss is 54037630962.86327\n",
            "For 7839th iteration, the training loss is 54037439734.33622\n",
            "For 7840th iteration, the training loss is 54037248138.97818\n",
            "For 7841th iteration, the training loss is 54037056700.29236\n",
            "For 7842th iteration, the training loss is 54036865574.71436\n",
            "For 7843th iteration, the training loss is 54036674464.31785\n",
            "For 7844th iteration, the training loss is 54036483260.3609\n",
            "For 7845th iteration, the training loss is 54036292306.19569\n",
            "For 7846th iteration, the training loss is 54036101149.49547\n",
            "For 7847th iteration, the training loss is 54035910165.91818\n",
            "For 7848th iteration, the training loss is 54035719086.99421\n",
            "For 7849th iteration, the training loss is 54035528260.13885\n",
            "For 7850th iteration, the training loss is 54035337226.21486\n",
            "For 7851th iteration, the training loss is 54035146257.74277\n",
            "For 7852th iteration, the training loss is 54034955539.21814\n",
            "For 7853th iteration, the training loss is 54034764614.352356\n",
            "For 7854th iteration, the training loss is 54034573754.06392\n",
            "For 7855th iteration, the training loss is 54034383142.05634\n",
            "For 7856th iteration, the training loss is 54034192324.00912\n",
            "For 7857th iteration, the training loss is 54034001569.75978\n",
            "For 7858th iteration, the training loss is 54033811062.555016\n",
            "For 7859th iteration, the training loss is 54033620777.985085\n",
            "For 7860th iteration, the training loss is 54033429829.28742\n",
            "For 7861th iteration, the training loss is 54033239316.74035\n",
            "For 7862th iteration, the training loss is 54033048488.38609\n",
            "For 7863th iteration, the training loss is 54032858205.082275\n",
            "For 7864th iteration, the training loss is 54032667483.091644\n",
            "For 7865th iteration, the training loss is 54032477223.9916\n",
            "For 7866th iteration, the training loss is 54032286556.93942\n",
            "For 7867th iteration, the training loss is 54032096060.66232\n",
            "For 7868th iteration, the training loss is 54031905863.387405\n",
            "For 7869th iteration, the training loss is 54031715675.60725\n",
            "For 7870th iteration, the training loss is 54031525497.58223\n",
            "For 7871th iteration, the training loss is 54031335219.11175\n",
            "For 7872th iteration, the training loss is 54031145190.00688\n",
            "For 7873th iteration, the training loss is 54030955368.59909\n",
            "For 7874th iteration, the training loss is 54030764992.448906\n",
            "For 7875th iteration, the training loss is 54030575014.08365\n",
            "For 7876th iteration, the training loss is 54030384691.81208\n",
            "For 7877th iteration, the training loss is 54030194927.52619\n",
            "For 7878th iteration, the training loss is 54030004707.71026\n",
            "For 7879th iteration, the training loss is 54029814957.735344\n",
            "For 7880th iteration, the training loss is 54029624792.666306\n",
            "For 7881th iteration, the training loss is 54029434794.42177\n",
            "For 7882th iteration, the training loss is 54029245089.70026\n",
            "For 7883th iteration, the training loss is 54029055391.53773\n",
            "For 7884th iteration, the training loss is 54028865591.2226\n",
            "For 7885th iteration, the training loss is 54028676034.11441\n",
            "For 7886th iteration, the training loss is 54028486563.53467\n",
            "For 7887th iteration, the training loss is 54028296642.78594\n",
            "For 7888th iteration, the training loss is 54028107208.576965\n",
            "For 7889th iteration, the training loss is 54027917541.046265\n",
            "For 7890th iteration, the training loss is 54027728509.101524\n",
            "For 7891th iteration, the training loss is 54027538765.45617\n",
            "For 7892th iteration, the training loss is 54027349235.30636\n",
            "For 7893th iteration, the training loss is 54027159790.47318\n",
            "For 7894th iteration, the training loss is 54026970410.92765\n",
            "For 7895th iteration, the training loss is 54026780853.03794\n",
            "For 7896th iteration, the training loss is 54026591452.09673\n",
            "For 7897th iteration, the training loss is 54026402219.90678\n",
            "For 7898th iteration, the training loss is 54026212789.501335\n",
            "For 7899th iteration, the training loss is 54026023484.20711\n",
            "For 7900th iteration, the training loss is 54025834406.4253\n",
            "For 7901th iteration, the training loss is 54025645331.57352\n",
            "For 7902th iteration, the training loss is 54025456149.81045\n",
            "For 7903th iteration, the training loss is 54025270543.3547\n",
            "For 7904th iteration, the training loss is 54025085133.699265\n",
            "For 7905th iteration, the training loss is 54024899180.786026\n",
            "For 7906th iteration, the training loss is 54024713732.608955\n",
            "For 7907th iteration, the training loss is 54024528027.061676\n",
            "For 7908th iteration, the training loss is 54024342966.9106\n",
            "For 7909th iteration, the training loss is 54024157183.53569\n",
            "For 7910th iteration, the training loss is 54023971608.685036\n",
            "For 7911th iteration, the training loss is 54023786121.634636\n",
            "For 7912th iteration, the training loss is 54023600683.78087\n",
            "For 7913th iteration, the training loss is 54023415076.99766\n",
            "For 7914th iteration, the training loss is 54023229612.15499\n",
            "For 7915th iteration, the training loss is 54023044431.29079\n",
            "For 7916th iteration, the training loss is 54022859327.83966\n",
            "For 7917th iteration, the training loss is 54022673780.80901\n",
            "For 7918th iteration, the training loss is 54022488692.5452\n",
            "For 7919th iteration, the training loss is 54022303459.034584\n",
            "For 7920th iteration, the training loss is 54022118855.11468\n",
            "For 7921th iteration, the training loss is 54021933474.42357\n",
            "For 7922th iteration, the training loss is 54021748343.24646\n",
            "For 7923th iteration, the training loss is 54021563265.108475\n",
            "For 7924th iteration, the training loss is 54021378255.11857\n",
            "For 7925th iteration, the training loss is 54021193381.538\n",
            "For 7926th iteration, the training loss is 54021008579.03119\n",
            "For 7927th iteration, the training loss is 54020823385.59595\n",
            "For 7928th iteration, the training loss is 54020638697.72242\n",
            "For 7929th iteration, the training loss is 54020453805.902405\n",
            "For 7930th iteration, the training loss is 54020268970.33685\n",
            "For 7931th iteration, the training loss is 54020084147.93815\n",
            "For 7932th iteration, the training loss is 54019899979.45054\n",
            "For 7933th iteration, the training loss is 54019715007.691635\n",
            "For 7934th iteration, the training loss is 54019530300.049\n",
            "For 7935th iteration, the training loss is 54019345601.43416\n",
            "For 7936th iteration, the training loss is 54019161057.44592\n",
            "For 7937th iteration, the training loss is 54018976598.07411\n",
            "For 7938th iteration, the training loss is 54018792241.75128\n",
            "For 7939th iteration, the training loss is 54018607464.8024\n",
            "For 7940th iteration, the training loss is 54018423219.45953\n",
            "For 7941th iteration, the training loss is 54018238736.85166\n",
            "For 7942th iteration, the training loss is 54018054335.038506\n",
            "For 7943th iteration, the training loss is 54017869953.5319\n",
            "For 7944th iteration, the training loss is 54017686141.87207\n",
            "For 7945th iteration, the training loss is 54017501594.52653\n",
            "For 7946th iteration, the training loss is 54017317234.45799\n",
            "For 7947th iteration, the training loss is 54017132948.28859\n",
            "For 7948th iteration, the training loss is 54016948754.82533\n",
            "For 7949th iteration, the training loss is 54016764697.96901\n",
            "For 7950th iteration, the training loss is 54016580555.61877\n",
            "For 7951th iteration, the training loss is 54016396227.4829\n",
            "For 7952th iteration, the training loss is 54016212258.7665\n",
            "For 7953th iteration, the training loss is 54016028012.09458\n",
            "For 7954th iteration, the training loss is 54015844439.86969\n",
            "For 7955th iteration, the training loss is 54015660245.60488\n",
            "For 7956th iteration, the training loss is 54015476468.676315\n",
            "For 7957th iteration, the training loss is 54015292357.32335\n",
            "For 7958th iteration, the training loss is 54015108898.81816\n",
            "For 7959th iteration, the training loss is 54014924840.207695\n",
            "For 7960th iteration, the training loss is 54014741177.328926\n",
            "For 7961th iteration, the training loss is 54014557089.73158\n",
            "For 7962th iteration, the training loss is 54014373106.33415\n",
            "For 7963th iteration, the training loss is 54014189471.71163\n",
            "For 7964th iteration, the training loss is 54014005716.044235\n",
            "For 7965th iteration, the training loss is 54013822173.0047\n",
            "For 7966th iteration, the training loss is 54013638619.771545\n",
            "For 7967th iteration, the training loss is 54013454943.384865\n",
            "For 7968th iteration, the training loss is 54013271481.290474\n",
            "For 7969th iteration, the training loss is 54013087897.12862\n",
            "For 7970th iteration, the training loss is 54012904524.506325\n",
            "For 7971th iteration, the training loss is 54012721140.73982\n",
            "For 7972th iteration, the training loss is 54012537632.62565\n",
            "For 7973th iteration, the training loss is 54012354449.27877\n",
            "For 7974th iteration, the training loss is 54012171017.0944\n",
            "For 7975th iteration, the training loss is 54011987908.99202\n",
            "For 7976th iteration, the training loss is 54011804551.57454\n",
            "For 7977th iteration, the training loss is 54011621405.524216\n",
            "For 7978th iteration, the training loss is 54011438135.925385\n",
            "For 7979th iteration, the training loss is 54011255186.60606\n",
            "For 7980th iteration, the training loss is 54011071989.07525\n",
            "For 7981th iteration, the training loss is 54010889002.05669\n",
            "For 7982th iteration, the training loss is 54010705852.994194\n",
            "For 7983th iteration, the training loss is 54010522913.59015\n",
            "For 7984th iteration, the training loss is 54010339849.54676\n",
            "For 7985th iteration, the training loss is 54010157104.69617\n",
            "For 7986th iteration, the training loss is 54009974110.04677\n",
            "For 7987th iteration, the training loss is 54009791121.75633\n",
            "For 7988th iteration, the training loss is 54009608497.42705\n",
            "For 7989th iteration, the training loss is 54009425604.61125\n",
            "For 7990th iteration, the training loss is 54009242780.34259\n",
            "For 7991th iteration, the training loss is 54009060206.35392\n",
            "For 7992th iteration, the training loss is 54008877821.02143\n",
            "For 7993th iteration, the training loss is 54008694804.2113\n",
            "For 7994th iteration, the training loss is 54008512221.80104\n",
            "For 7995th iteration, the training loss is 54008329658.26465\n",
            "For 7996th iteration, the training loss is 54008147493.989655\n",
            "For 7997th iteration, the training loss is 54007964724.944695\n",
            "For 7998th iteration, the training loss is 54007782682.5062\n",
            "For 7999th iteration, the training loss is 54007600012.69125\n",
            "For 8000th iteration, the training loss is 54007418040.35052\n",
            "For 8001th iteration, the training loss is 54007235420.25428\n",
            "For 8002th iteration, the training loss is 54007053210.11819\n",
            "For 8003th iteration, the training loss is 54006870615.64434\n",
            "For 8004th iteration, the training loss is 54006688451.16579\n",
            "For 8005th iteration, the training loss is 54006506104.21255\n",
            "For 8006th iteration, the training loss is 54006324219.32578\n",
            "For 8007th iteration, the training loss is 54006141892.80031\n",
            "For 8008th iteration, the training loss is 54005959760.294044\n",
            "For 8009th iteration, the training loss is 54005777603.326805\n",
            "For 8010th iteration, the training loss is 54005596059.82617\n",
            "For 8011th iteration, the training loss is 54005413764.29287\n",
            "For 8012th iteration, the training loss is 54005231610.57481\n",
            "For 8013th iteration, the training loss is 54005049578.21962\n",
            "For 8014th iteration, the training loss is 54004867730.59357\n",
            "For 8015th iteration, the training loss is 54004685770.44071\n",
            "For 8016th iteration, the training loss is 54004503886.56785\n",
            "For 8017th iteration, the training loss is 54004321998.518456\n",
            "For 8018th iteration, the training loss is 54004140691.705795\n",
            "For 8019th iteration, the training loss is 54003958671.868385\n",
            "For 8020th iteration, the training loss is 54003776748.9199\n",
            "For 8021th iteration, the training loss is 54003594985.67828\n",
            "For 8022th iteration, the training loss is 54003413369.592316\n",
            "For 8023th iteration, the training loss is 54003231678.81057\n",
            "For 8024th iteration, the training loss is 54003050638.68114\n",
            "For 8025th iteration, the training loss is 54002868806.66462\n",
            "For 8026th iteration, the training loss is 54002687143.01927\n",
            "For 8027th iteration, the training loss is 54002505577.31732\n",
            "For 8028th iteration, the training loss is 54002324014.20292\n",
            "For 8029th iteration, the training loss is 54002142661.07958\n",
            "For 8030th iteration, the training loss is 54001961580.218216\n",
            "For 8031th iteration, the training loss is 54001780303.748924\n",
            "For 8032th iteration, the training loss is 54001599455.91078\n",
            "For 8033th iteration, the training loss is 54001418259.28911\n",
            "For 8034th iteration, the training loss is 54001237432.14777\n",
            "For 8035th iteration, the training loss is 54001055961.77295\n",
            "For 8036th iteration, the training loss is 54000874736.72335\n",
            "For 8037th iteration, the training loss is 54000693207.790115\n",
            "For 8038th iteration, the training loss is 54000512118.80098\n",
            "For 8039th iteration, the training loss is 54000330791.90763\n",
            "For 8040th iteration, the training loss is 54000149947.841415\n",
            "For 8041th iteration, the training loss is 53999968699.14341\n",
            "For 8042th iteration, the training loss is 53999788110.5938\n",
            "For 8043th iteration, the training loss is 53999606901.7398\n",
            "For 8044th iteration, the training loss is 53999426400.02433\n",
            "For 8045th iteration, the training loss is 53999245263.406586\n",
            "For 8046th iteration, the training loss is 53999064846.31835\n",
            "For 8047th iteration, the training loss is 53998883781.5773\n",
            "For 8048th iteration, the training loss is 53998703446.990036\n",
            "For 8049th iteration, the training loss is 53998522382.55127\n",
            "For 8050th iteration, the training loss is 53998342172.498764\n",
            "For 8051th iteration, the training loss is 53998161618.72779\n",
            "For 8052th iteration, the training loss is 53997981498.532845\n",
            "For 8053th iteration, the training loss is 53997800994.30707\n",
            "For 8054th iteration, the training loss is 53997620526.881485\n",
            "For 8055th iteration, the training loss is 53997439625.97507\n",
            "For 8056th iteration, the training loss is 53997258789.22543\n",
            "For 8057th iteration, the training loss is 53997078177.389984\n",
            "For 8058th iteration, the training loss is 53996897759.54669\n",
            "For 8059th iteration, the training loss is 53996717198.96757\n",
            "For 8060th iteration, the training loss is 53996536833.23323\n",
            "For 8061th iteration, the training loss is 53996356323.6608\n",
            "For 8062th iteration, the training loss is 53996176009.80808\n",
            "For 8063th iteration, the training loss is 53995995551.001686\n",
            "For 8064th iteration, the training loss is 53995815176.1717\n",
            "For 8065th iteration, the training loss is 53995635104.02343\n",
            "For 8066th iteration, the training loss is 53995454763.65345\n",
            "For 8067th iteration, the training loss is 53995274617.07867\n",
            "For 8068th iteration, the training loss is 53995094325.3651\n",
            "For 8069th iteration, the training loss is 53994914226.96571\n",
            "For 8070th iteration, the training loss is 53994734307.191124\n",
            "For 8071th iteration, the training loss is 53994554117.23518\n",
            "For 8072th iteration, the training loss is 53994374121.035\n",
            "For 8073th iteration, the training loss is 53994193978.28648\n",
            "For 8074th iteration, the training loss is 53994013917.65975\n",
            "For 8075th iteration, the training loss is 53993834158.24053\n",
            "For 8076th iteration, the training loss is 53993654128.74094\n",
            "For 8077th iteration, the training loss is 53993474291.850044\n",
            "For 8078th iteration, the training loss is 53993294307.76495\n",
            "For 8079th iteration, the training loss is 53993114515.37012\n",
            "For 8080th iteration, the training loss is 53992934679.28758\n",
            "For 8081th iteration, the training loss is 53992755186.11774\n",
            "For 8082th iteration, the training loss is 53992575208.97516\n",
            "For 8083th iteration, the training loss is 53992396034.82999\n",
            "For 8084th iteration, the training loss is 53992216120.26611\n",
            "For 8085th iteration, the training loss is 53992036916.336266\n",
            "For 8086th iteration, the training loss is 53991857065.76243\n",
            "For 8087th iteration, the training loss is 53991677957.59911\n",
            "For 8088th iteration, the training loss is 53991498618.45511\n",
            "For 8089th iteration, the training loss is 53991319576.393616\n",
            "For 8090th iteration, the training loss is 53991139958.60881\n",
            "For 8091th iteration, the training loss is 53990960771.98899\n",
            "For 8092th iteration, the training loss is 53990781231.28403\n",
            "For 8093th iteration, the training loss is 53990601754.1061\n",
            "For 8094th iteration, the training loss is 53990422633.15298\n",
            "For 8095th iteration, the training loss is 53990243239.168686\n",
            "For 8096th iteration, the training loss is 53990064032.63906\n",
            "For 8097th iteration, the training loss is 53989885080.39539\n",
            "For 8098th iteration, the training loss is 53989705957.16595\n",
            "For 8099th iteration, the training loss is 53989526884.76335\n",
            "For 8100th iteration, the training loss is 53989347999.40108\n",
            "For 8101th iteration, the training loss is 53989169293.558784\n",
            "For 8102th iteration, the training loss is 53988989999.15773\n",
            "For 8103th iteration, the training loss is 53988811386.88087\n",
            "For 8104th iteration, the training loss is 53988632478.096535\n",
            "For 8105th iteration, the training loss is 53988453661.98005\n",
            "For 8106th iteration, the training loss is 53988274924.707085\n",
            "For 8107th iteration, the training loss is 53988096477.37054\n",
            "For 8108th iteration, the training loss is 53987917433.47431\n",
            "For 8109th iteration, the training loss is 53987739155.80195\n",
            "For 8110th iteration, the training loss is 53987560530.21911\n",
            "For 8111th iteration, the training loss is 53987382218.48265\n",
            "For 8112th iteration, the training loss is 53987203312.67094\n",
            "For 8113th iteration, the training loss is 53987025166.26725\n",
            "For 8114th iteration, the training loss is 53986846613.20493\n",
            "For 8115th iteration, the training loss is 53986668469.66395\n",
            "For 8116th iteration, the training loss is 53986490048.952\n",
            "For 8117th iteration, the training loss is 53986311999.28695\n",
            "For 8118th iteration, the training loss is 53986133650.71277\n",
            "For 8119th iteration, the training loss is 53985955692.31769\n",
            "For 8120th iteration, the training loss is 53985777415.614136\n",
            "For 8121th iteration, the training loss is 53985599545.97847\n",
            "For 8122th iteration, the training loss is 53985421340.890335\n",
            "For 8123th iteration, the training loss is 53985243557.59537\n",
            "For 8124th iteration, the training loss is 53985065357.771675\n",
            "For 8125th iteration, the training loss is 53984887348.56112\n",
            "For 8126th iteration, the training loss is 53984709136.78902\n",
            "For 8127th iteration, the training loss is 53984531417.99192\n",
            "For 8128th iteration, the training loss is 53984353159.06472\n",
            "For 8129th iteration, the training loss is 53984175072.657776\n",
            "For 8130th iteration, the training loss is 53983996992.57184\n",
            "For 8131th iteration, the training loss is 53983819372.533134\n",
            "For 8132th iteration, the training loss is 53983641250.63319\n",
            "For 8133th iteration, the training loss is 53983463265.318245\n",
            "For 8134th iteration, the training loss is 53983285317.13407\n",
            "For 8135th iteration, the training loss is 53983107790.943756\n",
            "For 8136th iteration, the training loss is 53982929806.61318\n",
            "For 8137th iteration, the training loss is 53982752532.32249\n",
            "For 8138th iteration, the training loss is 53982574595.2432\n",
            "For 8139th iteration, the training loss is 53982396647.098724\n",
            "For 8140th iteration, the training loss is 53982218880.69825\n",
            "For 8141th iteration, the training loss is 53982041744.68425\n",
            "For 8142th iteration, the training loss is 53981863935.401665\n",
            "For 8143th iteration, the training loss is 53981686122.02466\n",
            "For 8144th iteration, the training loss is 53981508484.32981\n",
            "For 8145th iteration, the training loss is 53981331479.03087\n",
            "For 8146th iteration, the training loss is 53981153799.20562\n",
            "For 8147th iteration, the training loss is 53980976113.283585\n",
            "For 8148th iteration, the training loss is 53980798604.60657\n",
            "For 8149th iteration, the training loss is 53980621722.997185\n",
            "For 8150th iteration, the training loss is 53980444174.17957\n",
            "For 8151th iteration, the training loss is 53980266608.91833\n",
            "For 8152th iteration, the training loss is 53980089229.55508\n",
            "For 8153th iteration, the training loss is 53979912465.10757\n",
            "For 8154th iteration, the training loss is 53979735004.75633\n",
            "For 8155th iteration, the training loss is 53979557618.016014\n",
            "For 8156th iteration, the training loss is 53979380363.70119\n",
            "For 8157th iteration, the training loss is 53979203772.102005\n",
            "For 8158th iteration, the training loss is 53979026396.12136\n",
            "For 8159th iteration, the training loss is 53978849062.9371\n",
            "For 8160th iteration, the training loss is 53978671942.4341\n",
            "For 8161th iteration, the training loss is 53978495403.43199\n",
            "For 8162th iteration, the training loss is 53978318283.89382\n",
            "For 8163th iteration, the training loss is 53978141257.393845\n",
            "For 8164th iteration, the training loss is 53977964447.1531\n",
            "For 8165th iteration, the training loss is 53977787800.87138\n",
            "For 8166th iteration, the training loss is 53977610715.6033\n",
            "For 8167th iteration, the training loss is 53977434138.7789\n",
            "For 8168th iteration, the training loss is 53977257123.54418\n",
            "For 8169th iteration, the training loss is 53977080614.61234\n",
            "For 8170th iteration, the training loss is 53976903669.13443\n",
            "For 8171th iteration, the training loss is 53976727366.40504\n",
            "For 8172th iteration, the training loss is 53976550498.206726\n",
            "For 8173th iteration, the training loss is 53976374183.18882\n",
            "For 8174th iteration, the training loss is 53976197383.82133\n",
            "For 8175th iteration, the training loss is 53976021269.076836\n",
            "For 8176th iteration, the training loss is 53975844546.02825\n",
            "For 8177th iteration, the training loss is 53975668414.87209\n",
            "For 8178th iteration, the training loss is 53975491759.80417\n",
            "For 8179th iteration, the training loss is 53975315823.21996\n",
            "For 8180th iteration, the training loss is 53975139191.08579\n",
            "For 8181th iteration, the training loss is 53974963366.26184\n",
            "For 8182th iteration, the training loss is 53974787049.8389\n",
            "For 8183th iteration, the training loss is 53974611224.270744\n",
            "For 8184th iteration, the training loss is 53974435064.48794\n",
            "For 8185th iteration, the training loss is 53974259278.34473\n",
            "For 8186th iteration, the training loss is 53974083185.59177\n",
            "For 8187th iteration, the training loss is 53973907438.242966\n",
            "For 8188th iteration, the training loss is 53973731084.533936\n",
            "For 8189th iteration, the training loss is 53973555470.87344\n",
            "For 8190th iteration, the training loss is 53973379101.37148\n",
            "For 8191th iteration, the training loss is 53973203136.458115\n",
            "For 8192th iteration, the training loss is 53973026778.66507\n",
            "For 8193th iteration, the training loss is 53972851323.9365\n",
            "For 8194th iteration, the training loss is 53972675133.54207\n",
            "For 8195th iteration, the training loss is 53972499703.3628\n",
            "For 8196th iteration, the training loss is 53972323647.64508\n",
            "For 8197th iteration, the training loss is 53972148325.55974\n",
            "For 8198th iteration, the training loss is 53971972342.72136\n",
            "For 8199th iteration, the training loss is 53971796641.19385\n",
            "For 8200th iteration, the training loss is 53971620776.54438\n",
            "For 8201th iteration, the training loss is 53971444938.59573\n",
            "For 8202th iteration, the training loss is 53971269342.325874\n",
            "For 8203th iteration, the training loss is 53971093691.69594\n",
            "For 8204th iteration, the training loss is 53970917867.24796\n",
            "For 8205th iteration, the training loss is 53970742095.67876\n",
            "For 8206th iteration, the training loss is 53970566376.41141\n",
            "For 8207th iteration, the training loss is 53970390708.88018\n",
            "For 8208th iteration, the training loss is 53970215204.96713\n",
            "For 8209th iteration, the training loss is 53970039527.43374\n",
            "For 8210th iteration, the training loss is 53969863902.09699\n",
            "For 8211th iteration, the training loss is 53969688328.39318\n",
            "For 8212th iteration, the training loss is 53969512919.61189\n",
            "For 8213th iteration, the training loss is 53969337724.22315\n",
            "For 8214th iteration, the training loss is 53969162300.77306\n",
            "For 8215th iteration, the training loss is 53968986870.92482\n",
            "For 8216th iteration, the training loss is 53968811752.47922\n",
            "For 8217th iteration, the training loss is 53968636337.415985\n",
            "For 8218th iteration, the training loss is 53968460972.879616\n",
            "For 8219th iteration, the training loss is 53968285769.119545\n",
            "For 8220th iteration, the training loss is 53968110604.14373\n",
            "For 8221th iteration, the training loss is 53967935646.72023\n",
            "For 8222th iteration, the training loss is 53967763976.79215\n",
            "For 8223th iteration, the training loss is 53967592005.59584\n",
            "For 8224th iteration, the training loss is 53967420307.79983\n",
            "For 8225th iteration, the training loss is 53967248811.19069\n",
            "For 8226th iteration, the training loss is 53967076982.41854\n",
            "For 8227th iteration, the training loss is 53966905204.33072\n",
            "For 8228th iteration, the training loss is 53966733719.9746\n",
            "For 8229th iteration, the training loss is 53966562054.58077\n",
            "For 8230th iteration, the training loss is 53966390714.71535\n",
            "For 8231th iteration, the training loss is 53966219040.33068\n",
            "For 8232th iteration, the training loss is 53966047416.82559\n",
            "For 8233th iteration, the training loss is 53965876085.157715\n",
            "For 8234th iteration, the training loss is 53965704684.62258\n",
            "For 8235th iteration, the training loss is 53965533477.32053\n",
            "For 8236th iteration, the training loss is 53965362243.88382\n",
            "For 8237th iteration, the training loss is 53965190855.93055\n",
            "For 8238th iteration, the training loss is 53965019802.28224\n",
            "For 8239th iteration, the training loss is 53964848406.38836\n",
            "For 8240th iteration, the training loss is 53964677029.04247\n",
            "For 8241th iteration, the training loss is 53964505942.93666\n",
            "For 8242th iteration, the training loss is 53964334674.26756\n",
            "For 8243th iteration, the training loss is 53964163724.93748\n",
            "For 8244th iteration, the training loss is 53963992548.64811\n",
            "For 8245th iteration, the training loss is 53963821338.38077\n",
            "For 8246th iteration, the training loss is 53963650413.08972\n",
            "For 8247th iteration, the training loss is 53963479416.9676\n",
            "For 8248th iteration, the training loss is 53963308612.062065\n",
            "For 8249th iteration, the training loss is 53963137785.33719\n",
            "For 8250th iteration, the training loss is 53962966770.69435\n",
            "For 8251th iteration, the training loss is 53962796075.28335\n",
            "For 8252th iteration, the training loss is 53962625148.87623\n",
            "For 8253th iteration, the training loss is 53962454188.881035\n",
            "For 8254th iteration, the training loss is 53962283511.50371\n",
            "For 8255th iteration, the training loss is 53962112762.12644\n",
            "For 8256th iteration, the training loss is 53961942201.01967\n",
            "For 8257th iteration, the training loss is 53961771618.49737\n",
            "For 8258th iteration, the training loss is 53961600846.417984\n",
            "For 8259th iteration, the training loss is 53961430389.128815\n",
            "For 8260th iteration, the training loss is 53961260003.057816\n",
            "For 8261th iteration, the training loss is 53961089485.818634\n",
            "For 8262th iteration, the training loss is 53960919049.20821\n",
            "For 8263th iteration, the training loss is 53960748760.021736\n",
            "For 8264th iteration, the training loss is 53960578226.178764\n",
            "For 8265th iteration, the training loss is 53960408022.805\n",
            "For 8266th iteration, the training loss is 53960237467.09984\n",
            "For 8267th iteration, the training loss is 53960067221.20278\n",
            "For 8268th iteration, the training loss is 53959897037.52996\n",
            "For 8269th iteration, the training loss is 53959726600.22652\n",
            "For 8270th iteration, the training loss is 53959556467.49281\n",
            "For 8271th iteration, the training loss is 53959386415.3132\n",
            "For 8272th iteration, the training loss is 53959216227.3973\n",
            "For 8273th iteration, the training loss is 53959046231.77681\n",
            "For 8274th iteration, the training loss is 53958875913.08595\n",
            "For 8275th iteration, the training loss is 53958705868.396614\n",
            "For 8276th iteration, the training loss is 53958535908.60544\n",
            "For 8277th iteration, the training loss is 53958366081.69673\n",
            "For 8278th iteration, the training loss is 53958195989.230965\n",
            "For 8279th iteration, the training loss is 53958025884.42036\n",
            "For 8280th iteration, the training loss is 53957856044.0122\n",
            "For 8281th iteration, the training loss is 53957686127.35164\n",
            "For 8282th iteration, the training loss is 53957516397.74298\n",
            "For 8283th iteration, the training loss is 53957346635.10076\n",
            "For 8284th iteration, the training loss is 53957176680.63532\n",
            "For 8285th iteration, the training loss is 53957007034.07531\n",
            "For 8286th iteration, the training loss is 53956837456.76487\n",
            "For 8287th iteration, the training loss is 53956667743.02125\n",
            "For 8288th iteration, the training loss is 53956498221.19563\n",
            "For 8289th iteration, the training loss is 53956328371.77948\n",
            "For 8290th iteration, the training loss is 53956158793.05535\n",
            "For 8291th iteration, the training loss is 53955989296.59108\n",
            "For 8292th iteration, the training loss is 53955819804.47055\n",
            "For 8293th iteration, the training loss is 53955650452.802864\n",
            "For 8294th iteration, the training loss is 53955480850.59448\n",
            "For 8295th iteration, the training loss is 53955311568.17422\n",
            "For 8296th iteration, the training loss is 53955142043.32945\n",
            "For 8297th iteration, the training loss is 53954972732.07749\n",
            "For 8298th iteration, the training loss is 53954803479.79266\n",
            "For 8299th iteration, the training loss is 53954634447.040405\n",
            "For 8300th iteration, the training loss is 53954465279.41133\n",
            "For 8301th iteration, the training loss is 53954295854.23755\n",
            "For 8302th iteration, the training loss is 53954126730.174034\n",
            "For 8303th iteration, the training loss is 53953957580.07052\n",
            "For 8304th iteration, the training loss is 53953788343.33499\n",
            "For 8305th iteration, the training loss is 53953619270.286194\n",
            "For 8306th iteration, the training loss is 53953450287.59797\n",
            "For 8307th iteration, the training loss is 53953281046.06338\n",
            "For 8308th iteration, the training loss is 53953112103.0002\n",
            "For 8309th iteration, the training loss is 53952943233.27176\n",
            "For 8310th iteration, the training loss is 53952774219.9435\n",
            "For 8311th iteration, the training loss is 53952605384.8108\n",
            "For 8312th iteration, the training loss is 53952436517.961555\n",
            "For 8313th iteration, the training loss is 53952267560.33517\n",
            "For 8314th iteration, the training loss is 53952098836.42267\n",
            "For 8315th iteration, the training loss is 53951929871.97722\n",
            "For 8316th iteration, the training loss is 53951761144.80043\n",
            "For 8317th iteration, the training loss is 53951592474.472534\n",
            "For 8318th iteration, the training loss is 53951424004.664\n",
            "For 8319th iteration, the training loss is 53951255378.22393\n",
            "For 8320th iteration, the training loss is 53951086865.27821\n",
            "For 8321th iteration, the training loss is 53950917997.344055\n",
            "For 8322th iteration, the training loss is 53950749615.0367\n",
            "For 8323th iteration, the training loss is 53950581111.73455\n",
            "For 8324th iteration, the training loss is 53950412771.643715\n",
            "For 8325th iteration, the training loss is 53950244235.483665\n",
            "For 8326th iteration, the training loss is 53950076001.29686\n",
            "For 8327th iteration, the training loss is 53949907472.34625\n",
            "For 8328th iteration, the training loss is 53949739264.00829\n",
            "For 8329th iteration, the training loss is 53949570857.80753\n",
            "For 8330th iteration, the training loss is 53949402752.01004\n",
            "For 8331th iteration, the training loss is 53949234444.784935\n",
            "For 8332th iteration, the training loss is 53949066400.40028\n",
            "For 8333th iteration, the training loss is 53948898125.06855\n",
            "For 8334th iteration, the training loss is 53948730180.87445\n",
            "For 8335th iteration, the training loss is 53948562004.38054\n",
            "For 8336th iteration, the training loss is 53948394115.30115\n",
            "For 8337th iteration, the training loss is 53948225970.1999\n",
            "For 8338th iteration, the training loss is 53948058178.708244\n",
            "For 8339th iteration, the training loss is 53947890106.75748\n",
            "For 8340th iteration, the training loss is 53947722286.95705\n",
            "For 8341th iteration, the training loss is 53947554188.810036\n",
            "For 8342th iteration, the training loss is 53947386234.6414\n",
            "For 8343th iteration, the training loss is 53947218447.50395\n",
            "For 8344th iteration, the training loss is 53947050459.757515\n",
            "For 8345th iteration, the training loss is 53946882666.04798\n",
            "For 8346th iteration, the training loss is 53946714702.51909\n",
            "For 8347th iteration, the training loss is 53946546676.42883\n",
            "For 8348th iteration, the training loss is 53946378809.629776\n",
            "For 8349th iteration, the training loss is 53946211136.79685\n",
            "For 8350th iteration, the training loss is 53946043292.02738\n",
            "For 8351th iteration, the training loss is 53945875384.97045\n",
            "For 8352th iteration, the training loss is 53945707748.11137\n",
            "For 8353th iteration, the training loss is 53945540175.759285\n",
            "For 8354th iteration, the training loss is 53945372734.77576\n",
            "For 8355th iteration, the training loss is 53945205030.820015\n",
            "For 8356th iteration, the training loss is 53945037621.04007\n",
            "For 8357th iteration, the training loss is 53944870170.63994\n",
            "For 8358th iteration, the training loss is 53944702395.82805\n",
            "For 8359th iteration, the training loss is 53944535261.53941\n",
            "For 8360th iteration, the training loss is 53944367730.3289\n",
            "For 8361th iteration, the training loss is 53944200157.19648\n",
            "For 8362th iteration, the training loss is 53944032841.01749\n",
            "For 8363th iteration, the training loss is 53943865679.84863\n",
            "For 8364th iteration, the training loss is 53943698471.3795\n",
            "For 8365th iteration, the training loss is 53943531367.082855\n",
            "For 8366th iteration, the training loss is 53943363922.214836\n",
            "For 8367th iteration, the training loss is 53943196723.949135\n",
            "For 8368th iteration, the training loss is 53943029690.11113\n",
            "For 8369th iteration, the training loss is 53942862566.237564\n",
            "For 8370th iteration, the training loss is 53942695621.270836\n",
            "For 8371th iteration, the training loss is 53942528318.621284\n",
            "For 8372th iteration, the training loss is 53942361315.97607\n",
            "For 8373th iteration, the training loss is 53942194375.804756\n",
            "For 8374th iteration, the training loss is 53942027533.08134\n",
            "For 8375th iteration, the training loss is 53941860736.33757\n",
            "For 8376th iteration, the training loss is 53941693674.58013\n",
            "For 8377th iteration, the training loss is 53941526904.69663\n",
            "For 8378th iteration, the training loss is 53941360089.16732\n",
            "For 8379th iteration, the training loss is 53941193418.28974\n",
            "For 8380th iteration, the training loss is 53941026698.45123\n",
            "For 8381th iteration, the training loss is 53940860077.09313\n",
            "For 8382th iteration, the training loss is 53940693204.3624\n",
            "For 8383th iteration, the training loss is 53940526548.103584\n",
            "For 8384th iteration, the training loss is 53940359948.30963\n",
            "For 8385th iteration, the training loss is 53940193445.630035\n",
            "For 8386th iteration, the training loss is 53940026608.50117\n",
            "For 8387th iteration, the training loss is 53939860459.187065\n",
            "For 8388th iteration, the training loss is 53939693800.799675\n",
            "For 8389th iteration, the training loss is 53939527476.93438\n",
            "For 8390th iteration, the training loss is 53939360978.205\n",
            "For 8391th iteration, the training loss is 53939194841.711365\n",
            "For 8392th iteration, the training loss is 53939028410.77544\n",
            "For 8393th iteration, the training loss is 53938862160.8215\n",
            "For 8394th iteration, the training loss is 53938695977.479866\n",
            "For 8395th iteration, the training loss is 53938529816.98593\n",
            "For 8396th iteration, the training loss is 53938363708.804634\n",
            "For 8397th iteration, the training loss is 53938197635.25155\n",
            "For 8398th iteration, the training loss is 53938031293.75896\n",
            "For 8399th iteration, the training loss is 53937865510.40543\n",
            "For 8400th iteration, the training loss is 53937699320.309044\n",
            "For 8401th iteration, the training loss is 53937533434.92106\n",
            "For 8402th iteration, the training loss is 53937367249.1627\n",
            "For 8403th iteration, the training loss is 53937201497.478035\n",
            "For 8404th iteration, the training loss is 53937035441.6356\n",
            "For 8405th iteration, the training loss is 53936869742.72027\n",
            "For 8406th iteration, the training loss is 53936703743.67118\n",
            "For 8407th iteration, the training loss is 53936538086.9007\n",
            "For 8408th iteration, the training loss is 53936372155.8509\n",
            "For 8409th iteration, the training loss is 53936206552.15452\n",
            "For 8410th iteration, the training loss is 53936040677.85484\n",
            "For 8411th iteration, the training loss is 53935875111.94438\n",
            "For 8412th iteration, the training loss is 53935709241.4243\n",
            "For 8413th iteration, the training loss is 53935543800.952515\n",
            "For 8414th iteration, the training loss is 53935378059.636665\n",
            "For 8415th iteration, the training loss is 53935212664.584366\n",
            "For 8416th iteration, the training loss is 53935046979.90562\n",
            "For 8417th iteration, the training loss is 53934881618.9496\n",
            "For 8418th iteration, the training loss is 53934716001.63792\n",
            "For 8419th iteration, the training loss is 53934550687.92841\n",
            "For 8420th iteration, the training loss is 53934385127.2262\n",
            "For 8421th iteration, the training loss is 53934219842.8202\n",
            "For 8422th iteration, the training loss is 53934054374.5476\n",
            "For 8423th iteration, the training loss is 53933889249.44815\n",
            "For 8424th iteration, the training loss is 53933723847.160614\n",
            "For 8425th iteration, the training loss is 53933558711.38512\n",
            "For 8426th iteration, the training loss is 53933393338.70956\n",
            "For 8427th iteration, the training loss is 53933228227.598236\n",
            "For 8428th iteration, the training loss is 53933062921.813736\n",
            "For 8429th iteration, the training loss is 53932898017.38876\n",
            "For 8430th iteration, the training loss is 53932732714.11175\n",
            "For 8431th iteration, the training loss is 53932567752.97612\n",
            "For 8432th iteration, the training loss is 53932402609.426834\n",
            "For 8433th iteration, the training loss is 53932237815.66389\n",
            "For 8434th iteration, the training loss is 53932072701.118835\n",
            "For 8435th iteration, the training loss is 53931907935.531555\n",
            "For 8436th iteration, the training loss is 53931742877.3657\n",
            "For 8437th iteration, the training loss is 53931578130.74933\n",
            "For 8438th iteration, the training loss is 53931413138.68254\n",
            "For 8439th iteration, the training loss is 53931248425.27306\n",
            "For 8440th iteration, the training loss is 53931083529.73127\n",
            "For 8441th iteration, the training loss is 53930918976.8623\n",
            "For 8442th iteration, the training loss is 53930754046.39061\n",
            "For 8443th iteration, the training loss is 53930589592.33053\n",
            "For 8444th iteration, the training loss is 53930424790.0186\n",
            "For 8445th iteration, the training loss is 53930260353.83327\n",
            "For 8446th iteration, the training loss is 53930095649.83268\n",
            "For 8447th iteration, the training loss is 53929931208.10982\n",
            "For 8448th iteration, the training loss is 53929766562.3726\n",
            "For 8449th iteration, the training loss is 53929602275.257286\n",
            "For 8450th iteration, the training loss is 53929437595.31572\n",
            "For 8451th iteration, the training loss is 53929273400.06595\n",
            "For 8452th iteration, the training loss is 53929108846.55047\n",
            "For 8453th iteration, the training loss is 53928944662.57408\n",
            "For 8454th iteration, the training loss is 53928780206.66019\n",
            "For 8455th iteration, the training loss is 53928616011.24111\n",
            "For 8456th iteration, the training loss is 53928451613.18342\n",
            "For 8457th iteration, the training loss is 53928287565.6693\n",
            "For 8458th iteration, the training loss is 53928123196.88896\n",
            "For 8459th iteration, the training loss is 53927959160.998085\n",
            "For 8460th iteration, the training loss is 53927794888.27925\n",
            "For 8461th iteration, the training loss is 53927630998.11488\n",
            "For 8462th iteration, the training loss is 53927466688.761086\n",
            "For 8463th iteration, the training loss is 53927302880.1746\n",
            "For 8464th iteration, the training loss is 53927138698.293785\n",
            "For 8465th iteration, the training loss is 53926974891.2967\n",
            "For 8466th iteration, the training loss is 53926810805.94249\n",
            "For 8467th iteration, the training loss is 53926646978.75377\n",
            "For 8468th iteration, the training loss is 53926482950.67785\n",
            "For 8469th iteration, the training loss is 53926319261.36021\n",
            "For 8470th iteration, the training loss is 53926155288.80652\n",
            "For 8471th iteration, the training loss is 53925991716.92897\n",
            "For 8472th iteration, the training loss is 53925827781.43284\n",
            "For 8473th iteration, the training loss is 53925664206.79117\n",
            "For 8474th iteration, the training loss is 53925500366.57909\n",
            "For 8475th iteration, the training loss is 53925336927.69081\n",
            "For 8476th iteration, the training loss is 53925173051.16845\n",
            "For 8477th iteration, the training loss is 53925009520.139915\n",
            "For 8478th iteration, the training loss is 53924845472.98398\n",
            "For 8479th iteration, the training loss is 53924682010.24028\n",
            "For 8480th iteration, the training loss is 53924518007.95969\n",
            "For 8481th iteration, the training loss is 53924354742.116806\n",
            "For 8482th iteration, the training loss is 53924191108.19953\n",
            "For 8483th iteration, the training loss is 53924027833.04853\n",
            "For 8484th iteration, the training loss is 53923864293.62937\n",
            "For 8485th iteration, the training loss is 53923701146.17253\n",
            "For 8486th iteration, the training loss is 53923537570.47717\n",
            "For 8487th iteration, the training loss is 53923374486.14551\n",
            "For 8488th iteration, the training loss is 53923211036.431435\n",
            "For 8489th iteration, the training loss is 53923047938.44171\n",
            "For 8490th iteration, the training loss is 53922884582.23976\n",
            "For 8491th iteration, the training loss is 53922721607.445114\n",
            "For 8492th iteration, the training loss is 53922558279.803345\n",
            "For 8493th iteration, the training loss is 53922395290.08417\n",
            "For 8494th iteration, the training loss is 53922232055.11689\n",
            "For 8495th iteration, the training loss is 53922069184.83884\n",
            "For 8496th iteration, the training loss is 53921905915.5841\n",
            "For 8497th iteration, the training loss is 53921743101.86104\n",
            "For 8498th iteration, the training loss is 53921579957.554115\n",
            "For 8499th iteration, the training loss is 53921417126.582886\n",
            "For 8500th iteration, the training loss is 53921253747.94178\n",
            "For 8501th iteration, the training loss is 53921090829.1361\n",
            "For 8502th iteration, the training loss is 53920927708.21298\n",
            "For 8503th iteration, the training loss is 53920764428.34312\n",
            "For 8504th iteration, the training loss is 53920601342.44808\n",
            "For 8505th iteration, the training loss is 53920438395.031425\n",
            "For 8506th iteration, the training loss is 53920275472.155785\n",
            "For 8507th iteration, the training loss is 53920112627.1414\n",
            "For 8508th iteration, the training loss is 53919949901.56034\n",
            "For 8509th iteration, the training loss is 53919786757.8157\n",
            "For 8510th iteration, the training loss is 53919623979.52432\n",
            "For 8511th iteration, the training loss is 53919461328.280136\n",
            "For 8512th iteration, the training loss is 53919298633.13392\n",
            "For 8513th iteration, the training loss is 53919136054.81917\n",
            "For 8514th iteration, the training loss is 53918973058.11268\n",
            "For 8515th iteration, the training loss is 53918810426.51288\n",
            "For 8516th iteration, the training loss is 53918647920.68452\n",
            "For 8517th iteration, the training loss is 53918485370.170395\n",
            "For 8518th iteration, the training loss is 53918322829.97931\n",
            "For 8519th iteration, the training loss is 53918160333.27119\n",
            "For 8520th iteration, the training loss is 53917997955.39018\n",
            "For 8521th iteration, the training loss is 53917835156.0544\n",
            "For 8522th iteration, the training loss is 53917672840.59372\n",
            "For 8523th iteration, the training loss is 53917510459.4566\n",
            "For 8524th iteration, the training loss is 53917348086.377014\n",
            "For 8525th iteration, the training loss is 53917185915.14951\n",
            "For 8526th iteration, the training loss is 53917023519.13282\n",
            "For 8527th iteration, the training loss is 53916861011.11487\n",
            "For 8528th iteration, the training loss is 53916698417.20701\n",
            "For 8529th iteration, the training loss is 53916536306.79245\n",
            "For 8530th iteration, the training loss is 53916374123.48471\n",
            "For 8531th iteration, the training loss is 53916211952.10009\n",
            "For 8532th iteration, the training loss is 53916049977.607185\n",
            "For 8533th iteration, the training loss is 53915887890.755295\n",
            "For 8534th iteration, the training loss is 53915725957.30356\n",
            "For 8535th iteration, the training loss is 53915563649.6172\n",
            "For 8536th iteration, the training loss is 53915402025.71162\n",
            "For 8537th iteration, the training loss is 53915239968.90273\n",
            "For 8538th iteration, the training loss is 53915078202.34112\n",
            "For 8539th iteration, the training loss is 53914916174.11472\n",
            "For 8540th iteration, the training loss is 53914754440.95614\n",
            "For 8541th iteration, the training loss is 53914592537.32643\n",
            "For 8542th iteration, the training loss is 53914430928.08528\n",
            "For 8543th iteration, the training loss is 53914269085.63713\n",
            "For 8544th iteration, the training loss is 53914107596.55529\n",
            "For 8545th iteration, the training loss is 53913945840.37967\n",
            "For 8546th iteration, the training loss is 53913784416.95455\n",
            "For 8547th iteration, the training loss is 53913622696.00463\n",
            "For 8548th iteration, the training loss is 53913461387.43058\n",
            "For 8549th iteration, the training loss is 53913299752.62483\n",
            "For 8550th iteration, the training loss is 53913138504.64273\n",
            "For 8551th iteration, the training loss is 53912976904.75843\n",
            "For 8552th iteration, the training loss is 53912818735.4862\n",
            "For 8553th iteration, the training loss is 53912660343.59794\n",
            "For 8554th iteration, the training loss is 53912502278.69615\n",
            "For 8555th iteration, the training loss is 53912343935.549\n",
            "For 8556th iteration, the training loss is 53912185928.74802\n",
            "For 8557th iteration, the training loss is 53912027618.217834\n",
            "For 8558th iteration, the training loss is 53911869718.88509\n",
            "For 8559th iteration, the training loss is 53911711467.2905\n",
            "For 8560th iteration, the training loss is 53911553390.23086\n",
            "For 8561th iteration, the training loss is 53911395068.43676\n",
            "For 8562th iteration, the training loss is 53911237173.16694\n",
            "For 8563th iteration, the training loss is 53911078934.08954\n",
            "For 8564th iteration, the training loss is 53910921214.724\n",
            "For 8565th iteration, the training loss is 53910763177.687836\n",
            "For 8566th iteration, the training loss is 53910605380.678665\n",
            "For 8567th iteration, the training loss is 53910447342.412315\n",
            "For 8568th iteration, the training loss is 53910289702.25933\n",
            "For 8569th iteration, the training loss is 53910131751.02185\n",
            "For 8570th iteration, the training loss is 53909974208.69823\n",
            "For 8571th iteration, the training loss is 53909816253.37975\n",
            "For 8572th iteration, the training loss is 53909658715.43483\n",
            "For 8573th iteration, the training loss is 53909500880.997894\n",
            "For 8574th iteration, the training loss is 53909343438.4864\n",
            "For 8575th iteration, the training loss is 53909185662.48924\n",
            "For 8576th iteration, the training loss is 53909028152.778435\n",
            "For 8577th iteration, the training loss is 53908870651.507545\n",
            "For 8578th iteration, the training loss is 53908713248.73728\n",
            "For 8579th iteration, the training loss is 53908555486.99773\n",
            "For 8580th iteration, the training loss is 53908398248.55844\n",
            "For 8581th iteration, the training loss is 53908240686.85222\n",
            "For 8582th iteration, the training loss is 53908083357.72231\n",
            "For 8583th iteration, the training loss is 53907925860.85281\n",
            "For 8584th iteration, the training loss is 53907768607.474335\n",
            "For 8585th iteration, the training loss is 53907611162.64256\n",
            "For 8586th iteration, the training loss is 53907453962.330574\n",
            "For 8587th iteration, the training loss is 53907296515.70965\n",
            "For 8588th iteration, the training loss is 53907139456.75024\n",
            "For 8589th iteration, the training loss is 53906982137.80384\n",
            "For 8590th iteration, the training loss is 53906825020.7455\n",
            "For 8591th iteration, the training loss is 53906667615.72645\n",
            "For 8592th iteration, the training loss is 53906510314.53947\n",
            "For 8593th iteration, the training loss is 53906353180.455414\n",
            "For 8594th iteration, the training loss is 53906195813.90172\n",
            "For 8595th iteration, the training loss is 53906038550.473694\n",
            "For 8596th iteration, the training loss is 53905881506.313416\n",
            "For 8597th iteration, the training loss is 53905724342.65843\n",
            "For 8598th iteration, the training loss is 53905567154.94752\n",
            "For 8599th iteration, the training loss is 53905410189.80203\n",
            "For 8600th iteration, the training loss is 53905252991.35431\n",
            "For 8601th iteration, the training loss is 53905095894.20933\n",
            "For 8602th iteration, the training loss is 53904939016.52122\n",
            "For 8603th iteration, the training loss is 53904781905.70348\n",
            "For 8604th iteration, the training loss is 53904625018.29959\n",
            "For 8605th iteration, the training loss is 53904468255.376976\n",
            "For 8606th iteration, the training loss is 53904311371.70056\n",
            "For 8607th iteration, the training loss is 53904154475.4707\n",
            "For 8608th iteration, the training loss is 53903997678.65365\n",
            "For 8609th iteration, the training loss is 53903840738.55328\n",
            "For 8610th iteration, the training loss is 53903684020.53084\n",
            "For 8611th iteration, the training loss is 53903527349.59229\n",
            "For 8612th iteration, the training loss is 53903370716.674614\n",
            "For 8613th iteration, the training loss is 53903214010.3146\n",
            "For 8614th iteration, the training loss is 53903057434.95885\n",
            "For 8615th iteration, the training loss is 53902900889.69411\n",
            "For 8616th iteration, the training loss is 53902744381.32744\n",
            "For 8617th iteration, the training loss is 53902587839.92478\n",
            "For 8618th iteration, the training loss is 53902431267.42597\n",
            "For 8619th iteration, the training loss is 53902274790.66613\n",
            "For 8620th iteration, the training loss is 53902118438.4454\n",
            "For 8621th iteration, the training loss is 53901961964.09744\n",
            "For 8622th iteration, the training loss is 53901805591.61898\n",
            "For 8623th iteration, the training loss is 53901649161.44905\n",
            "For 8624th iteration, the training loss is 53901492810.46266\n",
            "For 8625th iteration, the training loss is 53901336586.36351\n",
            "For 8626th iteration, the training loss is 53901180239.78049\n",
            "For 8627th iteration, the training loss is 53901023990.77979\n",
            "For 8628th iteration, the training loss is 53900867785.50801\n",
            "For 8629th iteration, the training loss is 53900711614.79467\n",
            "For 8630th iteration, the training loss is 53900555379.499664\n",
            "For 8631th iteration, the training loss is 53900399227.296814\n",
            "For 8632th iteration, the training loss is 53900243196.11281\n",
            "For 8633th iteration, the training loss is 53900087041.768265\n",
            "For 8634th iteration, the training loss is 53899930987.18539\n",
            "For 8635th iteration, the training loss is 53899774972.11517\n",
            "For 8636th iteration, the training loss is 53899618993.0289\n",
            "For 8637th iteration, the training loss is 53899462947.15345\n",
            "For 8638th iteration, the training loss is 53899306983.95901\n",
            "For 8639th iteration, the training loss is 53899151139.212\n",
            "For 8640th iteration, the training loss is 53898995170.71175\n",
            "For 8641th iteration, the training loss is 53898839301.302315\n",
            "For 8642th iteration, the training loss is 53898683471.22628\n",
            "For 8643th iteration, the training loss is 53898527552.4616\n",
            "For 8644th iteration, the training loss is 53898371833.711235\n",
            "For 8645th iteration, the training loss is 53898215990.899864\n",
            "For 8646th iteration, the training loss is 53898060239.151276\n",
            "For 8647th iteration, the training loss is 53897904506.36774\n",
            "For 8648th iteration, the training loss is 53897748599.749855\n",
            "For 8649th iteration, the training loss is 53897593179.753235\n",
            "For 8650th iteration, the training loss is 53897437596.70792\n",
            "For 8651th iteration, the training loss is 53897282118.76765\n",
            "For 8652th iteration, the training loss is 53897126635.951195\n",
            "For 8653th iteration, the training loss is 53896971298.4307\n",
            "For 8654th iteration, the training loss is 53896815930.5176\n",
            "For 8655th iteration, the training loss is 53896660516.770706\n",
            "For 8656th iteration, the training loss is 53896505394.24725\n",
            "For 8657th iteration, the training loss is 53896350091.08847\n",
            "For 8658th iteration, the training loss is 53896194756.86584\n",
            "For 8659th iteration, the training loss is 53896039344.78049\n",
            "For 8660th iteration, the training loss is 53895884119.39187\n",
            "For 8661th iteration, the training loss is 53895728767.80206\n",
            "For 8662th iteration, the training loss is 53895573508.6489\n",
            "For 8663th iteration, the training loss is 53895418362.30685\n",
            "For 8664th iteration, the training loss is 53895262976.365005\n",
            "For 8665th iteration, the training loss is 53895107810.29182\n",
            "For 8666th iteration, the training loss is 53894952675.20897\n",
            "For 8667th iteration, the training loss is 53894797570.47448\n",
            "For 8668th iteration, the training loss is 53894642492.325134\n",
            "For 8669th iteration, the training loss is 53894487447.960686\n",
            "For 8670th iteration, the training loss is 53894332426.20087\n",
            "For 8671th iteration, the training loss is 53894177427.366165\n",
            "For 8672th iteration, the training loss is 53894022499.99457\n",
            "For 8673th iteration, the training loss is 53893867445.716835\n",
            "For 8674th iteration, the training loss is 53893712470.09684\n",
            "For 8675th iteration, the training loss is 53893557516.577965\n",
            "For 8676th iteration, the training loss is 53893402719.591774\n",
            "For 8677th iteration, the training loss is 53893247912.24094\n",
            "For 8678th iteration, the training loss is 53893092864.13355\n",
            "For 8679th iteration, the training loss is 53892938292.8869\n",
            "For 8680th iteration, the training loss is 53892783558.132614\n",
            "For 8681th iteration, the training loss is 53892628909.549675\n",
            "For 8682th iteration, the training loss is 53892474223.58455\n",
            "For 8683th iteration, the training loss is 53892319575.82455\n",
            "For 8684th iteration, the training loss is 53892165228.18821\n",
            "For 8685th iteration, the training loss is 53892010681.4254\n",
            "For 8686th iteration, the training loss is 53891856117.87457\n",
            "For 8687th iteration, the training loss is 53891701577.965515\n",
            "For 8688th iteration, the training loss is 53891547066.1474\n",
            "For 8689th iteration, the training loss is 53891392577.65915\n",
            "For 8690th iteration, the training loss is 53891238190.65644\n",
            "For 8691th iteration, the training loss is 53891083674.53135\n",
            "For 8692th iteration, the training loss is 53890929244.59493\n",
            "For 8693th iteration, the training loss is 53890774923.941765\n",
            "For 8694th iteration, the training loss is 53890620474.09811\n",
            "For 8695th iteration, the training loss is 53890466102.2605\n",
            "For 8696th iteration, the training loss is 53890311847.65945\n",
            "For 8697th iteration, the training loss is 53890157350.71525\n",
            "For 8698th iteration, the training loss is 53890003335.20726\n",
            "For 8699th iteration, the training loss is 53889849137.11776\n",
            "For 8700th iteration, the training loss is 53889695037.6675\n",
            "For 8701th iteration, the training loss is 53889540886.24623\n",
            "For 8702th iteration, the training loss is 53889386774.10811\n",
            "For 8703th iteration, the training loss is 53889232957.02772\n",
            "For 8704th iteration, the training loss is 53889078937.82578\n",
            "For 8705th iteration, the training loss is 53888924901.31662\n",
            "For 8706th iteration, the training loss is 53888770881.18483\n",
            "For 8707th iteration, the training loss is 53888616964.42618\n",
            "For 8708th iteration, the training loss is 53888462916.972885\n",
            "For 8709th iteration, the training loss is 53888308944.895386\n",
            "For 8710th iteration, the training loss is 53888155087.60437\n",
            "For 8711th iteration, the training loss is 53888001099.63434\n",
            "For 8712th iteration, the training loss is 53887847457.00346\n",
            "For 8713th iteration, the training loss is 53887693935.45641\n",
            "For 8714th iteration, the training loss is 53887540172.85986\n",
            "For 8715th iteration, the training loss is 53887386475.31515\n",
            "For 8716th iteration, the training loss is 53887232532.972115\n",
            "For 8717th iteration, the training loss is 53887078787.81804\n",
            "For 8718th iteration, the training loss is 53886925155.67889\n",
            "For 8719th iteration, the training loss is 53886771392.082214\n",
            "For 8720th iteration, the training loss is 53886617970.95168\n",
            "For 8721th iteration, the training loss is 53886464571.09362\n",
            "For 8722th iteration, the training loss is 53886310998.6691\n",
            "For 8723th iteration, the training loss is 53886157504.43202\n",
            "For 8724th iteration, the training loss is 53886004099.822365\n",
            "For 8725th iteration, the training loss is 53885850672.19327\n",
            "For 8726th iteration, the training loss is 53885696998.85235\n",
            "For 8727th iteration, the training loss is 53885543512.42101\n",
            "For 8728th iteration, the training loss is 53885390146.538635\n",
            "For 8729th iteration, the training loss is 53885236976.19753\n",
            "For 8730th iteration, the training loss is 53885083666.762024\n",
            "For 8731th iteration, the training loss is 53884930442.03297\n",
            "For 8732th iteration, the training loss is 53884777197.64246\n",
            "For 8733th iteration, the training loss is 53884624158.64733\n",
            "For 8734th iteration, the training loss is 53884471099.46205\n",
            "For 8735th iteration, the training loss is 53884317943.93273\n",
            "For 8736th iteration, the training loss is 53884164770.07134\n",
            "For 8737th iteration, the training loss is 53884011602.10005\n",
            "For 8738th iteration, the training loss is 53883858468.240105\n",
            "For 8739th iteration, the training loss is 53883705331.27828\n",
            "For 8740th iteration, the training loss is 53883552307.13349\n",
            "For 8741th iteration, the training loss is 53883399480.47511\n",
            "For 8742th iteration, the training loss is 53883246408.5045\n",
            "For 8743th iteration, the training loss is 53883093587.14666\n",
            "For 8744th iteration, the training loss is 53882940668.3173\n",
            "For 8745th iteration, the training loss is 53882787833.82637\n",
            "For 8746th iteration, the training loss is 53882634975.969864\n",
            "For 8747th iteration, the training loss is 53882482320.9896\n",
            "For 8748th iteration, the training loss is 53882329745.17664\n",
            "For 8749th iteration, the training loss is 53882176992.531784\n",
            "For 8750th iteration, the training loss is 53882024471.95012\n",
            "For 8751th iteration, the training loss is 53881871826.53115\n",
            "For 8752th iteration, the training loss is 53881719295.35586\n",
            "For 8753th iteration, the training loss is 53881566691.49046\n",
            "For 8754th iteration, the training loss is 53881414303.1263\n",
            "For 8755th iteration, the training loss is 53881261803.054955\n",
            "For 8756th iteration, the training loss is 53881109492.83822\n",
            "For 8757th iteration, the training loss is 53880957093.7917\n",
            "For 8758th iteration, the training loss is 53880804815.267044\n",
            "For 8759th iteration, the training loss is 53880652311.53978\n",
            "For 8760th iteration, the training loss is 53880499872.339165\n",
            "For 8761th iteration, the training loss is 53880347290.49422\n",
            "For 8762th iteration, the training loss is 53880194819.93425\n",
            "For 8763th iteration, the training loss is 53880042454.06702\n",
            "For 8764th iteration, the training loss is 53879890282.7806\n",
            "For 8765th iteration, the training loss is 53879737962.50743\n",
            "For 8766th iteration, the training loss is 53879585722.4688\n",
            "For 8767th iteration, the training loss is 53879433354.99326\n",
            "For 8768th iteration, the training loss is 53879281232.48008\n",
            "For 8769th iteration, the training loss is 53879129011.803734\n",
            "For 8770th iteration, the training loss is 53878976983.91025\n",
            "For 8771th iteration, the training loss is 53878825090.647934\n",
            "For 8772th iteration, the training loss is 53878672934.14171\n",
            "For 8773th iteration, the training loss is 53878520964.11246\n",
            "For 8774th iteration, the training loss is 53878368884.3433\n",
            "For 8775th iteration, the training loss is 53878217108.65642\n",
            "For 8776th iteration, the training loss is 53878065070.641365\n",
            "For 8777th iteration, the training loss is 53877913307.14082\n",
            "For 8778th iteration, the training loss is 53877761407.43512\n",
            "For 8779th iteration, the training loss is 53877609717.57882\n",
            "For 8780th iteration, the training loss is 53877457909.17341\n",
            "For 8781th iteration, the training loss is 53877306201.53709\n",
            "For 8782th iteration, the training loss is 53877154419.71862\n",
            "For 8783th iteration, the training loss is 53877002848.5082\n",
            "For 8784th iteration, the training loss is 53876851155.706314\n",
            "For 8785th iteration, the training loss is 53876699656.071\n",
            "For 8786th iteration, the training loss is 53876548050.07073\n",
            "For 8787th iteration, the training loss is 53876396621.03288\n",
            "For 8788th iteration, the training loss is 53876244818.57238\n",
            "For 8789th iteration, the training loss is 53876093142.39007\n",
            "For 8790th iteration, the training loss is 53875941647.322716\n",
            "For 8791th iteration, the training loss is 53875790046.66863\n",
            "For 8792th iteration, the training loss is 53875638627.250786\n",
            "For 8793th iteration, the training loss is 53875487064.8005\n",
            "For 8794th iteration, the training loss is 53875335682.06645\n",
            "For 8795th iteration, the training loss is 53875184093.06385\n",
            "For 8796th iteration, the training loss is 53875032654.5338\n",
            "For 8797th iteration, the training loss is 53874881469.90267\n",
            "For 8798th iteration, the training loss is 53874730164.443474\n",
            "For 8799th iteration, the training loss is 53874579058.808716\n",
            "For 8800th iteration, the training loss is 53874427798.697876\n",
            "For 8801th iteration, the training loss is 53874276736.059326\n",
            "For 8802th iteration, the training loss is 53874125555.4615\n",
            "For 8803th iteration, the training loss is 53873974560.21754\n",
            "For 8804th iteration, the training loss is 53873823457.2713\n",
            "For 8805th iteration, the training loss is 53873672437.65951\n",
            "For 8806th iteration, the training loss is 53873521348.47181\n",
            "For 8807th iteration, the training loss is 53873370460.399414\n",
            "For 8808th iteration, the training loss is 53873219447.55376\n",
            "For 8809th iteration, the training loss is 53873068625.4893\n",
            "For 8810th iteration, the training loss is 53872917687.24171\n",
            "For 8811th iteration, the training loss is 53872766930.42432\n",
            "For 8812th iteration, the training loss is 53872615783.41191\n",
            "For 8813th iteration, the training loss is 53872464765.88963\n",
            "For 8814th iteration, the training loss is 53872313830.22587\n",
            "For 8815th iteration, the training loss is 53872163113.94361\n",
            "For 8816th iteration, the training loss is 53872012185.59247\n",
            "For 8817th iteration, the training loss is 53871861343.860115\n",
            "For 8818th iteration, the training loss is 53871710361.16646\n",
            "For 8819th iteration, the training loss is 53871559409.944084\n",
            "For 8820th iteration, the training loss is 53871408581.78206\n",
            "For 8821th iteration, the training loss is 53871257807.894295\n",
            "For 8822th iteration, the training loss is 53871107019.813484\n",
            "For 8823th iteration, the training loss is 53870956307.592384\n",
            "For 8824th iteration, the training loss is 53870805816.98547\n",
            "For 8825th iteration, the training loss is 53870655109.423065\n",
            "For 8826th iteration, the training loss is 53870504740.470634\n",
            "For 8827th iteration, the training loss is 53870354094.39772\n",
            "For 8828th iteration, the training loss is 53870203782.86639\n",
            "For 8829th iteration, the training loss is 53870053197.23976\n",
            "For 8830th iteration, the training loss is 53869902942.521576\n",
            "For 8831th iteration, the training loss is 53869752416.33631\n",
            "For 8832th iteration, the training loss is 53869602217.84603\n",
            "For 8833th iteration, the training loss is 53869451750.133965\n",
            "For 8834th iteration, the training loss is 53869301607.3081\n",
            "For 8835th iteration, the training loss is 53869151304.26746\n",
            "For 8836th iteration, the training loss is 53869001113.79428\n",
            "For 8837th iteration, the training loss is 53868850966.97377\n",
            "For 8838th iteration, the training loss is 53868700904.42789\n",
            "For 8839th iteration, the training loss is 53868550616.36915\n",
            "For 8840th iteration, the training loss is 53868400379.29382\n",
            "For 8841th iteration, the training loss is 53868250206.436295\n",
            "For 8842th iteration, the training loss is 53868100002.520256\n",
            "For 8843th iteration, the training loss is 53867949854.56343\n",
            "For 8844th iteration, the training loss is 53867799684.0731\n",
            "For 8845th iteration, the training loss is 53867649677.34035\n",
            "For 8846th iteration, the training loss is 53867499567.14155\n",
            "For 8847th iteration, the training loss is 53867349624.4074\n",
            "For 8848th iteration, the training loss is 53867199473.24785\n",
            "For 8849th iteration, the training loss is 53867049452.99893\n",
            "For 8850th iteration, the training loss is 53866899749.89232\n",
            "For 8851th iteration, the training loss is 53866749780.22028\n",
            "For 8852th iteration, the training loss is 53866600128.19572\n",
            "For 8853th iteration, the training loss is 53866450208.45559\n",
            "For 8854th iteration, the training loss is 53866300511.61888\n",
            "For 8855th iteration, the training loss is 53866150861.88663\n",
            "For 8856th iteration, the training loss is 53866001283.5847\n",
            "For 8857th iteration, the training loss is 53865851484.85502\n",
            "For 8858th iteration, the training loss is 53865701981.04347\n",
            "For 8859th iteration, the training loss is 53865552189.934555\n",
            "For 8860th iteration, the training loss is 53865402736.02704\n",
            "For 8861th iteration, the training loss is 53865252992.88721\n",
            "For 8862th iteration, the training loss is 53865103588.553665\n",
            "For 8863th iteration, the training loss is 53864954170.565865\n",
            "For 8864th iteration, the training loss is 53864804730.88817\n",
            "For 8865th iteration, the training loss is 53864655529.23245\n",
            "For 8866th iteration, the training loss is 53864506018.69674\n",
            "For 8867th iteration, the training loss is 53864356539.84096\n",
            "For 8868th iteration, the training loss is 53864207306.77222\n",
            "For 8869th iteration, the training loss is 53864057835.57445\n",
            "For 8870th iteration, the training loss is 53863908415.90673\n",
            "For 8871th iteration, the training loss is 53863759158.032715\n",
            "For 8872th iteration, the training loss is 53863609754.94865\n",
            "For 8873th iteration, the training loss is 53863460416.6238\n",
            "For 8874th iteration, the training loss is 53863311336.90243\n",
            "For 8875th iteration, the training loss is 53863162094.5521\n",
            "For 8876th iteration, the training loss is 53863013120.612274\n",
            "For 8877th iteration, the training loss is 53862863867.74845\n",
            "For 8878th iteration, the training loss is 53862714938.11045\n",
            "For 8879th iteration, the training loss is 53862565723.84177\n",
            "For 8880th iteration, the training loss is 53862416838.37906\n",
            "For 8881th iteration, the training loss is 53862267662.493\n",
            "For 8882th iteration, the training loss is 53862118821.0836\n",
            "For 8883th iteration, the training loss is 53861969683.3753\n",
            "For 8884th iteration, the training loss is 53861820885.90162\n",
            "For 8885th iteration, the training loss is 53861672063.3897\n",
            "For 8886th iteration, the training loss is 53861523231.24341\n",
            "For 8887th iteration, the training loss is 53861374608.58352\n",
            "For 8888th iteration, the training loss is 53861225709.80878\n",
            "For 8889th iteration, the training loss is 53861076799.08706\n",
            "For 8890th iteration, the training loss is 53860928204.833595\n",
            "For 8891th iteration, the training loss is 53860779498.60817\n",
            "For 8892th iteration, the training loss is 53860630952.637535\n",
            "For 8893th iteration, the training loss is 53860482281.08326\n",
            "For 8894th iteration, the training loss is 53860333783.29753\n",
            "For 8895th iteration, the training loss is 53860188145.82045\n",
            "For 8896th iteration, the training loss is 53860042695.07493\n",
            "For 8897th iteration, the training loss is 53859897091.67719\n",
            "For 8898th iteration, the training loss is 53859751739.48931\n",
            "For 8899th iteration, the training loss is 53859605986.18777\n",
            "For 8900th iteration, the training loss is 53859460397.234566\n",
            "For 8901th iteration, the training loss is 53859314964.92155\n",
            "For 8902th iteration, the training loss is 53859169383.420876\n",
            "For 8903th iteration, the training loss is 53859023855.481445\n",
            "For 8904th iteration, the training loss is 53858878645.07756\n",
            "For 8905th iteration, the training loss is 53858733143.795\n",
            "For 8906th iteration, the training loss is 53858587970.01393\n",
            "For 8907th iteration, the training loss is 53858442495.560585\n",
            "For 8908th iteration, the training loss is 53858297108.54538\n",
            "For 8909th iteration, the training loss is 53858151875.17885\n",
            "For 8910th iteration, the training loss is 53858006493.94724\n",
            "For 8911th iteration, the training loss is 53857861162.67178\n",
            "For 8912th iteration, the training loss is 53857716049.76283\n",
            "For 8913th iteration, the training loss is 53857570963.586914\n",
            "For 8914th iteration, the training loss is 53857425885.10411\n",
            "For 8915th iteration, the training loss is 53857280978.94006\n",
            "For 8916th iteration, the training loss is 53857135837.19506\n",
            "For 8917th iteration, the training loss is 53856990890.1401\n",
            "For 8918th iteration, the training loss is 53856845859.53802\n",
            "For 8919th iteration, the training loss is 53856700789.3511\n",
            "For 8920th iteration, the training loss is 53856556012.10257\n",
            "For 8921th iteration, the training loss is 53856410847.1924\n",
            "For 8922th iteration, the training loss is 53856265793.27472\n",
            "For 8923th iteration, the training loss is 53856120669.79389\n",
            "For 8924th iteration, the training loss is 53855975708.328255\n",
            "For 8925th iteration, the training loss is 53855830787.084206\n",
            "For 8926th iteration, the training loss is 53855685835.83698\n",
            "For 8927th iteration, the training loss is 53855540933.54784\n",
            "For 8928th iteration, the training loss is 53855396345.3204\n",
            "For 8929th iteration, the training loss is 53855251460.4162\n",
            "For 8930th iteration, the training loss is 53855106903.549034\n",
            "For 8931th iteration, the training loss is 53854962036.52966\n",
            "For 8932th iteration, the training loss is 53854817261.291\n",
            "For 8933th iteration, the training loss is 53854672628.0804\n",
            "For 8934th iteration, the training loss is 53854527853.32653\n",
            "For 8935th iteration, the training loss is 53854383112.14868\n",
            "For 8936th iteration, the training loss is 53854238700.26418\n",
            "For 8937th iteration, the training loss is 53854094248.53315\n",
            "For 8938th iteration, the training loss is 53853949794.143585\n",
            "For 8939th iteration, the training loss is 53853805510.19118\n",
            "For 8940th iteration, the training loss is 53853660991.94109\n",
            "For 8941th iteration, the training loss is 53853516654.30374\n",
            "For 8942th iteration, the training loss is 53853372246.3144\n",
            "For 8943th iteration, the training loss is 53853227774.1424\n",
            "For 8944th iteration, the training loss is 53853083608.9626\n",
            "For 8945th iteration, the training loss is 53852939314.67564\n",
            "For 8946th iteration, the training loss is 53852795186.64044\n",
            "For 8947th iteration, the training loss is 53852650903.093376\n",
            "For 8948th iteration, the training loss is 53852506863.648834\n",
            "For 8949th iteration, the training loss is 53852362532.674034\n",
            "For 8950th iteration, the training loss is 53852218519.29162\n",
            "For 8951th iteration, the training loss is 53852074197.12935\n",
            "For 8952th iteration, the training loss is 53851929959.64865\n",
            "For 8953th iteration, the training loss is 53851785861.05455\n",
            "For 8954th iteration, the training loss is 53851641618.710976\n",
            "For 8955th iteration, the training loss is 53851497404.79311\n",
            "For 8956th iteration, the training loss is 53851353521.19076\n",
            "For 8957th iteration, the training loss is 53851209588.924286\n",
            "For 8958th iteration, the training loss is 53851065787.95113\n",
            "For 8959th iteration, the training loss is 53850921859.59649\n",
            "For 8960th iteration, the training loss is 53850778093.24287\n",
            "For 8961th iteration, the training loss is 53850634169.6233\n",
            "For 8962th iteration, the training loss is 53850490488.68835\n",
            "For 8963th iteration, the training loss is 53850346620.8166\n",
            "For 8964th iteration, the training loss is 53850202956.1052\n",
            "For 8965th iteration, the training loss is 53850059245.17478\n",
            "For 8966th iteration, the training loss is 53849915568.81908\n",
            "For 8967th iteration, the training loss is 53849771797.59444\n",
            "For 8968th iteration, the training loss is 53849628272.692406\n",
            "For 8969th iteration, the training loss is 53849484447.72848\n",
            "For 8970th iteration, the training loss is 53849340944.739876\n",
            "For 8971th iteration, the training loss is 53849197121.43485\n",
            "For 8972th iteration, the training loss is 53849053389.49086\n",
            "For 8973th iteration, the training loss is 53848909784.3398\n",
            "For 8974th iteration, the training loss is 53848766043.33587\n",
            "For 8975th iteration, the training loss is 53848622588.44632\n",
            "For 8976th iteration, the training loss is 53848479166.49804\n",
            "For 8977th iteration, the training loss is 53848335647.300835\n",
            "For 8978th iteration, the training loss is 53848192375.581665\n",
            "For 8979th iteration, the training loss is 53848048800.643936\n",
            "For 8980th iteration, the training loss is 53847905548.86296\n",
            "For 8981th iteration, the training loss is 53847762246.180305\n",
            "For 8982th iteration, the training loss is 53847618982.14418\n",
            "For 8983th iteration, the training loss is 53847475612.757805\n",
            "For 8984th iteration, the training loss is 53847332493.584076\n",
            "For 8985th iteration, the training loss is 53847189173.676636\n",
            "For 8986th iteration, the training loss is 53847045816.14091\n",
            "For 8987th iteration, the training loss is 53846902584.365776\n",
            "For 8988th iteration, the training loss is 53846759214.1379\n",
            "For 8989th iteration, the training loss is 53846616127.63184\n",
            "For 8990th iteration, the training loss is 53846473075.19338\n",
            "For 8991th iteration, the training loss is 53846329918.31989\n",
            "For 8992th iteration, the training loss is 53846187009.3492\n",
            "For 8993th iteration, the training loss is 53846043791.005486\n",
            "For 8994th iteration, the training loss is 53845900899.002335\n",
            "For 8995th iteration, the training loss is 53845757946.27951\n",
            "For 8996th iteration, the training loss is 53845615129.444115\n",
            "For 8997th iteration, the training loss is 53845472164.538666\n",
            "For 8998th iteration, the training loss is 53845329375.88206\n",
            "For 8999th iteration, the training loss is 53845186400.17604\n",
            "For 9000th iteration, the training loss is 53845043685.08579\n",
            "For 9001th iteration, the training loss is 53844900647.60275\n",
            "For 9002th iteration, the training loss is 53844757697.77873\n",
            "For 9003th iteration, the training loss is 53844614866.00669\n",
            "For 9004th iteration, the training loss is 53844472218.1474\n",
            "For 9005th iteration, the training loss is 53844329539.16549\n",
            "For 9006th iteration, the training loss is 53844186846.41189\n",
            "For 9007th iteration, the training loss is 53844044308.2188\n",
            "For 9008th iteration, the training loss is 53843901599.37503\n",
            "For 9009th iteration, the training loss is 53843759135.89902\n",
            "For 9010th iteration, the training loss is 53843616357.4409\n",
            "For 9011th iteration, the training loss is 53843473907.21188\n",
            "For 9012th iteration, the training loss is 53843331386.936485\n",
            "For 9013th iteration, the training loss is 53843188920.56638\n",
            "For 9014th iteration, the training loss is 53843046321.32975\n",
            "For 9015th iteration, the training loss is 53842903990.030785\n",
            "For 9016th iteration, the training loss is 53842761324.55948\n",
            "For 9017th iteration, the training loss is 53842618753.83068\n",
            "For 9018th iteration, the training loss is 53842476089.293686\n",
            "For 9019th iteration, the training loss is 53842333834.51133\n",
            "For 9020th iteration, the training loss is 53842191499.97179\n",
            "For 9021th iteration, the training loss is 53842049330.59313\n",
            "For 9022th iteration, the training loss is 53841906940.84586\n",
            "For 9023th iteration, the training loss is 53841764814.75595\n",
            "For 9024th iteration, the training loss is 53841622630.258286\n",
            "For 9025th iteration, the training loss is 53841480470.30482\n",
            "For 9026th iteration, the training loss is 53841338234.419716\n",
            "For 9027th iteration, the training loss is 53841196236.91463\n",
            "For 9028th iteration, the training loss is 53841054029.575935\n",
            "For 9029th iteration, the training loss is 53840912034.73392\n",
            "For 9030th iteration, the training loss is 53840769954.24692\n",
            "For 9031th iteration, the training loss is 53840628032.3955\n",
            "For 9032th iteration, the training loss is 53840485925.98067\n",
            "For 9033th iteration, the training loss is 53840344071.392426\n",
            "For 9034th iteration, the training loss is 53840201887.10949\n",
            "For 9035th iteration, the training loss is 53840059790.08635\n",
            "For 9036th iteration, the training loss is 53839917799.74457\n",
            "For 9037th iteration, the training loss is 53839775986.43565\n",
            "For 9038th iteration, the training loss is 53839634148.267586\n",
            "For 9039th iteration, the training loss is 53839492273.99635\n",
            "For 9040th iteration, the training loss is 53839350575.56965\n",
            "For 9041th iteration, the training loss is 53839209097.75187\n",
            "For 9042th iteration, the training loss is 53839067212.43647\n",
            "For 9043th iteration, the training loss is 53838925500.55973\n",
            "For 9044th iteration, the training loss is 53838783719.45285\n",
            "For 9045th iteration, the training loss is 53838641910.49582\n",
            "For 9046th iteration, the training loss is 53838500403.4087\n",
            "For 9047th iteration, the training loss is 53838358731.17017\n",
            "For 9048th iteration, the training loss is 53838217290.590775\n",
            "For 9049th iteration, the training loss is 53838075526.56719\n",
            "For 9050th iteration, the training loss is 53837934090.66248\n",
            "For 9051th iteration, the training loss is 53837792570.6546\n",
            "For 9052th iteration, the training loss is 53837651202.68005\n",
            "For 9053th iteration, the training loss is 53837509647.113945\n",
            "For 9054th iteration, the training loss is 53837368340.897514\n",
            "For 9055th iteration, the training loss is 53837226696.18007\n",
            "For 9056th iteration, the training loss is 53837085140.7094\n",
            "For 9057th iteration, the training loss is 53836943587.79093\n",
            "For 9058th iteration, the training loss is 53836802080.80003\n",
            "For 9059th iteration, the training loss is 53836660586.68287\n",
            "For 9060th iteration, the training loss is 53836519407.543785\n",
            "For 9061th iteration, the training loss is 53836378152.64738\n",
            "For 9062th iteration, the training loss is 53836236948.22975\n",
            "For 9063th iteration, the training loss is 53836096011.79195\n",
            "For 9064th iteration, the training loss is 53835954743.68082\n",
            "For 9065th iteration, the training loss is 53835813557.81019\n",
            "For 9066th iteration, the training loss is 53835672411.44182\n",
            "For 9067th iteration, the training loss is 53835531326.6801\n",
            "For 9068th iteration, the training loss is 53835390263.653114\n",
            "For 9069th iteration, the training loss is 53835249101.64484\n",
            "For 9070th iteration, the training loss is 53835108219.03965\n",
            "For 9071th iteration, the training loss is 53834967179.22034\n",
            "For 9072th iteration, the training loss is 53834826359.00351\n",
            "For 9073th iteration, the training loss is 53834685202.15845\n",
            "For 9074th iteration, the training loss is 53834544098.06279\n",
            "For 9075th iteration, the training loss is 53834402993.50147\n",
            "For 9076th iteration, the training loss is 53834262217.29287\n",
            "For 9077th iteration, the training loss is 53834121345.16383\n",
            "For 9078th iteration, the training loss is 53833980633.549194\n",
            "For 9079th iteration, the training loss is 53833840135.036125\n",
            "For 9080th iteration, the training loss is 53833699289.42877\n",
            "For 9081th iteration, the training loss is 53833558533.10755\n",
            "For 9082th iteration, the training loss is 53833417809.164185\n",
            "For 9083th iteration, the training loss is 53833277142.04294\n",
            "For 9084th iteration, the training loss is 53833136500.63187\n",
            "For 9085th iteration, the training loss is 53832995749.52051\n",
            "For 9086th iteration, the training loss is 53832855281.40716\n",
            "For 9087th iteration, the training loss is 53832714647.479126\n",
            "For 9088th iteration, the training loss is 53832574236.79157\n",
            "For 9089th iteration, the training loss is 53832433478.94683\n",
            "For 9090th iteration, the training loss is 53832292778.92541\n",
            "For 9091th iteration, the training loss is 53832152067.127174\n",
            "For 9092th iteration, the training loss is 53832011440.35239\n",
            "For 9093th iteration, the training loss is 53831870806.49321\n",
            "For 9094th iteration, the training loss is 53831730219.17452\n",
            "For 9095th iteration, the training loss is 53831589629.45665\n",
            "For 9096th iteration, the training loss is 53831449363.28725\n",
            "For 9097th iteration, the training loss is 53831308997.4737\n",
            "For 9098th iteration, the training loss is 53831168791.92948\n",
            "For 9099th iteration, the training loss is 53831028786.27503\n",
            "For 9100th iteration, the training loss is 53830888447.0854\n",
            "For 9101th iteration, the training loss is 53830748172.963135\n",
            "For 9102th iteration, the training loss is 53830608126.47456\n",
            "For 9103th iteration, the training loss is 53830467875.50484\n",
            "For 9104th iteration, the training loss is 53830327857.0598\n",
            "For 9105th iteration, the training loss is 53830187492.935135\n",
            "For 9106th iteration, the training loss is 53830047214.884865\n",
            "For 9107th iteration, the training loss is 53829906923.22252\n",
            "For 9108th iteration, the training loss is 53829766681.5658\n",
            "For 9109th iteration, the training loss is 53829626429.78255\n",
            "For 9110th iteration, the training loss is 53829486506.65957\n",
            "For 9111th iteration, the training loss is 53829346471.03781\n",
            "For 9112th iteration, the training loss is 53829206654.5527\n",
            "For 9113th iteration, the training loss is 53829066383.54977\n",
            "For 9114th iteration, the training loss is 53828926285.82945\n",
            "For 9115th iteration, the training loss is 53828786175.4026\n",
            "For 9116th iteration, the training loss is 53828646394.03862\n",
            "For 9117th iteration, the training loss is 53828506495.19002\n",
            "For 9118th iteration, the training loss is 53828366723.20327\n",
            "For 9119th iteration, the training loss is 53828226925.8449\n",
            "For 9120th iteration, the training loss is 53828087274.42074\n",
            "For 9121th iteration, the training loss is 53827947825.443085\n",
            "For 9122th iteration, the training loss is 53827808037.42512\n",
            "For 9123th iteration, the training loss is 53827668310.98842\n",
            "For 9124th iteration, the training loss is 53827528826.42125\n",
            "For 9125th iteration, the training loss is 53827389496.430664\n",
            "For 9126th iteration, the training loss is 53827249829.85355\n",
            "For 9127th iteration, the training loss is 53827110348.02825\n",
            "For 9128th iteration, the training loss is 53826970758.034966\n",
            "For 9129th iteration, the training loss is 53826831192.181656\n",
            "For 9130th iteration, the training loss is 53826691848.51992\n",
            "For 9131th iteration, the training loss is 53826552696.42706\n",
            "For 9132th iteration, the training loss is 53826413260.56454\n",
            "For 9133th iteration, the training loss is 53826273770.6469\n",
            "For 9134th iteration, the training loss is 53826134530.59493\n",
            "For 9135th iteration, the training loss is 53825995236.68819\n",
            "For 9136th iteration, the training loss is 53825856038.733055\n",
            "For 9137th iteration, the training loss is 53825716480.503685\n",
            "For 9138th iteration, the training loss is 53825577285.51062\n",
            "For 9139th iteration, the training loss is 53825438151.304\n",
            "For 9140th iteration, the training loss is 53825298652.726715\n",
            "For 9141th iteration, the training loss is 53825159559.239586\n",
            "For 9142th iteration, the training loss is 53825020514.45141\n",
            "For 9143th iteration, the training loss is 53824881118.55295\n",
            "For 9144th iteration, the training loss is 53824741806.950455\n",
            "For 9145th iteration, the training loss is 53824602481.61545\n",
            "For 9146th iteration, the training loss is 53824463479.01872\n",
            "For 9147th iteration, the training loss is 53824324355.89553\n",
            "For 9148th iteration, the training loss is 53824185451.29778\n",
            "For 9149th iteration, the training loss is 53824046198.71407\n",
            "For 9150th iteration, the training loss is 53823907279.64715\n",
            "For 9151th iteration, the training loss is 53823768642.25428\n",
            "For 9152th iteration, the training loss is 53823629580.29086\n",
            "For 9153th iteration, the training loss is 53823491167.77681\n",
            "For 9154th iteration, the training loss is 53823351860.29232\n",
            "For 9155th iteration, the training loss is 53823213017.01798\n",
            "For 9156th iteration, the training loss is 53823073897.53945\n",
            "For 9157th iteration, the training loss is 53822935464.364365\n",
            "For 9158th iteration, the training loss is 53822796291.96486\n",
            "For 9159th iteration, the training loss is 53822657429.57115\n",
            "For 9160th iteration, the training loss is 53822518480.4541\n",
            "For 9161th iteration, the training loss is 53822380127.52483\n",
            "For 9162th iteration, the training loss is 53822241060.546234\n",
            "For 9163th iteration, the training loss is 53822102276.7181\n",
            "For 9164th iteration, the training loss is 53821963586.510216\n",
            "For 9165th iteration, the training loss is 53821824865.2095\n",
            "For 9166th iteration, the training loss is 53821686404.01448\n",
            "For 9167th iteration, the training loss is 53821547747.25921\n",
            "For 9168th iteration, the training loss is 53821409302.687126\n",
            "For 9169th iteration, the training loss is 53821270616.99666\n",
            "For 9170th iteration, the training loss is 53821132245.42719\n",
            "For 9171th iteration, the training loss is 53820993774.655\n",
            "For 9172th iteration, the training loss is 53820855446.62679\n",
            "For 9173th iteration, the training loss is 53820717293.35155\n",
            "For 9174th iteration, the training loss is 53820578912.95636\n",
            "For 9175th iteration, the training loss is 53820440512.59956\n",
            "For 9176th iteration, the training loss is 53820302330.23376\n",
            "For 9177th iteration, the training loss is 53820164316.87946\n",
            "For 9178th iteration, the training loss is 53820026044.54057\n",
            "For 9179th iteration, the training loss is 53819887672.986755\n",
            "For 9180th iteration, the training loss is 53819749578.97109\n",
            "For 9181th iteration, the training loss is 53819611804.37282\n",
            "For 9182th iteration, the training loss is 53819473641.20514\n",
            "For 9183th iteration, the training loss is 53819335508.7891\n",
            "For 9184th iteration, the training loss is 53819197560.71105\n",
            "For 9185th iteration, the training loss is 53819059405.95568\n",
            "For 9186th iteration, the training loss is 53818921467.53832\n",
            "For 9187th iteration, the training loss is 53818783153.61582\n",
            "For 9188th iteration, the training loss is 53818645193.82541\n",
            "For 9189th iteration, the training loss is 53818507304.10668\n",
            "For 9190th iteration, the training loss is 53818369291.652916\n",
            "For 9191th iteration, the training loss is 53818231489.2678\n",
            "For 9192th iteration, the training loss is 53818093325.35456\n",
            "For 9193th iteration, the training loss is 53817955550.9564\n",
            "For 9194th iteration, the training loss is 53817817820.54188\n",
            "For 9195th iteration, the training loss is 53817679728.865814\n",
            "For 9196th iteration, the training loss is 53817542026.43712\n",
            "For 9197th iteration, the training loss is 53817404367.204666\n",
            "For 9198th iteration, the training loss is 53817266346.376274\n",
            "For 9199th iteration, the training loss is 53817128714.69981\n",
            "For 9200th iteration, the training loss is 53816991021.936615\n",
            "For 9201th iteration, the training loss is 53816853317.32491\n",
            "For 9202th iteration, the training loss is 53816715800.66278\n",
            "For 9203th iteration, the training loss is 53816577939.00587\n",
            "For 9204th iteration, the training loss is 53816440397.22472\n",
            "For 9205th iteration, the training loss is 53816303127.42816\n",
            "For 9206th iteration, the training loss is 53816165481.717514\n",
            "For 9207th iteration, the training loss is 53816028016.88027\n",
            "For 9208th iteration, the training loss is 53815890428.38247\n",
            "For 9209th iteration, the training loss is 53815753028.64055\n",
            "For 9210th iteration, the training loss is 53815615497.292336\n",
            "For 9211th iteration, the training loss is 53815478014.80072\n",
            "For 9212th iteration, the training loss is 53815340745.57841\n",
            "For 9213th iteration, the training loss is 53815203629.96563\n",
            "For 9214th iteration, the training loss is 53815066271.313286\n",
            "For 9215th iteration, the training loss is 53814929029.96333\n",
            "For 9216th iteration, the training loss is 53814791723.97616\n",
            "For 9217th iteration, the training loss is 53814654363.45772\n",
            "For 9218th iteration, the training loss is 53814517242.20148\n",
            "For 9219th iteration, the training loss is 53814379935.7292\n",
            "For 9220th iteration, the training loss is 53814242843.904015\n",
            "For 9221th iteration, the training loss is 53814105486.23039\n",
            "For 9222th iteration, the training loss is 53813968392.35253\n",
            "For 9223th iteration, the training loss is 53813831358.39989\n",
            "For 9224th iteration, the training loss is 53813694204.691505\n",
            "For 9225th iteration, the training loss is 53813557250.34926\n",
            "For 9226th iteration, the training loss is 53813419932.69078\n",
            "For 9227th iteration, the training loss is 53813282995.04938\n",
            "For 9228th iteration, the training loss is 53813146102.41022\n",
            "For 9229th iteration, the training loss is 53813008838.79563\n",
            "For 9230th iteration, the training loss is 53812871957.19718\n",
            "For 9231th iteration, the training loss is 53812735126.02977\n",
            "For 9232th iteration, the training loss is 53812598183.59625\n",
            "For 9233th iteration, the training loss is 53812461430.10865\n",
            "For 9234th iteration, the training loss is 53812324321.182724\n",
            "For 9235th iteration, the training loss is 53812187804.73942\n",
            "For 9236th iteration, the training loss is 53812051308.90938\n",
            "For 9237th iteration, the training loss is 53811914613.97802\n",
            "For 9238th iteration, the training loss is 53811777861.928215\n",
            "For 9239th iteration, the training loss is 53811641074.03702\n",
            "For 9240th iteration, the training loss is 53811504490.411285\n",
            "For 9241th iteration, the training loss is 53811367537.031784\n",
            "For 9242th iteration, the training loss is 53811230965.673515\n",
            "For 9243th iteration, the training loss is 53811094448.39978\n",
            "For 9244th iteration, the training loss is 53810957775.49229\n",
            "For 9245th iteration, the training loss is 53810821309.61985\n",
            "For 9246th iteration, the training loss is 53810684740.05703\n",
            "For 9247th iteration, the training loss is 53810548214.35667\n",
            "For 9248th iteration, the training loss is 53810411853.11814\n",
            "For 9249th iteration, the training loss is 53810275435.58674\n",
            "For 9250th iteration, the training loss is 53810142107.38362\n",
            "For 9251th iteration, the training loss is 53810005695.05919\n",
            "For 9252th iteration, the training loss is 53809872692.25812\n",
            "For 9253th iteration, the training loss is 53809738783.33355\n",
            "For 9254th iteration, the training loss is 53809605285.4945\n",
            "For 9255th iteration, the training loss is 53809471622.680664\n",
            "For 9256th iteration, the training loss is 53809338559.920135\n",
            "For 9257th iteration, the training loss is 53809204782.61688\n",
            "For 9258th iteration, the training loss is 53809071227.66987\n",
            "For 9259th iteration, the training loss is 53808937866.88105\n",
            "For 9260th iteration, the training loss is 53808804456.12168\n",
            "For 9261th iteration, the training loss is 53808671276.86897\n",
            "For 9262th iteration, the training loss is 53808538312.56025\n",
            "For 9263th iteration, the training loss is 53808405052.142715\n",
            "For 9264th iteration, the training loss is 53808271690.34707\n",
            "For 9265th iteration, the training loss is 53808138596.907715\n",
            "For 9266th iteration, the training loss is 53808005681.17603\n",
            "For 9267th iteration, the training loss is 53807872521.10086\n",
            "For 9268th iteration, the training loss is 53807739448.97974\n",
            "For 9269th iteration, the training loss is 53807606338.28142\n",
            "For 9270th iteration, the training loss is 53807473378.08259\n",
            "For 9271th iteration, the training loss is 53807340316.565735\n",
            "For 9272th iteration, the training loss is 53807207206.02545\n",
            "For 9273th iteration, the training loss is 53807074323.57762\n",
            "For 9274th iteration, the training loss is 53806941753.0932\n",
            "For 9275th iteration, the training loss is 53806808793.02302\n",
            "For 9276th iteration, the training loss is 53806675941.00734\n",
            "For 9277th iteration, the training loss is 53806542961.6218\n",
            "For 9278th iteration, the training loss is 53806410133.24026\n",
            "For 9279th iteration, the training loss is 53806277270.580284\n",
            "For 9280th iteration, the training loss is 53806144547.928795\n",
            "For 9281th iteration, the training loss is 53806011734.12467\n",
            "For 9282th iteration, the training loss is 53805878859.052086\n",
            "For 9283th iteration, the training loss is 53805746218.18677\n",
            "For 9284th iteration, the training loss is 53805613877.39182\n",
            "For 9285th iteration, the training loss is 53805481164.70246\n",
            "For 9286th iteration, the training loss is 53805348533.25254\n",
            "For 9287th iteration, the training loss is 53805215892.279366\n",
            "For 9288th iteration, the training loss is 53805083315.503845\n",
            "For 9289th iteration, the training loss is 53804950699.8836\n",
            "For 9290th iteration, the training loss is 53804818222.41908\n",
            "For 9291th iteration, the training loss is 53804685422.58217\n",
            "For 9292th iteration, the training loss is 53804553124.183\n",
            "For 9293th iteration, the training loss is 53804420306.05648\n",
            "For 9294th iteration, the training loss is 53804288308.24212\n",
            "For 9295th iteration, the training loss is 53804155514.3494\n",
            "For 9296th iteration, the training loss is 53804023038.19932\n",
            "For 9297th iteration, the training loss is 53803890392.41399\n",
            "For 9298th iteration, the training loss is 53803758320.58248\n",
            "For 9299th iteration, the training loss is 53803625691.65491\n",
            "For 9300th iteration, the training loss is 53803493320.87393\n",
            "For 9301th iteration, the training loss is 53803361130.89634\n",
            "For 9302th iteration, the training loss is 53803228679.650505\n",
            "For 9303th iteration, the training loss is 53803096352.11003\n",
            "For 9304th iteration, the training loss is 53802964146.01132\n",
            "For 9305th iteration, the training loss is 53802831990.41037\n",
            "For 9306th iteration, the training loss is 53802700212.1828\n",
            "For 9307th iteration, the training loss is 53802568017.59898\n",
            "For 9308th iteration, the training loss is 53802435945.23333\n",
            "For 9309th iteration, the training loss is 53802303798.73811\n",
            "For 9310th iteration, the training loss is 53802171563.37917\n",
            "For 9311th iteration, the training loss is 53802039580.19518\n",
            "For 9312th iteration, the training loss is 53801907866.125534\n",
            "For 9313th iteration, the training loss is 53801775820.02393\n",
            "For 9314th iteration, the training loss is 53801644309.5548\n",
            "For 9315th iteration, the training loss is 53801511907.22914\n",
            "For 9316th iteration, the training loss is 53801379863.5614\n",
            "For 9317th iteration, the training loss is 53801247739.32202\n",
            "For 9318th iteration, the training loss is 53801116240.01595\n",
            "For 9319th iteration, the training loss is 53800983951.34257\n",
            "For 9320th iteration, the training loss is 53800851919.415\n",
            "For 9321th iteration, the training loss is 53800720055.02245\n",
            "For 9322th iteration, the training loss is 53800588133.82077\n",
            "For 9323th iteration, the training loss is 53800456439.65632\n",
            "For 9324th iteration, the training loss is 53800324896.56758\n",
            "For 9325th iteration, the training loss is 53800193293.38585\n",
            "For 9326th iteration, the training loss is 53800061981.10007\n",
            "For 9327th iteration, the training loss is 53799930273.507034\n",
            "For 9328th iteration, the training loss is 53799798648.73963\n",
            "For 9329th iteration, the training loss is 53799666988.76227\n",
            "For 9330th iteration, the training loss is 53799535440.283\n",
            "For 9331th iteration, the training loss is 53799403827.83455\n",
            "For 9332th iteration, the training loss is 53799272353.51371\n",
            "For 9333th iteration, the training loss is 53799140788.5126\n",
            "For 9334th iteration, the training loss is 53799009386.29844\n",
            "For 9335th iteration, the training loss is 53798877801.80873\n",
            "For 9336th iteration, the training loss is 53798746387.958435\n",
            "For 9337th iteration, the training loss is 53798614917.7528\n",
            "For 9338th iteration, the training loss is 53798483574.97903\n",
            "For 9339th iteration, the training loss is 53798352152.10621\n",
            "For 9340th iteration, the training loss is 53798220878.469955\n",
            "For 9341th iteration, the training loss is 53798089502.86002\n",
            "For 9342th iteration, the training loss is 53797958153.5206\n",
            "For 9343th iteration, the training loss is 53797826964.1392\n",
            "For 9344th iteration, the training loss is 53797695872.45677\n",
            "For 9345th iteration, the training loss is 53797564747.21899\n",
            "For 9346th iteration, the training loss is 53797433877.4024\n",
            "For 9347th iteration, the training loss is 53797302657.6619\n",
            "For 9348th iteration, the training loss is 53797171969.99645\n",
            "For 9349th iteration, the training loss is 53797040390.82065\n",
            "For 9350th iteration, the training loss is 53796909148.64858\n",
            "For 9351th iteration, the training loss is 53796777847.0524\n",
            "For 9352th iteration, the training loss is 53796647124.40727\n",
            "For 9353th iteration, the training loss is 53796515730.00152\n",
            "For 9354th iteration, the training loss is 53796384736.748215\n",
            "For 9355th iteration, the training loss is 53796253695.250534\n",
            "For 9356th iteration, the training loss is 53796122763.02166\n",
            "For 9357th iteration, the training loss is 53795991768.512215\n",
            "For 9358th iteration, the training loss is 53795860895.73546\n",
            "For 9359th iteration, the training loss is 53795729948.164406\n",
            "For 9360th iteration, the training loss is 53795599133.32468\n",
            "For 9361th iteration, the training loss is 53795468232.64503\n",
            "For 9362th iteration, the training loss is 53795337572.72662\n",
            "For 9363th iteration, the training loss is 53795206720.75993\n",
            "For 9364th iteration, the training loss is 53795075993.89735\n",
            "For 9365th iteration, the training loss is 53794945188.75914\n",
            "For 9366th iteration, the training loss is 53794814516.36727\n",
            "For 9367th iteration, the training loss is 53794683691.496216\n",
            "For 9368th iteration, the training loss is 53794553503.637566\n",
            "For 9369th iteration, the training loss is 53794422391.748955\n",
            "For 9370th iteration, the training loss is 53794291637.2198\n",
            "For 9371th iteration, the training loss is 53794160796.348755\n",
            "For 9372th iteration, the training loss is 53794030547.14833\n",
            "For 9373th iteration, the training loss is 53793899707.670815\n",
            "For 9374th iteration, the training loss is 53793769313.241684\n",
            "For 9375th iteration, the training loss is 53793638733.62174\n",
            "For 9376th iteration, the training loss is 53793508365.87238\n",
            "For 9377th iteration, the training loss is 53793377834.8147\n",
            "For 9378th iteration, the training loss is 53793247394.24852\n",
            "For 9379th iteration, the training loss is 53793116909.84468\n",
            "For 9380th iteration, the training loss is 53792986517.817894\n",
            "For 9381th iteration, the training loss is 53792856080.03687\n",
            "For 9382th iteration, the training loss is 53792725833.76915\n",
            "For 9383th iteration, the training loss is 53792595444.49275\n",
            "For 9384th iteration, the training loss is 53792465633.05717\n",
            "For 9385th iteration, the training loss is 53792334893.819824\n",
            "For 9386th iteration, the training loss is 53792204506.751686\n",
            "For 9387th iteration, the training loss is 53792074036.03967\n",
            "For 9388th iteration, the training loss is 53791944143.8294\n",
            "For 9389th iteration, the training loss is 53791813676.19835\n",
            "For 9390th iteration, the training loss is 53791683491.41605\n",
            "For 9391th iteration, the training loss is 53791553440.097435\n",
            "For 9392th iteration, the training loss is 53791423570.375435\n",
            "For 9393th iteration, the training loss is 53791293416.243935\n",
            "For 9394th iteration, the training loss is 53791163796.324615\n",
            "For 9395th iteration, the training loss is 53791033307.60475\n",
            "For 9396th iteration, the training loss is 53790903107.600365\n",
            "For 9397th iteration, the training loss is 53790773043.37\n",
            "For 9398th iteration, the training loss is 53790642911.18703\n",
            "For 9399th iteration, the training loss is 53790513000.762115\n",
            "For 9400th iteration, the training loss is 53790383200.63405\n",
            "For 9401th iteration, the training loss is 53790253374.369194\n",
            "For 9402th iteration, the training loss is 53790123637.71615\n",
            "For 9403th iteration, the training loss is 53789993868.95368\n",
            "For 9404th iteration, the training loss is 53789864194.18277\n",
            "For 9405th iteration, the training loss is 53789734482.559616\n",
            "For 9406th iteration, the training loss is 53789604897.06039\n",
            "For 9407th iteration, the training loss is 53789475252.283035\n",
            "For 9408th iteration, the training loss is 53789345661.83979\n",
            "For 9409th iteration, the training loss is 53789215913.228264\n",
            "For 9410th iteration, the training loss is 53789086665.2979\n",
            "For 9411th iteration, the training loss is 53788956575.99584\n",
            "For 9412th iteration, the training loss is 53788826737.68563\n",
            "For 9413th iteration, the training loss is 53788697078.16902\n",
            "For 9414th iteration, the training loss is 53788567548.965065\n",
            "For 9415th iteration, the training loss is 53788437935.58277\n",
            "For 9416th iteration, the training loss is 53788308431.58354\n",
            "For 9417th iteration, the training loss is 53788178864.33099\n",
            "For 9418th iteration, the training loss is 53788049385.257484\n",
            "For 9419th iteration, the training loss is 53787919864.13031\n",
            "For 9420th iteration, the training loss is 53787790409.71353\n",
            "For 9421th iteration, the training loss is 53787660934.707535\n",
            "For 9422th iteration, the training loss is 53787532013.731415\n",
            "For 9423th iteration, the training loss is 53787402188.16404\n",
            "For 9424th iteration, the training loss is 53787272668.78241\n",
            "For 9425th iteration, the training loss is 53787143112.8314\n",
            "For 9426th iteration, the training loss is 53787014061.66192\n",
            "For 9427th iteration, the training loss is 53786884423.86311\n",
            "For 9428th iteration, the training loss is 53786755578.852585\n",
            "For 9429th iteration, the training loss is 53786625950.933136\n",
            "For 9430th iteration, the training loss is 53786496601.44019\n",
            "For 9431th iteration, the training loss is 53786367173.459114\n",
            "For 9432th iteration, the training loss is 53786238287.51013\n",
            "For 9433th iteration, the training loss is 53786108835.664665\n",
            "For 9434th iteration, the training loss is 53785979825.42401\n",
            "For 9435th iteration, the training loss is 53785850652.274284\n",
            "For 9436th iteration, the training loss is 53785722140.50552\n",
            "For 9437th iteration, the training loss is 53785592637.847115\n",
            "For 9438th iteration, the training loss is 53785463399.68849\n",
            "For 9439th iteration, the training loss is 53785334316.74427\n",
            "For 9440th iteration, the training loss is 53785205473.8325\n",
            "For 9441th iteration, the training loss is 53785076438.94428\n",
            "For 9442th iteration, the training loss is 53784947998.35847\n",
            "For 9443th iteration, the training loss is 53784818622.76403\n",
            "For 9444th iteration, the training loss is 53784689572.94231\n",
            "For 9445th iteration, the training loss is 53784560625.913414\n",
            "For 9446th iteration, the training loss is 53784431581.309814\n",
            "For 9447th iteration, the training loss is 53784302802.81789\n",
            "For 9448th iteration, the training loss is 53784173969.19015\n",
            "For 9449th iteration, the training loss is 53784045374.85748\n",
            "For 9450th iteration, the training loss is 53783916550.00021\n",
            "For 9451th iteration, the training loss is 53783788034.54245\n",
            "For 9452th iteration, the training loss is 53783659509.70066\n",
            "For 9453th iteration, the training loss is 53783530752.06491\n",
            "For 9454th iteration, the training loss is 53783402305.41618\n",
            "For 9455th iteration, the training loss is 53783273627.76583\n",
            "For 9456th iteration, the training loss is 53783145257.64507\n",
            "For 9457th iteration, the training loss is 53783016877.11091\n",
            "For 9458th iteration, the training loss is 53782888152.938416\n",
            "For 9459th iteration, the training loss is 53782759857.92338\n",
            "For 9460th iteration, the training loss is 53782631552.075874\n",
            "For 9461th iteration, the training loss is 53782503013.775\n",
            "For 9462th iteration, the training loss is 53782374820.45587\n",
            "For 9463th iteration, the training loss is 53782246615.40522\n",
            "For 9464th iteration, the training loss is 53782118179.480316\n",
            "For 9465th iteration, the training loss is 53781989814.441734\n",
            "For 9466th iteration, the training loss is 53781861663.27101\n",
            "For 9467th iteration, the training loss is 53781733256.83821\n",
            "For 9468th iteration, the training loss is 53781605350.33746\n",
            "For 9469th iteration, the training loss is 53781476610.25013\n",
            "For 9470th iteration, the training loss is 53781348081.05322\n",
            "For 9471th iteration, the training loss is 53781219761.79227\n",
            "For 9472th iteration, the training loss is 53781091513.22938\n",
            "For 9473th iteration, the training loss is 53780963239.84032\n",
            "For 9474th iteration, the training loss is 53780835493.408226\n",
            "For 9475th iteration, the training loss is 53780706885.550415\n",
            "For 9476th iteration, the training loss is 53780578512.61609\n",
            "For 9477th iteration, the training loss is 53780450326.23437\n",
            "For 9478th iteration, the training loss is 53780322228.182945\n",
            "For 9479th iteration, the training loss is 53780194087.670586\n",
            "For 9480th iteration, the training loss is 53780066488.79434\n",
            "For 9481th iteration, the training loss is 53779938016.16484\n",
            "For 9482th iteration, the training loss is 53779809787.37905\n",
            "For 9483th iteration, the training loss is 53779681733.73802\n",
            "For 9484th iteration, the training loss is 53779553776.244934\n",
            "For 9485th iteration, the training loss is 53779425768.47617\n",
            "For 9486th iteration, the training loss is 53779298305.95109\n",
            "For 9487th iteration, the training loss is 53779169971.25457\n",
            "For 9488th iteration, the training loss is 53779041875.76908\n",
            "For 9489th iteration, the training loss is 53778913954.75898\n",
            "For 9490th iteration, the training loss is 53778786128.91272\n",
            "For 9491th iteration, the training loss is 53778658253.78162\n",
            "For 9492th iteration, the training loss is 53778530917.57289\n",
            "For 9493th iteration, the training loss is 53778402723.24725\n",
            "For 9494th iteration, the training loss is 53778274751.34603\n",
            "For 9495th iteration, the training loss is 53778146962.88002\n",
            "For 9496th iteration, the training loss is 53778019260.70043\n",
            "For 9497th iteration, the training loss is 53777891518.1228\n",
            "For 9498th iteration, the training loss is 53777764299.24222\n",
            "For 9499th iteration, the training loss is 53777636326.5044\n",
            "For 9500th iteration, the training loss is 53777508511.00768\n",
            "For 9501th iteration, the training loss is 53777380854.154205\n",
            "For 9502th iteration, the training loss is 53777253278.87047\n",
            "For 9503th iteration, the training loss is 53777125788.15643\n",
            "For 9504th iteration, the training loss is 53776998426.73835\n",
            "For 9505th iteration, the training loss is 53776870991.34203\n",
            "For 9506th iteration, the training loss is 53776743699.440956\n",
            "For 9507th iteration, the training loss is 53776616318.95178\n",
            "For 9508th iteration, the training loss is 53776489094.72486\n",
            "For 9509th iteration, the training loss is 53776361768.74914\n",
            "For 9510th iteration, the training loss is 53776234507.96197\n",
            "For 9511th iteration, the training loss is 53776107237.8976\n",
            "For 9512th iteration, the training loss is 53775980162.09976\n",
            "For 9513th iteration, the training loss is 53775852945.66988\n",
            "For 9514th iteration, the training loss is 53775725829.0548\n",
            "For 9515th iteration, the training loss is 53775598667.6694\n",
            "For 9516th iteration, the training loss is 53775471732.4412\n",
            "For 9517th iteration, the training loss is 53775344623.883\n",
            "For 9518th iteration, the training loss is 53775217643.82345\n",
            "For 9519th iteration, the training loss is 53775090589.51295\n",
            "For 9520th iteration, the training loss is 53774963685.007416\n",
            "For 9521th iteration, the training loss is 53774836530.10576\n",
            "For 9522th iteration, the training loss is 53774709824.03439\n",
            "For 9523th iteration, the training loss is 53774582408.0595\n",
            "For 9524th iteration, the training loss is 53774455840.6973\n",
            "For 9525th iteration, the training loss is 53774328396.74694\n",
            "For 9526th iteration, the training loss is 53774201174.0368\n",
            "For 9527th iteration, the training loss is 53774074145.57071\n",
            "For 9528th iteration, the training loss is 53773947677.70335\n",
            "For 9529th iteration, the training loss is 53773820323.420135\n",
            "For 9530th iteration, the training loss is 53773693197.96014\n",
            "For 9531th iteration, the training loss is 53773566255.66223\n",
            "For 9532th iteration, the training loss is 53773439882.24127\n",
            "For 9533th iteration, the training loss is 53773312658.9888\n",
            "For 9534th iteration, the training loss is 53773185719.679825\n",
            "For 9535th iteration, the training loss is 53773058861.3142\n",
            "For 9536th iteration, the training loss is 53772932245.96495\n",
            "For 9537th iteration, the training loss is 53772805436.11708\n",
            "For 9538th iteration, the training loss is 53772679161.07705\n",
            "For 9539th iteration, the training loss is 53772552037.900314\n",
            "For 9540th iteration, the training loss is 53772425616.57542\n",
            "For 9541th iteration, the training loss is 53772298555.10244\n",
            "For 9542th iteration, the training loss is 53772171849.674835\n",
            "For 9543th iteration, the training loss is 53772045163.568275\n",
            "For 9544th iteration, the training loss is 53771918527.93675\n",
            "For 9545th iteration, the training loss is 53771792022.40464\n",
            "For 9546th iteration, the training loss is 53771665461.61007\n",
            "For 9547th iteration, the training loss is 53771539123.59568\n",
            "For 9548th iteration, the training loss is 53771412764.90445\n",
            "For 9549th iteration, the training loss is 53771286161.23782\n",
            "For 9550th iteration, the training loss is 53771159856.31224\n",
            "For 9551th iteration, the training loss is 53771033306.2684\n",
            "For 9552th iteration, the training loss is 53770907054.3704\n",
            "For 9553th iteration, the training loss is 53770780557.15065\n",
            "For 9554th iteration, the training loss is 53770654357.56961\n",
            "For 9555th iteration, the training loss is 53770527912.404785\n",
            "For 9556th iteration, the training loss is 53770401764.45639\n",
            "For 9557th iteration, the training loss is 53770275373.10435\n",
            "For 9558th iteration, the training loss is 53770149312.6202\n",
            "For 9559th iteration, the training loss is 53770023229.89512\n",
            "For 9560th iteration, the training loss is 53769896901.03485\n",
            "For 9561th iteration, the training loss is 53769770905.14408\n",
            "For 9562th iteration, the training loss is 53769644994.9648\n",
            "For 9563th iteration, the training loss is 53769519090.10575\n",
            "For 9564th iteration, the training loss is 53769392860.57201\n",
            "For 9565th iteration, the training loss is 53769266960.83827\n",
            "For 9566th iteration, the training loss is 53769141038.05032\n",
            "For 9567th iteration, the training loss is 53769014867.90297\n",
            "For 9568th iteration, the training loss is 53768889030.10847\n",
            "For 9569th iteration, the training loss is 53768763276.97335\n",
            "For 9570th iteration, the training loss is 53768637417.094635\n",
            "For 9571th iteration, the training loss is 53768511464.118164\n",
            "For 9572th iteration, the training loss is 53768385718.959236\n",
            "For 9573th iteration, the training loss is 53768260059.19185\n",
            "For 9574th iteration, the training loss is 53768134292.077675\n",
            "For 9575th iteration, the training loss is 53768008318.241714\n",
            "For 9576th iteration, the training loss is 53767882636.520386\n",
            "For 9577th iteration, the training loss is 53767756709.18394\n",
            "For 9578th iteration, the training loss is 53767631109.32344\n",
            "For 9579th iteration, the training loss is 53767505593.60408\n",
            "For 9580th iteration, the training loss is 53767379969.77948\n",
            "For 9581th iteration, the training loss is 53767254470.3972\n",
            "For 9582th iteration, the training loss is 53767128998.03657\n",
            "For 9583th iteration, the training loss is 53767003248.011185\n",
            "For 9584th iteration, the training loss is 53766877794.12608\n",
            "For 9585th iteration, the training loss is 53766752009.51348\n",
            "For 9586th iteration, the training loss is 53766626637.12168\n",
            "For 9587th iteration, the training loss is 53766500721.05497\n",
            "For 9588th iteration, the training loss is 53766375092.11157\n",
            "For 9589th iteration, the training loss is 53766249467.21009\n",
            "For 9590th iteration, the training loss is 53766124263.63715\n",
            "For 9591th iteration, the training loss is 53765998398.54107\n",
            "For 9592th iteration, the training loss is 53765873293.375015\n",
            "For 9593th iteration, the training loss is 53765747468.39525\n",
            "For 9594th iteration, the training loss is 53765622458.65636\n",
            "For 9595th iteration, the training loss is 53765496615.057365\n",
            "For 9596th iteration, the training loss is 53765371221.39975\n",
            "For 9597th iteration, the training loss is 53765245757.52693\n",
            "For 9598th iteration, the training loss is 53765120310.35107\n",
            "For 9599th iteration, the training loss is 53764995063.078674\n",
            "For 9600th iteration, the training loss is 53764869773.441536\n",
            "For 9601th iteration, the training loss is 53764744700.19857\n",
            "For 9602th iteration, the training loss is 53764619599.55392\n",
            "For 9603th iteration, the training loss is 53764494694.64755\n",
            "For 9604th iteration, the training loss is 53764369684.30761\n",
            "For 9605th iteration, the training loss is 53764244643.6749\n",
            "For 9606th iteration, the training loss is 53764119724.06904\n",
            "For 9607th iteration, the training loss is 53763994718.917885\n",
            "For 9608th iteration, the training loss is 53763869649.9058\n",
            "For 9609th iteration, the training loss is 53763744408.66234\n",
            "For 9610th iteration, the training loss is 53763619347.57153\n",
            "For 9611th iteration, the training loss is 53763494449.34534\n",
            "For 9612th iteration, the training loss is 53763369494.1442\n",
            "For 9613th iteration, the training loss is 53763244630.14539\n",
            "For 9614th iteration, the training loss is 53763119720.488266\n",
            "For 9615th iteration, the training loss is 53762994890.1944\n",
            "For 9616th iteration, the training loss is 53762870025.98272\n",
            "For 9617th iteration, the training loss is 53762745228.89014\n",
            "For 9618th iteration, the training loss is 53762620410.029015\n",
            "For 9619th iteration, the training loss is 53762495645.65222\n",
            "For 9620th iteration, the training loss is 53762370872.05033\n",
            "For 9621th iteration, the training loss is 53762248917.44605\n",
            "For 9622th iteration, the training loss is 53762126965.69639\n",
            "For 9623th iteration, the training loss is 53762005042.98518\n",
            "For 9624th iteration, the training loss is 53761883135.229416\n",
            "For 9625th iteration, the training loss is 53761761243.93715\n",
            "For 9626th iteration, the training loss is 53761639407.61733\n",
            "For 9627th iteration, the training loss is 53761517465.810295\n",
            "For 9628th iteration, the training loss is 53761395583.40305\n",
            "For 9629th iteration, the training loss is 53761273956.33881\n",
            "For 9630th iteration, the training loss is 53761152110.31773\n",
            "For 9631th iteration, the training loss is 53761030321.57335\n",
            "For 9632th iteration, the training loss is 53760908612.0363\n",
            "For 9633th iteration, the training loss is 53760787170.063\n",
            "For 9634th iteration, the training loss is 53760665358.577126\n",
            "For 9635th iteration, the training loss is 53760543926.99593\n",
            "For 9636th iteration, the training loss is 53760421900.55544\n",
            "For 9637th iteration, the training loss is 53760300174.22244\n",
            "For 9638th iteration, the training loss is 53760178443.167816\n",
            "For 9639th iteration, the training loss is 53760057115.62192\n",
            "For 9640th iteration, the training loss is 53759935173.194595\n",
            "For 9641th iteration, the training loss is 53759813546.12352\n",
            "For 9642th iteration, the training loss is 53759691895.5322\n",
            "For 9643th iteration, the training loss is 53759570666.6294\n",
            "For 9644th iteration, the training loss is 53759448808.711464\n",
            "For 9645th iteration, the training loss is 53759327276.46965\n",
            "For 9646th iteration, the training loss is 53759205706.37659\n",
            "For 9647th iteration, the training loss is 53759084571.10748\n",
            "For 9648th iteration, the training loss is 53758962884.32745\n",
            "For 9649th iteration, the training loss is 53758841455.81225\n",
            "For 9650th iteration, the training loss is 53758720120.85934\n",
            "For 9651th iteration, the training loss is 53758599059.98272\n",
            "For 9652th iteration, the training loss is 53758477621.04925\n",
            "For 9653th iteration, the training loss is 53758356566.58143\n",
            "For 9654th iteration, the training loss is 53758235015.42073\n",
            "For 9655th iteration, the training loss is 53758113793.90911\n",
            "For 9656th iteration, the training loss is 53757992436.64325\n",
            "For 9657th iteration, the training loss is 53757871480.067276\n",
            "For 9658th iteration, the training loss is 53757749982.770805\n",
            "For 9659th iteration, the training loss is 53757628777.96937\n",
            "For 9660th iteration, the training loss is 53757507628.7833\n",
            "For 9661th iteration, the training loss is 53757386572.73475\n",
            "For 9662th iteration, the training loss is 53757265520.27829\n",
            "For 9663th iteration, the training loss is 53757144445.41344\n",
            "For 9664th iteration, the training loss is 53757023566.628\n",
            "For 9665th iteration, the training loss is 53756902652.61533\n",
            "For 9666th iteration, the training loss is 53756781924.862625\n",
            "For 9667th iteration, the training loss is 53756661083.219124\n",
            "For 9668th iteration, the training loss is 53756540206.54426\n",
            "For 9669th iteration, the training loss is 53756419413.69335\n",
            "For 9670th iteration, the training loss is 53756298460.706635\n",
            "For 9671th iteration, the training loss is 53756177667.20468\n",
            "For 9672th iteration, the training loss is 53756056821.84483\n",
            "For 9673th iteration, the training loss is 53755936035.66069\n",
            "For 9674th iteration, the training loss is 53755815229.84583\n",
            "For 9675th iteration, the training loss is 53755694451.38267\n",
            "For 9676th iteration, the training loss is 53755573685.183014\n",
            "For 9677th iteration, the training loss is 53755452914.8297\n",
            "For 9678th iteration, the training loss is 53755332245.28658\n",
            "For 9679th iteration, the training loss is 53755211681.90513\n",
            "For 9680th iteration, the training loss is 53755090951.48642\n",
            "For 9681th iteration, the training loss is 53754970386.48184\n",
            "For 9682th iteration, the training loss is 53754849684.767624\n",
            "For 9683th iteration, the training loss is 53754729056.08753\n",
            "For 9684th iteration, the training loss is 53754608520.40781\n",
            "For 9685th iteration, the training loss is 53754488094.08447\n",
            "For 9686th iteration, the training loss is 53754367496.791794\n",
            "For 9687th iteration, the training loss is 53754247067.2485\n",
            "For 9688th iteration, the training loss is 53754126481.221825\n",
            "For 9689th iteration, the training loss is 53754006022.25445\n",
            "For 9690th iteration, the training loss is 53753885593.48086\n",
            "For 9691th iteration, the training loss is 53753765054.444084\n",
            "For 9692th iteration, the training loss is 53753644567.06006\n",
            "For 9693th iteration, the training loss is 53753524211.17934\n",
            "For 9694th iteration, the training loss is 53753403844.315994\n",
            "For 9695th iteration, the training loss is 53753283487.60567\n",
            "For 9696th iteration, the training loss is 53753163213.35825\n",
            "For 9697th iteration, the training loss is 53753043051.63901\n",
            "For 9698th iteration, the training loss is 53752922714.451515\n",
            "For 9699th iteration, the training loss is 53752802545.587685\n",
            "For 9700th iteration, the training loss is 53752682236.83289\n",
            "For 9701th iteration, the training loss is 53752561996.49295\n",
            "For 9702th iteration, the training loss is 53752441847.36399\n",
            "For 9703th iteration, the training loss is 53752321804.86079\n",
            "For 9704th iteration, the training loss is 53752201592.28194\n",
            "For 9705th iteration, the training loss is 53752081535.4125\n",
            "For 9706th iteration, the training loss is 53751961339.33102\n",
            "For 9707th iteration, the training loss is 53751841245.96173\n",
            "For 9708th iteration, the training loss is 53751721231.64074\n",
            "For 9709th iteration, the training loss is 53751601211.55009\n",
            "For 9710th iteration, the training loss is 53751481117.7966\n",
            "For 9711th iteration, the training loss is 53751361149.61218\n",
            "For 9712th iteration, the training loss is 53751241236.214165\n",
            "For 9713th iteration, the training loss is 53751121651.0619\n",
            "For 9714th iteration, the training loss is 53751001855.315\n",
            "For 9715th iteration, the training loss is 53750882127.89104\n",
            "For 9716th iteration, the training loss is 53750762165.83511\n",
            "For 9717th iteration, the training loss is 53750642391.63741\n",
            "For 9718th iteration, the training loss is 53750522705.97978\n",
            "For 9719th iteration, the training loss is 53750402836.18385\n",
            "For 9720th iteration, the training loss is 53750283134.569565\n",
            "For 9721th iteration, the training loss is 53750163287.69102\n",
            "For 9722th iteration, the training loss is 53750043505.075745\n",
            "For 9723th iteration, the training loss is 53749923815.255714\n",
            "For 9724th iteration, the training loss is 53749804227.0749\n",
            "For 9725th iteration, the training loss is 53749684471.60501\n",
            "For 9726th iteration, the training loss is 53749564853.317116\n",
            "For 9727th iteration, the training loss is 53749445141.92737\n",
            "For 9728th iteration, the training loss is 53749325292.61777\n",
            "For 9729th iteration, the training loss is 53749205611.849464\n",
            "For 9730th iteration, the training loss is 53749086049.18903\n",
            "For 9731th iteration, the training loss is 53748966544.55702\n",
            "For 9732th iteration, the training loss is 53748847249.7658\n",
            "For 9733th iteration, the training loss is 53748727829.95191\n",
            "For 9734th iteration, the training loss is 53748608253.67496\n",
            "For 9735th iteration, the training loss is 53748488865.04729\n",
            "For 9736th iteration, the training loss is 53748369559.334366\n",
            "For 9737th iteration, the training loss is 53748250076.0594\n",
            "For 9738th iteration, the training loss is 53748130739.26101\n",
            "For 9739th iteration, the training loss is 53748011285.62475\n",
            "For 9740th iteration, the training loss is 53747891972.00001\n",
            "For 9741th iteration, the training loss is 53747772532.2595\n",
            "For 9742th iteration, the training loss is 53747653381.92098\n",
            "For 9743th iteration, the training loss is 53747533709.18774\n",
            "For 9744th iteration, the training loss is 53747414709.879364\n",
            "For 9745th iteration, the training loss is 53747295067.63405\n",
            "For 9746th iteration, the training loss is 53747175706.74581\n",
            "For 9747th iteration, the training loss is 53747056360.750984\n",
            "For 9748th iteration, the training loss is 53746937329.92128\n",
            "For 9749th iteration, the training loss is 53746818001.25261\n",
            "For 9750th iteration, the training loss is 53746698869.489174\n",
            "For 9751th iteration, the training loss is 53746579607.175934\n",
            "For 9752th iteration, the training loss is 53746460678.5388\n",
            "For 9753th iteration, the training loss is 53746341300.549416\n",
            "For 9754th iteration, the training loss is 53746222059.767334\n",
            "For 9755th iteration, the training loss is 53746103014.3941\n",
            "For 9756th iteration, the training loss is 53745984119.65857\n",
            "For 9757th iteration, the training loss is 53745865158.90287\n",
            "For 9758th iteration, the training loss is 53745746398.887436\n",
            "For 9759th iteration, the training loss is 53745627515.633965\n",
            "For 9760th iteration, the training loss is 53745508918.56046\n",
            "For 9761th iteration, the training loss is 53745390109.86414\n",
            "For 9762th iteration, the training loss is 53745271364.50356\n",
            "For 9763th iteration, the training loss is 53745152612.4868\n",
            "For 9764th iteration, the training loss is 53745033692.86215\n",
            "For 9765th iteration, the training loss is 53744914891.59439\n",
            "For 9766th iteration, the training loss is 53744796140.22035\n",
            "For 9767th iteration, the training loss is 53744677594.479614\n",
            "For 9768th iteration, the training loss is 53744558921.4514\n",
            "For 9769th iteration, the training loss is 53744440326.25937\n",
            "For 9770th iteration, the training loss is 53744321552.4074\n",
            "For 9771th iteration, the training loss is 53744202910.51737\n",
            "For 9772th iteration, the training loss is 53744084302.96778\n",
            "For 9773th iteration, the training loss is 53743965793.99217\n",
            "For 9774th iteration, the training loss is 53743847167.189514\n",
            "For 9775th iteration, the training loss is 53743728490.19005\n",
            "For 9776th iteration, the training loss is 53743609930.85796\n",
            "For 9777th iteration, the training loss is 53743491316.950836\n",
            "For 9778th iteration, the training loss is 53743372898.68895\n",
            "For 9779th iteration, the training loss is 53743254307.05835\n",
            "For 9780th iteration, the training loss is 53743135832.93817\n",
            "For 9781th iteration, the training loss is 53743017406.18251\n",
            "For 9782th iteration, the training loss is 53742899297.7202\n",
            "For 9783th iteration, the training loss is 53742780971.136734\n",
            "For 9784th iteration, the training loss is 53742662705.75847\n",
            "For 9785th iteration, the training loss is 53742544323.06703\n",
            "For 9786th iteration, the training loss is 53742425884.9724\n",
            "For 9787th iteration, the training loss is 53742307564.77646\n",
            "For 9788th iteration, the training loss is 53742189197.53505\n",
            "For 9789th iteration, the training loss is 53742070989.96497\n",
            "For 9790th iteration, the training loss is 53741952865.94591\n",
            "For 9791th iteration, the training loss is 53741834693.08708\n",
            "For 9792th iteration, the training loss is 53741716695.70548\n",
            "For 9793th iteration, the training loss is 53741598597.302635\n",
            "For 9794th iteration, the training loss is 53741480558.8554\n",
            "For 9795th iteration, the training loss is 53741362403.07415\n",
            "For 9796th iteration, the training loss is 53741244186.815765\n",
            "For 9797th iteration, the training loss is 53741126090.32995\n",
            "For 9798th iteration, the training loss is 53741007943.21675\n",
            "For 9799th iteration, the training loss is 53740889867.4208\n",
            "For 9800th iteration, the training loss is 53740771765.79615\n",
            "For 9801th iteration, the training loss is 53740653848.14604\n",
            "For 9802th iteration, the training loss is 53740535756.401566\n",
            "For 9803th iteration, the training loss is 53740417722.45108\n",
            "For 9804th iteration, the training loss is 53740299771.593185\n",
            "For 9805th iteration, the training loss is 53740181701.97541\n",
            "For 9806th iteration, the training loss is 53740063710.720894\n",
            "For 9807th iteration, the training loss is 53739945866.78725\n",
            "For 9808th iteration, the training loss is 53739827973.7309\n",
            "For 9809th iteration, the training loss is 53739710077.83177\n",
            "For 9810th iteration, the training loss is 53739592256.921486\n",
            "For 9811th iteration, the training loss is 53739474441.24854\n",
            "For 9812th iteration, the training loss is 53739356593.57665\n",
            "For 9813th iteration, the training loss is 53739238932.80272\n",
            "For 9814th iteration, the training loss is 53739121093.13938\n",
            "For 9815th iteration, the training loss is 53739003311.27634\n",
            "For 9816th iteration, the training loss is 53738885610.50282\n",
            "For 9817th iteration, the training loss is 53738767909.96213\n",
            "For 9818th iteration, the training loss is 53738650181.91382\n",
            "For 9819th iteration, the training loss is 53738532631.11787\n",
            "For 9820th iteration, the training loss is 53738414993.41897\n",
            "For 9821th iteration, the training loss is 53738297384.58888\n",
            "For 9822th iteration, the training loss is 53738179821.96659\n",
            "For 9823th iteration, the training loss is 53738062455.06885\n",
            "For 9824th iteration, the training loss is 53737944954.82472\n",
            "For 9825th iteration, the training loss is 53737827435.22013\n",
            "For 9826th iteration, the training loss is 53737709884.24898\n",
            "For 9827th iteration, the training loss is 53737592512.36103\n",
            "For 9828th iteration, the training loss is 53737474969.59198\n",
            "For 9829th iteration, the training loss is 53737357580.98765\n",
            "For 9830th iteration, the training loss is 53737240024.101234\n",
            "For 9831th iteration, the training loss is 53737122799.63413\n",
            "For 9832th iteration, the training loss is 53737005026.65786\n",
            "For 9833th iteration, the training loss is 53736887898.34177\n",
            "For 9834th iteration, the training loss is 53736770161.135895\n",
            "For 9835th iteration, the training loss is 53736653126.09491\n",
            "For 9836th iteration, the training loss is 53736535511.02507\n",
            "For 9837th iteration, the training loss is 53736418102.487625\n",
            "For 9838th iteration, the training loss is 53736300698.50683\n",
            "For 9839th iteration, the training loss is 53736183564.44103\n",
            "For 9840th iteration, the training loss is 53736066173.844124\n",
            "For 9841th iteration, the training loss is 53735949008.06655\n",
            "For 9842th iteration, the training loss is 53735831826.31016\n",
            "For 9843th iteration, the training loss is 53735714571.03261\n",
            "For 9844th iteration, the training loss is 53735597581.72072\n",
            "For 9845th iteration, the training loss is 53735480538.42687\n",
            "For 9846th iteration, the training loss is 53735363657.98455\n",
            "For 9847th iteration, the training loss is 53735246643.04041\n",
            "For 9848th iteration, the training loss is 53735129900.01863\n",
            "For 9849th iteration, the training loss is 53735012938.44483\n",
            "For 9850th iteration, the training loss is 53734896139.995544\n",
            "For 9851th iteration, the training loss is 53734779239.4559\n",
            "For 9852th iteration, the training loss is 53734662614.63945\n",
            "For 9853th iteration, the training loss is 53734545765.495964\n",
            "For 9854th iteration, the training loss is 53734429082.55785\n",
            "For 9855th iteration, the training loss is 53734312292.526566\n",
            "For 9856th iteration, the training loss is 53734195554.39196\n",
            "For 9857th iteration, the training loss is 53734078596.74265\n",
            "For 9858th iteration, the training loss is 53733961726.96666\n",
            "For 9859th iteration, the training loss is 53733845026.25708\n",
            "For 9860th iteration, the training loss is 53733728243.288414\n",
            "For 9861th iteration, the training loss is 53733611467.82275\n",
            "For 9862th iteration, the training loss is 53733494750.10744\n",
            "For 9863th iteration, the training loss is 53733378032.11247\n",
            "For 9864th iteration, the training loss is 53733261281.94653\n",
            "For 9865th iteration, the training loss is 53733144695.59165\n",
            "For 9866th iteration, the training loss is 53733027953.973366\n",
            "For 9867th iteration, the training loss is 53732911332.39218\n",
            "For 9868th iteration, the training loss is 53732794582.66382\n",
            "For 9869th iteration, the training loss is 53732678094.5024\n",
            "For 9870th iteration, the training loss is 53732561285.3939\n",
            "For 9871th iteration, the training loss is 53732444693.77502\n",
            "For 9872th iteration, the training loss is 53732328018.53994\n",
            "For 9873th iteration, the training loss is 53732211692.691185\n",
            "For 9874th iteration, the training loss is 53732094806.85745\n",
            "For 9875th iteration, the training loss is 53731978552.11128\n",
            "For 9876th iteration, the training loss is 53731861791.04652\n",
            "For 9877th iteration, the training loss is 53731745645.05607\n",
            "For 9878th iteration, the training loss is 53731628913.17849\n",
            "For 9879th iteration, the training loss is 53731512373.93072\n",
            "For 9880th iteration, the training loss is 53731395984.18897\n",
            "For 9881th iteration, the training loss is 53731279727.62059\n",
            "For 9882th iteration, the training loss is 53731163401.93305\n",
            "For 9883th iteration, the training loss is 53731047250.38913\n",
            "For 9884th iteration, the training loss is 53730931186.08585\n",
            "For 9885th iteration, the training loss is 53730814980.79991\n",
            "For 9886th iteration, the training loss is 53730699043.592186\n",
            "For 9887th iteration, the training loss is 53730582882.44384\n",
            "For 9888th iteration, the training loss is 53730466988.51525\n",
            "For 9889th iteration, the training loss is 53730350871.01563\n",
            "For 9890th iteration, the training loss is 53730235019.78502\n",
            "For 9891th iteration, the training loss is 53730118945.463264\n",
            "For 9892th iteration, the training loss is 53730002839.30708\n",
            "For 9893th iteration, the training loss is 53729886699.68478\n",
            "For 9894th iteration, the training loss is 53729770712.79588\n",
            "For 9895th iteration, the training loss is 53729654670.60061\n",
            "For 9896th iteration, the training loss is 53729538438.712074\n",
            "For 9897th iteration, the training loss is 53729422344.90035\n",
            "For 9898th iteration, the training loss is 53729306331.841415\n",
            "For 9899th iteration, the training loss is 53729190379.380684\n",
            "For 9900th iteration, the training loss is 53729074414.9612\n",
            "For 9901th iteration, the training loss is 53728958426.52735\n",
            "For 9902th iteration, the training loss is 53728842572.82652\n",
            "For 9903th iteration, the training loss is 53728726723.775215\n",
            "For 9904th iteration, the training loss is 53728611070.78823\n",
            "For 9905th iteration, the training loss is 53728495275.76617\n",
            "For 9906th iteration, the training loss is 53728379445.390724\n",
            "For 9907th iteration, the training loss is 53728263588.37801\n",
            "For 9908th iteration, the training loss is 53728147866.73336\n",
            "For 9909th iteration, the training loss is 53728032043.87507\n",
            "For 9910th iteration, the training loss is 53727916616.29714\n",
            "For 9911th iteration, the training loss is 53727800961.197685\n",
            "For 9912th iteration, the training loss is 53727685459.7738\n",
            "For 9913th iteration, the training loss is 53727569851.137436\n",
            "For 9914th iteration, the training loss is 53727454299.20761\n",
            "For 9915th iteration, the training loss is 53727338813.31495\n",
            "For 9916th iteration, the training loss is 53727223374.766426\n",
            "For 9917th iteration, the training loss is 53727108121.99963\n",
            "For 9918th iteration, the training loss is 53726992636.30058\n",
            "For 9919th iteration, the training loss is 53726877306.60271\n",
            "For 9920th iteration, the training loss is 53726761864.9941\n",
            "For 9921th iteration, the training loss is 53726646481.3878\n",
            "For 9922th iteration, the training loss is 53726530919.96912\n",
            "For 9923th iteration, the training loss is 53726415527.82776\n",
            "For 9924th iteration, the training loss is 53726299888.04059\n",
            "For 9925th iteration, the training loss is 53726184518.797516\n",
            "For 9926th iteration, the training loss is 53726068895.22197\n",
            "For 9927th iteration, the training loss is 53725953406.17057\n",
            "For 9928th iteration, the training loss is 53725838053.71734\n",
            "For 9929th iteration, the training loss is 53725722721.53196\n",
            "For 9930th iteration, the training loss is 53725607429.72025\n",
            "For 9931th iteration, the training loss is 53725492129.09417\n",
            "For 9932th iteration, the training loss is 53725376798.05378\n",
            "For 9933th iteration, the training loss is 53725261596.7193\n",
            "For 9934th iteration, the training loss is 53725146296.77722\n",
            "For 9935th iteration, the training loss is 53725031288.06467\n",
            "For 9936th iteration, the training loss is 53724916222.73675\n",
            "For 9937th iteration, the training loss is 53724801095.2009\n",
            "For 9938th iteration, the training loss is 53724685924.76649\n",
            "For 9939th iteration, the training loss is 53724570733.80473\n",
            "For 9940th iteration, the training loss is 53724455654.62645\n",
            "For 9941th iteration, the training loss is 53724340595.98212\n",
            "For 9942th iteration, the training loss is 53724225833.71615\n",
            "For 9943th iteration, the training loss is 53724110839.434166\n",
            "For 9944th iteration, the training loss is 53723995698.18914\n",
            "For 9945th iteration, the training loss is 53723880640.533485\n",
            "For 9946th iteration, the training loss is 53723765715.5057\n",
            "For 9947th iteration, the training loss is 53723650695.521065\n",
            "For 9948th iteration, the training loss is 53723535734.84254\n",
            "For 9949th iteration, the training loss is 53723420747.929085\n",
            "For 9950th iteration, the training loss is 53723305875.16435\n",
            "For 9951th iteration, the training loss is 53723191018.79478\n",
            "For 9952th iteration, the training loss is 53723076344.9089\n",
            "For 9953th iteration, the training loss is 53722961526.16003\n",
            "For 9954th iteration, the training loss is 53722846546.668594\n",
            "For 9955th iteration, the training loss is 53722731676.57243\n",
            "For 9956th iteration, the training loss is 53722616898.41053\n",
            "For 9957th iteration, the training loss is 53722502066.7522\n",
            "For 9958th iteration, the training loss is 53722387265.16243\n",
            "For 9959th iteration, the training loss is 53722272464.5992\n",
            "For 9960th iteration, the training loss is 53722157735.02806\n",
            "For 9961th iteration, the training loss is 53722043064.22158\n",
            "For 9962th iteration, the training loss is 53721928564.813\n",
            "For 9963th iteration, the training loss is 53721814016.58739\n",
            "For 9964th iteration, the training loss is 53721699621.4482\n",
            "For 9965th iteration, the training loss is 53721585074.887634\n",
            "For 9966th iteration, the training loss is 53721470571.98525\n",
            "For 9967th iteration, the training loss is 53721356136.04515\n",
            "For 9968th iteration, the training loss is 53721241741.8375\n",
            "For 9969th iteration, the training loss is 53721127311.78702\n",
            "For 9970th iteration, the training loss is 53721012945.13783\n",
            "For 9971th iteration, the training loss is 53720898620.628784\n",
            "For 9972th iteration, the training loss is 53720784261.53562\n",
            "For 9973th iteration, the training loss is 53720669962.78758\n",
            "For 9974th iteration, the training loss is 53720555598.679375\n",
            "For 9975th iteration, the training loss is 53720441074.55291\n",
            "For 9976th iteration, the training loss is 53720326546.350586\n",
            "For 9977th iteration, the training loss is 53720212191.674965\n",
            "For 9978th iteration, the training loss is 53720097790.427185\n",
            "For 9979th iteration, the training loss is 53719983301.89905\n",
            "For 9980th iteration, the training loss is 53719868936.21847\n",
            "For 9981th iteration, the training loss is 53719754632.291435\n",
            "For 9982th iteration, the training loss is 53719640392.64168\n",
            "For 9983th iteration, the training loss is 53719526116.43029\n",
            "For 9984th iteration, the training loss is 53719411833.3822\n",
            "For 9985th iteration, the training loss is 53719297622.1311\n",
            "For 9986th iteration, the training loss is 53719183372.400856\n",
            "For 9987th iteration, the training loss is 53719069136.35614\n",
            "For 9988th iteration, the training loss is 53718955144.52672\n",
            "For 9989th iteration, the training loss is 53718841086.050835\n",
            "For 9990th iteration, the training loss is 53718727179.4744\n",
            "For 9991th iteration, the training loss is 53718613217.92687\n",
            "For 9992th iteration, the training loss is 53718499518.73615\n",
            "For 9993th iteration, the training loss is 53718385576.48661\n",
            "For 9994th iteration, the training loss is 53718271780.690926\n",
            "For 9995th iteration, the training loss is 53718157866.241135\n",
            "For 9996th iteration, the training loss is 53718043995.62639\n",
            "For 9997th iteration, the training loss is 53717930184.057365\n",
            "For 9998th iteration, the training loss is 53717816412.35826\n",
            "For 9999th iteration, the training loss is 53717702600.719124\n",
            "For 10000th iteration, the training loss is 53717588848.28159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(loss[:100])\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss1[:100])\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.ylabel(\"Validation loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "3i9QMcEmPIGJ",
        "outputId": "c1896532-4318-4db1-b479-32383ac802e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "s5ucVf3ngDz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regresssion using Scikit-Learn"
      ],
      "metadata": {
        "id": "cnqPf322cGa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('kc_house_data.csv')\n"
      ],
      "metadata": {
        "id": "RqUSh2xMcPgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing train_test_split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "# splitting the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.drop(['price','id','date'],axis =1), data['price'], test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "BdCkxDTck78J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# creating an object of LinearRegression class\n",
        "LR = LinearRegression()\n",
        "# fitting the training data\n",
        "LR.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZdZmHp7lkbq",
        "outputId": "25aaef78-30ef-4d75-c429-9b962d17ec23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prediction =  LR.predict(x_test)"
      ],
      "metadata": {
        "id": "Y7plkSXlltyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing r2_score module\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# predicting the accuracy score\n",
        "score=r2_score(y_test,y_prediction)\n",
        "print(\"r2 score is\",score)\n",
        "print(\"mean_sqrd_error is \",mean_squared_error(y_test,y_prediction))\n",
        "print(\"root_mean_squared error of is \",np.sqrt(mean_squared_error(y_test,y_prediction)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CAl76WqmymT",
        "outputId": "52684a29-07d9-4141-9483-d97622afbbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 score is 0.7011904448878554\n",
            "mean_sqrd_error is  45173046132.78801\n",
            "root_mean_squared error of is  212539.5166381725\n"
          ]
        }
      ]
    }
  ]
}